@misc{acharyaLearningForecastAleatoric2023,
  title = {Learning to {{Forecast Aleatoric}} and {{Epistemic Uncertainties}} over {{Long Horizon Trajectories}}},
  author = {Acharya, Aastha and Russell, Rebecca and Ahmed, Nisar R.},
  year = {2023},
  month = feb,
  number = {arXiv:2302.08669},
  eprint = {2302.08669},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.08669},
  urldate = {2024-03-14},
  abstract = {Giving autonomous agents the ability to forecast their own outcomes and uncertainty will allow them to communicate their competencies and be used more safely. We accomplish this by using a learned world model of the agent system to forecast full agent trajectories over long time horizons. Real world systems involve significant sources of both aleatoric and epistemic uncertainty that compound and interact over time in the trajectory forecasts. We develop a deep generative world model that quantifies aleatoric uncertainty while incorporating the effects of epistemic uncertainty during the learning process. We show on two reinforcement learning problems that our uncertainty model produces calibrated outcome uncertainty estimates over the full trajectory horizon.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,notion},
  file = {/Users/nscherf/Zotero/storage/U5N99LDJ/Acharya et al. - 2023 - Learning to Forecast Aleatoric and Epistemic Uncer.pdf;/Users/nscherf/Zotero/storage/WIG5TBVL/2302.html}
}

@article{achtibatAttributionMapsHumanunderstandable2023,
  title = {From Attribution Maps to Human-Understandable Explanations through {{Concept Relevance Propagation}}},
  author = {Achtibat, Reduan and Dreyer, Maximilian and Eisenbraun, Ilona and Bosse, Sebastian and Wiegand, Thomas and Samek, Wojciech and Lapuschkin, Sebastian},
  year = {2023},
  month = sep,
  journal = {Nature Machine Intelligence},
  volume = {5},
  number = {9},
  pages = {1006--1019},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00711-8},
  urldate = {2023-09-26},
  abstract = {The field of explainable artificial intelligence (XAI) aims to bring transparency to today's powerful but opaque deep learning models. While local XAI methods explain individual predictions in the form of attribution maps, thereby identifying `where' important features occur (but not providing information about `what' they represent), global explanation techniques visualize what concepts a model has generally learned to encode. Both types of method thus provide only partial insights and leave the burden of interpreting the model's reasoning to the user. Here we introduce the Concept Relevance Propagation (CRP) approach, which combines the local and global perspectives and thus allows answering both the `where' and `what' questions for individual predictions. We demonstrate the capability of our method in various settings, showcasing that CRP leads to more human interpretable explanations and provides deep insights into the model's representation and reasoning through concept atlases, concept-composition analyses, and quantitative investigations of concept subspaces and their role in fine-grained decision-making.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Computer science,notion,Statistics},
  file = {/Users/nscherf/Zotero/storage/3L8B3QF7/Achtibat et al. - 2023 - From attribution maps to human-understandable expl.pdf}
}

@inproceedings{amiranashviliLearningShapeReconstruction2022,
  title = {Learning {{Shape Reconstruction}} from {{Sparse Measurements}} with {{Neural Implicit Functions}}},
  booktitle = {Medical {{Imaging}} with {{Deep Learning}}},
  author = {Amiranashvili, Tamaz and L{\"u}dke, David and Li, Hongwei and Menze, Bjoern and Zachow, Stefan},
  year = {2022},
  month = jun,
  urldate = {2022-10-25},
  abstract = {Reconstructing anatomical shapes from sparse or partial measurements relies on prior knowledge of shape variations that occur within a given population. Such shape priors are learned from example shapes, obtained by segmenting volumetric medical images. For existing models, the resolution of a learned shape prior is limited to the resolution of the training data. However, in clinical practice, volumetric images are often acquired with highly anisotropic voxel sizes, e.g. to reduce image acquisition time in MRI or radiation exposure in CT imaging. The missing shape information between the slices prohibits existing methods to learn a high-resolution shape prior. We introduce a method for high-resolution shape reconstruction from sparse measurements without relying on high-resolution ground truth for training. Our method is based on neural implicit shape representations and learns a continuous shape prior only from highly anisotropic segmentations. Furthermore, it is able to learn from shapes with a varying field of view and can reconstruct from various sparse input configurations. We demonstrate its effectiveness on two anatomical structures: vertebra and distal femur, and successfully reconstruct high-resolution shapes from sparse segmentations, using as few as three orthogonal slices.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/FDGX8AD2/Amiranashvili et al_2022_Learning Shape Reconstruction from Sparse Measurements with Neural Implicit.pdf;/Users/nscherf/Zotero/storage/8VA2PQRH/forum.html}
}

@article{anonymousInternalRepresentationDynamics2023,
  title = {Internal {{Representation Dynamics}} in {{Transformers}}},
  author = {Anonymous},
  year = {2023},
  month = oct,
  urldate = {2024-03-04},
  abstract = {In this study, we present an investigation into the anisotropy dynamics and intrinsic dimension of embeddings in transformer architectures, focusing on the dichotomy between encoders and decoders. Our findings reveal that the anisotropy profile in transformer decoders exhibits a distinct bell-shaped curve, with the highest anisotropy concentrations in the middle layers. This pattern diverges from the more uniformly distributed anisotropy observed in encoders. In addition, we found that the intrinsic dimension of embeddings increases in the initial phases of training, indicating an expansion into higher-dimensional space. This fact is then followed by a compression phase towards the end of training with dimensionality decrease, suggesting a refinement into more compact representations. Our results provide fresh insights to the understanding of encoders and decoders embedding properties.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/XC47M4TW/Anonymous - 2023 - Internal Representation Dynamics in Transformers.pdf}
}

@article{anOverviewBiologicalComputational2021,
  title = {An {{Overview}} of {{Biological}} and {{Computational Methods}} for {{Designing Mechanism-Informed Anti-biofilm Agents}}},
  author = {An, Andy Y. and Choi, Ka-Yee Grace and Baghela, Arjun S. and Hancock, Robert E. W.},
  year = {2021},
  journal = {Frontiers in Microbiology},
  volume = {12},
  issn = {1664-302X},
  urldate = {2023-11-24},
  abstract = {Bacterial biofilms are complex and highly antibiotic-resistant aggregates of microbes that form on surfaces in the environment and body including medical devices. They are key contributors to the growing antibiotic resistance crisis and account for two-thirds of all infections. Thus, there is a critical need to develop anti-biofilm specific therapeutics. Here we discuss mechanisms of biofilm formation, current anti-biofilm agents, and strategies for developing, discovering, and testing new anti-biofilm agents. Biofilm formation involves many factors and is broadly regulated by the stringent response, quorum sensing, and c-di-GMP signaling, processes that have been targeted by anti-biofilm agents. Developing new anti-biofilm agents requires a comprehensive systems-level understanding of these mechanisms, as well as the discovery of new mechanisms. This can be accomplished through omics approaches such as transcriptomics, metabolomics, and proteomics, which can also be integrated to better understand biofilm biology. Guided by mechanistic understanding, in silico techniques such as virtual screening and machine learning can discover small molecules that can inhibit key biofilm regulators. To increase the likelihood that these candidate agents selected from in silico approaches are efficacious in humans, they must be tested in biologically relevant biofilm models. We discuss the benefits and drawbacks of in vitro and in vivo biofilm models and highlight organoids as a new biofilm model. This review offers a comprehensive guide of current and future biological and computational approaches of anti-biofilm therapeutic discovery for investigators to utilize to combat the antibiotic resistance crisis.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/ETE3MAR5/An et al. - 2021 - An Overview of Biological and Computational Method.pdf}
}

@misc{ansuiniIntrinsicDimensionData2019,
  title = {Intrinsic Dimension of Data Representations in Deep Neural Networks},
  author = {Ansuini, Alessio and Laio, Alessandro and Macke, Jakob H. and Zoccolan, Davide},
  year = {2019},
  month = oct,
  number = {arXiv:1905.12784},
  eprint = {1905.12784},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2023-05-08},
  abstract = {Deep neural networks progressively transform their inputs across multiple processing layers. What are the geometrical properties of the representations learned by these networks? Here we study the intrinsic dimensionality (ID) of data-representations, i.e. the minimal number of parameters needed to describe a representation. We find that, in a trained network, the ID is orders of magnitude smaller than the number of units in each layer. Across layers, the ID first increases and then progressively decreases in the final layers. Remarkably, the ID of the last hidden layer predicts classification accuracy on the test set. These results can neither be found by linear dimensionality estimates (e.g., with principal component analysis), nor in representations that had been artificially linearized. They are neither found in untrained networks, nor in networks that are trained on randomized labels. This suggests that neural networks that can generalize are those that transform the data into low-dimensional, but not necessarily flat manifolds.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/6FIHWRYG/Ansuini et al. - 2019 - Intrinsic dimension of data representations in dee.pdf;/Users/nscherf/Zotero/storage/SUBXY3JF/1905.html}
}

@article{aziziTimeVaryingAnalysis2024,
  title = {Time Varying Analysis of Dynamic Resting-State Functional Brain Network to Unfold Memory Function},
  author = {Azizi, Tahmineh},
  year = {2024},
  month = mar,
  journal = {Neuroscience Informatics},
  volume = {4},
  number = {1},
  pages = {100148},
  issn = {2772-5286},
  doi = {10.1016/j.neuri.2023.100148},
  urldate = {2024-02-01},
  abstract = {Recent advances in brain network analysis are largely based on graph theory methods to assess brain network organization, function, and malfunction. Although, functional magnetic resonance imaging (fMRI) has been frequently used to study brain activity, however, the nonlinear dynamics in resting-state (fMRI) data have not been extensively characterized. In this work, we aim to model the dynamics of resting-state (fMRI) and characterize the dynamical patterns in resting-state (fMRI) time series data in left and right hippocampus and inferior frontal gyrus. We use Sliding Window Embedding (SWE) method to reconstruct the phase space of resting-state (fMRI) data from left and right hippocampus and orbital part of inferior frontal gyrus. The complexity of resting-state MRI data is examined using fractal analysis. The main purpose of the current study is to explore the topological organization of hippocampus and frontal gyrus and consequently, memory. By constructing resting-state functional network from resting-state (fMRI) time series data, we are able to draw a big picture of how brain functions and step forward to classify brain activity between normal control people and patients with different brain disorders.},
  keywords = {Dynamic memory,Frontal gyrus,Hippocampus,notion,Resting state networks,Sliding window embedding,Topological data analysis},
  file = {/Users/nscherf/Zotero/storage/4VFNWK2J/S277252862300033X.html}
}

@article{barackTwoViewsCognitive2021,
  title = {Two Views on the Cognitive Brain},
  author = {Barack, David L. and Krakauer, John W.},
  year = {2021},
  month = jun,
  journal = {Nature Reviews Neuroscience},
  volume = {22},
  number = {6},
  pages = {359--371},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-021-00448-6},
  urldate = {2022-05-30},
  abstract = {Cognition can be defined as computation over meaningful representations in the brain to produce adaptive behaviour. There are two views on the relationship between cognition and the brain that are largely implicit in the literature. The Sherringtonian view seeks to explain cognition as the result of operations on signals performed at nodes in a network and passed between them that are implemented by specific neurons and their connections in circuits in the brain. The contrasting Hopfieldian view explains cognition as the result of transformations between or movement within representational spaces that are implemented by neural populations. Thus, the Hopfieldian view relegates details regarding the identity of and connections between specific neurons to the status of secondary explainers. Only the Hopfieldian approach has the representational and computational resources needed to develop novel neurofunctional objects that can serve as primary explainers of cognition.},
  copyright = {2021 Springer Nature Limited},
  langid = {english},
  keywords = {ACONITE,Intelligence,notion,Philosophy},
  file = {/Users/nscherf/Zotero/storage/STZVBXMP/Barack_Krakauer_2021_Two views on the cognitive brain.pdf;/Users/nscherf/Zotero/storage/WQ797X58/s41583-021-00448-6.html}
}

@article{bardesRevisitingFeaturePrediction,
  title = {Revisiting {{Feature Prediction}} for {{Learning Visual Representations}} from {{Video}}},
  author = {Bardes, Adrien and Garrido, Quentin and Ponce, Jean and Chen, Xinlei and Rabbat, Michael and LeCun, Yann and Assran, Mahmoud and Ballas, Nicolas},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/VMXHATX6/Bardes et al. - Revisiting Feature Prediction for Learning Visual .pdf}
}

@misc{bengioDeepGenerativeStochastic2014,
  title = {Deep {{Generative Stochastic Networks Trainable}} by {{Backprop}}},
  author = {Bengio, Yoshua and {Thibodeau-Laufer}, {\'E}ric and Alain, Guillaume and Yosinski, Jason},
  year = {2014},
  month = may,
  number = {arXiv:1306.1091},
  eprint = {1306.1091},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-07-10},
  abstract = {We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution of the Markov chain is conditional on the previous state, generally involving a small move, so this conditional distribution has fewer dominant modes, being unimodal in the limit of small moves. Thus, it is easier to learn because it is easier to approximate its partition function, more like learning to perform supervised function approximation, with gradients that can be obtained by backprop. We provide theorems that generalize recent work on the probabilistic interpretation of denoising autoencoders and obtain along the way an interesting justification for dependency networks and generalized pseudolikelihood, along with a definition of an appropriate joint distribution and sampling mechanism even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. We validate these theoretical results with experiments on two image datasets using an architecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows training to proceed with simple backprop, without the need for layerwise pretraining.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/ZSPPXT7Z/Bengio et al. - 2014 - Deep Generative Stochastic Networks Trainable by B.pdf;/Users/nscherf/Zotero/storage/VL242CDL/1306.html}
}

@article{bhatiaBuresWassersteinDistance2019,
  title = {On the {{Bures}}--{{Wasserstein}} Distance between Positive Definite Matrices},
  author = {Bhatia, Rajendra and Jain, Tanvi and Lim, Yongdo},
  year = {2019},
  month = jun,
  journal = {Expositiones Mathematicae},
  volume = {37},
  number = {2},
  pages = {165--191},
  issn = {0723-0869},
  doi = {10.1016/j.exmath.2018.01.002},
  urldate = {2024-02-09},
  abstract = {The metric d(A,B)=trA+trB-2tr(A1/2BA1/2)1/21/2 on the manifold of n{\texttimes}n positive definite matrices arises in various optimisation problems, in quantum information and in the theory of optimal transport. It is also related to Riemannian geometry. In the first part of this paper we study this metric from the perspective of matrix analysis, simplifying and unifying various proofs. Then we develop a theory of a mean of two, and a barycentre of several, positive definite matrices with respect to this metric. We explain some recent work on a fixed point iteration for computing this Wasserstein barycentre. Our emphasis is on ideas natural to matrix analysis.},
  keywords = {Bures distance,Coupling problem,Fidelity,notion,Optimal transport,Positive definite matrices,Wasserstein metric},
  file = {/Users/nscherf/Zotero/storage/4VPWPLGI/Bhatia et al. - 2019 - On the Buresâ€“Wasserstein distance between positive.pdf;/Users/nscherf/Zotero/storage/7V4BYTXY/S0723086918300021.html}
}

@article{broidoScalefreeNetworksAre2019,
  title = {Scale-Free Networks Are Rare},
  author = {Broido, Anna D. and Clauset, Aaron},
  year = {2019},
  month = mar,
  journal = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {1017},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-08746-5},
  urldate = {2023-12-08},
  abstract = {Real-world networks are often claimed to be scale free,~meaning that the fraction of nodes with degree k follows a power law k-{$\alpha$}, a pattern with broad implications for the structure and dynamics of complex systems. However, the universality of scale-free networks remains controversial. Here, we organize different definitions of scale-free networks and construct a severe test of their empirical prevalence using state-of-the-art statistical tools applied to nearly 1000 social, biological, technological, transportation, and information networks. Across these networks, we find robust evidence that strongly scale-free structure is empirically rare, while for most networks, log-normal distributions fit the data as well or better than power laws. Furthermore, social networks are at best weakly scale free, while a handful of technological and biological networks appear strongly scale free. These findings highlight the structural diversity of real-world networks and the need for new theoretical explanations of these non-scale-free patterns.},
  copyright = {2019 The Author(s)},
  langid = {english},
  keywords = {Complex networks,Network topology,notion,Power law,Statistical methods},
  file = {/Users/nscherf/Zotero/storage/TD2FR4NY/Broido and Clauset - 2019 - Scale-free networks are rare.pdf}
}

@misc{cetinHyperbolicDeepReinforcement2022,
  title = {Hyperbolic {{Deep Reinforcement Learning}}},
  author = {Cetin, Edoardo and Chamberlain, Benjamin and Bronstein, Michael and Hunt, Jonathan J.},
  year = {2022},
  month = oct,
  number = {arXiv:2210.01542},
  eprint = {2210.01542},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-11-30},
  abstract = {We propose a new class of deep reinforcement learning (RL) algorithms that model latent representations in hyperbolic space. Sequential decision-making requires reasoning about the possible future consequences of current behavior. Consequently, capturing the relationship between key evolving features for a given task is conducive to recovering effective policies. To this end, hyperbolic geometry provides deep RL models with a natural basis to precisely encode this inherently hierarchical information. However, applying existing methodologies from the hyperbolic deep learning literature leads to fatal optimization instabilities due to the non-stationarity and variance characterizing RL gradient estimators. Hence, we design a new general method that counteracts such optimization challenges and enables stable end-to-end learning with deep hyperbolic representations. We empirically validate our framework by applying it to popular on-policy and off-policy RL algorithms on the Procgen and Atari 100K benchmarks, attaining near universal performance and generalization benefits. Given its natural fit, we hope future RL research will consider hyperbolic representations as a standard tool.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/LCTK7EYE/Cetin et al. - 2022 - Hyperbolic Deep Reinforcement Learning.pdf;/Users/nscherf/Zotero/storage/6VCF2F2A/2210.html}
}

@misc{chamberlainGraphNeuralNetworks2023,
  title = {Graph {{Neural Networks}} for {{Link Prediction}} with {{Subgraph Sketching}}},
  author = {Chamberlain, Benjamin Paul and Shirobokov, Sergey and Rossi, Emanuele and Frasca, Fabrizio and Markovich, Thomas and Hammerla, Nils and Bronstein, Michael M. and Hansmire, Max},
  year = {2023},
  month = may,
  number = {arXiv:2209.15486},
  eprint = {2209.15486},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2209.15486},
  urldate = {2024-02-02},
  abstract = {Many Graph Neural Networks (GNNs) perform poorly compared to simple heuristics on Link Prediction (LP) tasks. This is due to limitations in expressive power such as the inability to count triangles (the backbone of most LP heuristics) and because they can not distinguish automorphic nodes (those having identical structural roles). Both expressiveness issues can be alleviated by learning link (rather than node) representations and incorporating structural features such as triangle counts. Since explicit link representations are often prohibitively expensive, recent works resorted to subgraph-based methods, which have achieved state-of-the-art performance for LP, but suffer from poor efficiency due to high levels of redundancy between subgraphs. We analyze the components of subgraph GNN (SGNN) methods for link prediction. Based on our analysis, we propose a novel full-graph GNN called ELPH (Efficient Link Prediction with Hashing) that passes subgraph sketches as messages to approximate the key components of SGNNs without explicit subgraph construction. ELPH is provably more expressive than Message Passing GNNs (MPNNs). It outperforms existing SGNN models on many standard LP benchmarks while being orders of magnitude faster. However, it shares the common GNN limitation that it is only efficient when the dataset fits in GPU memory. Accordingly, we develop a highly scalable model, called BUDDY, which uses feature precomputation to circumvent this limitation without sacrificing predictive performance. Our experiments show that BUDDY also outperforms SGNNs on standard LP benchmarks while being highly scalable and faster than ELPH.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/RIF944PM/Chamberlain et al. - 2023 - Graph Neural Networks for Link Prediction with Sub.pdf;/Users/nscherf/Zotero/storage/93QBNBMR/2209.html}
}

@misc{chenUnsupervisedManifoldAlignment2023,
  title = {Unsupervised {{Manifold Alignment}} with {{Joint Multidimensional Scaling}}},
  author = {Chen, Dexiong and Fan, Bowen and Oliver, Carlos and Borgwardt, Karsten},
  year = {2023},
  month = feb,
  number = {arXiv:2207.02968},
  eprint = {2207.02968},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2023-12-08},
  abstract = {We introduce Joint Multidimensional Scaling, a novel approach for unsupervised manifold alignment, which maps datasets from two different domains, without any known correspondences between data instances across the datasets, to a common low-dimensional Euclidean space. Our approach integrates Multidimensional Scaling (MDS) and Wasserstein Procrustes analysis into a joint optimization problem to simultaneously generate isometric embeddings of data and learn correspondences between instances from two different datasets, while only requiring intra-dataset pairwise dissimilarities as input. This unique characteristic makes our approach applicable to datasets without access to the input features, such as solving the inexact graph matching problem. We propose an alternating optimization scheme to solve the problem that can fully benefit from the optimization techniques for MDS and Wasserstein Procrustes. We demonstrate the effectiveness of our approach in several applications, including joint visualization of two datasets, unsupervised heterogeneous domain adaptation, graph matching, and protein structure alignment. The implementation of our work is available at https://github.com/BorgwardtLab/JointMDS},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/XURURSDB/Chen et al. - 2023 - Unsupervised Manifold Alignment with Joint Multidi.pdf;/Users/nscherf/Zotero/storage/WIMIN36J/2207.html}
}

@inproceedings{choNeuralLatentAligner2023,
  title = {Neural {{Latent Aligner}}: {{Cross-trial Alignment}} for {{Learning Representations}} of {{Complex}}, {{Naturalistic Neural Data}}},
  shorttitle = {Neural {{Latent Aligner}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Cho, Cheol Jun and Chang, Edward and Anumanchipalli, Gopala},
  year = {2023},
  month = jul,
  pages = {5661--5676},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2023-11-23},
  abstract = {Understanding the neural implementation of complex human behaviors is one of the major goals in neuroscience. To this end, it is crucial to find a true representation of the neural data, which is challenging due to the high complexity of behaviors and the low signal-to-ratio (SNR) of the signals. Here, we propose a novel unsupervised learning framework, Neural Latent Aligner (NLA), to find well-constrained, behaviorally relevant neural representations of complex behaviors. The key idea is to align representations across repeated trials to learn cross-trial consistent information. Furthermore, we propose a novel, fully differentiable time warping model (TWM) to resolve the temporal misalignment of trials. When applied to intracranial electrocorticography (ECoG) of natural speaking, our model learns better representations for decoding behaviors than the baseline models, especially in lower dimensional space. The TWM is empirically validated by measuring behavioral coherence between aligned trials. The proposed framework learns more cross-trial consistent representations than the baselines, and when visualized, the manifold reveals shared neural trajectories across trials.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/APE792PV/Cho et al. - 2023 - Neural Latent Aligner Cross-trial Alignment for L.pdf}
}

@article{choudharyChaosBacterialStress2023,
  title = {Chaos in a Bacterial Stress Response},
  author = {Choudhary, Divya and Foster, Kevin R. and Uphoff, Stephan},
  year = {2023},
  month = dec,
  journal = {Current Biology},
  volume = {33},
  number = {24},
  pages = {5404-5414.e9},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2023.11.002},
  urldate = {2024-01-26},
  abstract = {Cellular responses to environmental changes are often highly heterogeneous and exhibit seemingly random dynamics. The astonishing insight of chaos theory is that such unpredictable patterns can, in principle, arise without the need for any random processes, i.e., purely deterministically without noise. However, while chaos is well understood in mathematics and physics, its role in cell biology remains unclear because the complexity and noisiness of biological systems make testing difficult. Here, we show that chaos explains the heterogeneous response of Escherichia coli cells to oxidative stress. We developed a theoretical model of the gene expression dynamics and demonstrate that chaotic behavior arises from rapid molecular feedbacks that are coupled with cell growth dynamics and cell-cell interactions. Based on theoretical predictions, we then designed single-cell experiments to show we can shift gene expression from periodic oscillations to chaos on demand. Our work suggests that chaotic gene regulation can be employed by cell populations to generate strong and variable responses to changing environments.},
  keywords = {bacterial stress response,chaos,gene regulation,notion,oxidative stress,phenotypic heterogeneity,single-cell analysis},
  file = {/Users/nscherf/Zotero/storage/IXEP4FNJ/S0960982223015166.html}
}

@article{choVariationalAutoencoderProvides2023,
  title = {A Variational Autoencoder Provides Novel, Data-Driven Features That Explain Functional Brain Representations in a Naturalistic Navigation Task},
  author = {Cho, Cheol Jun and Zhang, Tianjiao and Gallant, Jack L.},
  year = {2023},
  month = aug,
  journal = {Journal of Vision},
  volume = {23},
  number = {9},
  pages = {5728},
  issn = {1534-7362},
  doi = {10.1167/jov.23.9.5728},
  urldate = {2023-11-29},
  abstract = {Navigation in the real world is a complex task that engages several cognitive systems, brain regions and networks. Current models of brain systems mediating navigation reflect relatively simple psychological theories and so may miss important aspects of cognitive function in this complex task. Here we develop an alternative, data-driven approach that uses a variational autoencoder to generate novel hypotheses about brain representation during navigation. The key idea is to generate features from a trained autoencoder to create novel encoding models that successfully model brain activity. As a proof of concept, we applied this method to fMRI data acquired from three participants who performed a taxi-driver task in a large virtual environment. A spatiotemporal variational autoencoder was trained on the visual stimulus seen by the participants while they performed the task, and ridge regression was used to estimate voxelwise encoding models based on the latent features learned by the autoencoder. Inspection of the fit voxelwise encoding models shows that the latent autoencoder features explain variance in brain activity broadly across the cerebral cortex. To interpret the fit encoding models a new cluster analysis method called model connectivity (MC) was used to recover functional networks by grouping voxels according to their encoding model weights. MC recovers several different networks from the data, encompassing motor (M1 and S1), vision (V1-4), navigation (RSC, OPA, PPA, and PFC), and theory-of-mind (TPJ and PFC) ROIs and other regions of the cerebral cortex. Finally, to facilitate interpretation the average weights obtained within each identified cluster were decoded. This procedure revealed specific visual-motor features--such as approaching vehicles and destination instructions--that are preferentially represented in distinct functional networks. In sum, these preliminary data suggest that a variational autoencoder can reveal novel aspects of cortical representation during naturalistic navigation.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/F3BC9UZE/article.html}
}

@article{chowdhuryHypergraphCooptimalTransport2023,
  title = {Hypergraph Co-Optimal Transport: Metric and Categorical Properties},
  shorttitle = {Hypergraph Co-Optimal Transport},
  author = {Chowdhury, Samir and Needham, Tom and Semrad, Ethan and Wang, Bei and Zhou, Youjia},
  year = {2023},
  month = sep,
  journal = {Journal of Applied and Computational Topology},
  issn = {2367-1734},
  doi = {10.1007/s41468-023-00142-9},
  urldate = {2023-12-06},
  abstract = {Hypergraphs capture multi-way relationships in data, and they have consequently seen a number of applications in higher-order network analysis, computer vision, geometry processing, and machine learning. In this paper, we develop theoretical foundations for studying the space of hypergraphs using ingredients from optimal transport. By enriching a hypergraph with probability measures on its nodes and hyperedges, as well as relational information capturing local and global structures, we obtain a general and robust framework for studying the collection of all hypergraphs. First, we introduce a hypergraph distance based on the co-optimal transport framework of Redko et al. and study its theoretical properties. Second, we formalize common methods for transforming a hypergraph into a graph as maps between the space of hypergraphs and the space of graphs, and study their functorial properties and Lipschitz bounds. Finally, we demonstrate the versatility of our Hypergraph Co-Optimal Transport (HyperCOT) framework through various examples.},
  langid = {english},
  keywords = {18M35,51F99,55N31,Category theory,Hypergraph matching,Hypergraph metrics,Hypergraphs,notion,Optimal transport},
  file = {/Users/nscherf/Zotero/storage/JPZWMXAG/Chowdhury et al. - 2023 - Hypergraph co-optimal transport metric and catego.pdf}
}

@article{chungNeuralPopulationGeometry2021,
  title = {Neural Population Geometry: {{An}} Approach for Understanding Biological and Artificial Neural Networks},
  shorttitle = {Neural Population Geometry},
  author = {Chung, SueYeon and Abbott, L. F.},
  year = {2021},
  month = apr,
  journal = {arXiv:2104.07059 [cs, q-bio]},
  eprint = {2104.07059},
  primaryclass = {cs, q-bio},
  urldate = {2021-09-10},
  abstract = {Advances in experimental neuroscience have transformed our ability to explore the structure and function of neural circuits. At the same time, advances in machine learning have unleashed the remarkable computational power of artificial neural networks (ANNs). While these two fields have different tools and applications, they present a similar challenge: namely, understanding how information is embedded and processed through high-dimensional representations to solve complex tasks. One approach to addressing this challenge is to utilize mathematical and computational tools to analyze the geometry of these high-dimensional representations, i.e., neural population geometry. We review examples of geometrical approaches providing insight into the function of biological and artificial neural networks: representation untangling in perception, a geometric theory of classification capacity, disentanglement and abstraction in cognitive systems, topological representations underlying cognitive maps, dynamic untangling in motor systems, and a dynamical approach to cognition. Together, these findings illustrate an exciting trend at the intersection of machine learning, neuroscience, and geometry, in which neural population geometry provides a useful population-level mechanistic descriptor underlying task implementation. Importantly, geometric descriptions are applicable across sensory modalities, brain regions, network architectures and timescales. Thus, neural population geometry has the potential to unify our understanding of structure and function in biological and artificial neural networks, bridging the gap between single neurons, populations and behavior.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,neural geometry,notion,Quantitative Biology - Neurons and Cognition},
  annotation = {ZSCC: 0000002},
  file = {/Users/nscherf/Zotero/storage/CFTDIKZJ/2104.html}
}

@article{coifmanDiffusionMaps2006,
  title = {Diffusion Maps},
  author = {Coifman, Ronald R. and Lafon, St{\'e}phane},
  year = {2006},
  month = jul,
  journal = {Applied and Computational Harmonic Analysis},
  series = {Special {{Issue}}: {{Diffusion Maps}} and {{Wavelets}}},
  volume = {21},
  number = {1},
  pages = {5--30},
  issn = {1063-5203},
  doi = {10.1016/j.acha.2006.04.006},
  urldate = {2022-08-17},
  abstract = {In this paper, we provide a framework based upon diffusion processes for finding meaningful geometric descriptions of data sets. We show that eigenfunctions of Markov matrices can be used to construct coordinates called diffusion maps that generate efficient representations of complex geometric structures. The associated family of diffusion distances, obtained by iterating the Markov matrix, defines multiscale geometries that prove to be useful in the context of data parametrization and dimensionality reduction. The proposed framework relates the spectral properties of Markov processes to their geometric counterparts and it unifies ideas arising in a variety of contexts such as machine learning, spectral graph theory and eigenmap methods.},
  langid = {english},
  keywords = {Diffusion metric,Diffusion processes,Dimensionality reduction,Eigenmaps,Graph Laplacian,Manifold learning,notion},
  file = {/Users/nscherf/Zotero/storage/WDD9YAJZ/Coifman_Lafon_2006_Diffusion maps.pdf;/Users/nscherf/Zotero/storage/WYABYCCA/S1063520306000546.html}
}

@misc{csiszarikSimilarityMatchingNeural2021,
  title = {Similarity and {{Matching}} of {{Neural Network Representations}}},
  author = {Csisz{\'a}rik, Adri{\'a}n and {K{\H o}r{\"o}si-Szab{\'o}}, P{\'e}ter and Matszangosz, {\'A}kos K. and Papp, Gergely and Varga, D{\'a}niel},
  year = {2021},
  month = oct,
  number = {arXiv:2110.14633},
  eprint = {2110.14633},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.14633},
  urldate = {2023-12-11},
  abstract = {We employ a toolset -- dubbed Dr. Frankenstein -- to analyse the similarity of representations in deep neural networks. With this toolset, we aim to match the activations on given layers of two trained neural networks by joining them with a stitching layer. We demonstrate that the inner representations emerging in deep convolutional neural networks with the same architecture but different initializations can be matched with a surprisingly high degree of accuracy even with a single, affine stitching layer. We choose the stitching layer from several possible classes of linear transformations and investigate their performance and properties. The task of matching representations is closely related to notions of similarity. Using this toolset, we also provide a novel viewpoint on the current line of research regarding similarity indices of neural network representations: the perspective of the performance on a task.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion}
}

@misc{daiTransformerXLAttentiveLanguage2019,
  title = {Transformer-{{XL}}: {{Attentive Language Models Beyond}} a {{Fixed-Length Context}}},
  shorttitle = {Transformer-{{XL}}},
  author = {Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V. and Salakhutdinov, Ruslan},
  year = {2019},
  month = jun,
  number = {arXiv:1901.02860},
  eprint = {1901.02860},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1901.02860},
  urldate = {2023-11-24},
  abstract = {Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80\% longer than RNNs and 450\% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,notion,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/HYJU9WZS/Dai et al. - 2019 - Transformer-XL Attentive Language Models Beyond a.pdf;/Users/nscherf/Zotero/storage/DLBQ733G/1901.html}
}

@misc{dalalMatrixBayesianLearning2024a,
  title = {The {{Matrix}}: {{A Bayesian}} Learning Model for {{LLMs}}},
  shorttitle = {The {{Matrix}}},
  author = {Dalal, Siddhartha and Misra, Vishal},
  year = {2024},
  month = feb,
  urldate = {2024-02-26},
  abstract = {In this paper, we introduce a Bayesian learning model to understand the behavior of Large Language Models (LLMs). We explore the optimization metric of LLMs, which is based on predicting the next token, and develop a novel model grounded in this principle. Our approach involves constructing an ideal generative text model represented by a multinomial transition probability matrix with a prior, and we examine how LLMs approximate this matrix. We discuss the continuity of the mapping between embeddings and multinomial distributions, and present the Dirichlet approximation theorem to approximate any prior. Additionally, we demonstrate how text generation by LLMs aligns with Bayesian learning principles and delve into the implications for in-context learning, specifically explaining why in-context learning emerges in larger models where prompts are considered as samples to be updated. Our findings indicate that the behavior of LLMs is consistent with Bayesian Learning, offering new insights into their functioning and potential applications.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/KXRK64KH/Dalal and Misra - 2024 - The Matrix A Bayesian learning model for LLMs.pdf}
}

@inproceedings{davariProbingRepresentationForgetting2022,
  title = {Probing {{Representation Forgetting}} in {{Supervised}} and {{Unsupervised Continual Learning}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Davari, MohammadReza and Asadi, Nader and Mudur, Sudhir and Aljundi, Rahaf and Belilovsky, Eugene},
  year = {2022},
  month = jun,
  pages = {16691--16700},
  publisher = {IEEE},
  address = {New Orleans, LA, USA},
  doi = {10.1109/CVPR52688.2022.01621},
  urldate = {2023-11-24},
  isbn = {978-1-66546-946-3},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/CEC3P65P/Davari et al. - 2022 - Probing Representation Forgetting in Supervised an.pdf}
}

@inproceedings{davariReliabilityCKASimilarity2022,
  title = {Reliability of {{CKA}} as a {{Similarity Measure}} in {{Deep Learning}}},
  booktitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  author = {Davari, MohammadReza and Horoi, Stefan and Natik, Amine and Lajoie, Guillaume and Wolf, Guy and Belilovsky, Eugene},
  year = {2022},
  month = sep,
  urldate = {2023-11-24},
  abstract = {Comparing learned neural representations in neural networks is a challenging but important problem, which has been approached in different ways. The Centered Kernel Alignment (CKA) similarity metric, particularly its linear variant, has recently become a popular approach and has been widely used to compare representations of a network's different layers, of architecturally similar networks trained differently, or of models with different architectures trained on the same data. A wide variety of claims about similarity and dissimilarity of these various representations have been made using CKA results. In this work we present analysis that formally characterizes CKA sensitivity to a large class of simple transformations, which can naturally occur in the context of modern machine learning. This provides a concrete explanation to CKA sensitivity to outliers, which has been observed in past works, and to transformations that preserve the linear separability of the data, an important generalization attribute. We empirically investigate several weaknesses of the CKA similarity metric, demonstrating situations in which it gives unexpected or counterintuitive results. Finally we study approaches for modifying representations to maintain functional behaviour while changing the CKA value. Our results illustrate that, in many cases, the CKA value can be easily manipulated without substantial changes to the functional behaviour of the models, and call for caution when leveraging activation alignment metrics.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/3VR8J3JK/Davari et al. - 2022 - Reliability of CKA as a Similarity Measure in Deep.pdf}
}

@misc{deGriffinMixingGated2024,
  title = {Griffin: {{Mixing Gated Linear Recurrences}} with {{Local Attention}} for {{Efficient Language Models}}},
  shorttitle = {Griffin},
  author = {De, Soham and Smith, Samuel L. and Fernando, Anushan and Botev, Aleksandar and {Cristian-Muraru}, George and Gu, Albert and Haroun, Ruba and Berrada, Leonard and Chen, Yutian and Srinivasan, Srivatsan and Desjardins, Guillaume and Doucet, Arnaud and Budden, David and Teh, Yee Whye and Pascanu, Razvan and De Freitas, Nando and Gulcehre, Caglar},
  year = {2024},
  month = feb,
  number = {arXiv:2402.19427},
  eprint = {2402.19427},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.19427},
  urldate = {2024-03-04},
  abstract = {Recurrent neural networks (RNNs) have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale. We propose Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that mixes gated linear recurrences with local attention. Hawk exceeds the reported performance of Mamba on downstream tasks, while Griffin matches the performance of Llama-2 despite being trained on over 6 times fewer tokens. We also show that Griffin can extrapolate on sequences significantly longer than those seen during training. Our models match the hardware efficiency of Transformers during training, and during inference they have lower latency and significantly higher throughput. We scale Griffin up to 14B parameters, and explain how to shard our models for efficient distributed training.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/3H5PEG4R/De et al. - 2024 - Griffin Mixing Gated Linear Recurrences with Loca.pdf;/Users/nscherf/Zotero/storage/DSAN7LBS/2402.html}
}

@misc{dinuSymbolicAIFrameworkLogicbased2024,
  title = {{{SymbolicAI}}: {{A}} Framework for Logic-Based Approaches Combining Generative Models and Solvers},
  shorttitle = {{{SymbolicAI}}},
  author = {Dinu, Marius-Constantin and {Leoveanu-Condrei}, Claudiu and Holzleitner, Markus and Zellinger, Werner and Hochreiter, Sepp},
  year = {2024},
  month = feb,
  number = {arXiv:2402.00854},
  eprint = {2402.00854},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.00854},
  urldate = {2024-02-05},
  abstract = {We introduce SymbolicAI, a versatile and modular framework employing a logic-based approach to concept learning and flow management in generative processes. SymbolicAI enables the seamless integration of generative models with a diverse range of solvers by treating large language models (LLMs) as semantic parsers that execute tasks based on both natural and formal language instructions, thus bridging the gap between symbolic reasoning and generative AI. We leverage probabilistic programming principles to tackle complex tasks, and utilize differentiable and classical programming paradigms with their respective strengths. The framework introduces a set of polymorphic, compositional, and self-referential operations for data stream manipulation, aligning LLM outputs with user objectives. As a result, we can transition between the capabilities of various foundation models endowed with zero- and few-shot learning capabilities and specialized, fine-tuned models or solvers proficient in addressing specific problems. In turn, the framework facilitates the creation and evaluation of explainable computational graphs. We conclude by introducing a quality measure and its empirical score for evaluating these computational graphs, and propose a benchmark that compares various state-of-the-art LLMs across a set of complex workflows. We refer to the empirical score as the "Vector Embedding for Relational Trajectory Evaluation through Cross-similarity", or VERTEX score for short. The framework codebase and benchmark are linked below.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Software Engineering,Computer Science - Symbolic Computation,notion},
  file = {/Users/nscherf/Zotero/storage/CTD4ZBW6/Dinu et al. - 2024 - SymbolicAI A framework for logic-based approaches.pdf;/Users/nscherf/Zotero/storage/R23ISE6M/2402.html}
}

@article{doerigNeuroconnectionistResearchProgramme2023,
  title = {The Neuroconnectionist Research Programme},
  author = {Doerig, Adrien and Sommers, Rowan P. and Seeliger, Katja and Richards, Blake and Ismael, Jenann and Lindsay, Grace W. and Kording, Konrad P. and Konkle, Talia and {van Gerven}, Marcel A. J. and Kriegeskorte, Nikolaus and Kietzmann, Tim C.},
  year = {2023},
  month = may,
  journal = {Nature Reviews Neuroscience},
  pages = {1--20},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-023-00705-w},
  urldate = {2023-05-31},
  abstract = {Artificial neural networks (ANNs) inspired by biology are beginning to be widely used to model behavioural and neural data, an approach we call `neuroconnectionism'. ANNs have been not only lauded as the current best models of information processing in the brain but also criticized for failing to account for basic cognitive functions. In this Perspective article, we propose that arguing about the successes and failures of a restricted set of current ANNs is the wrong approach to assess the promise of neuroconnectionism for brain science. Instead, we take inspiration from the philosophy of science, and in particular from Lakatos, who showed that the core of a~scientific research programme is often not directly falsifiable but should be assessed by its capacity to generate novel insights. Following this view, we present neuroconnectionism as a general research programme centred around ANNs as a computational language for expressing falsifiable theories about brain computation. We describe the core of the programme, the underlying computational framework and its tools for testing specific neuroscientific hypotheses and deriving novel understanding. Taking a longitudinal view, we review past and present neuroconnectionist projects and their responses to challenges and argue that the research programme is highly progressive, generating new and otherwise unreachable insights into the workings of the brain.},
  copyright = {2023 Springer Nature Limited},
  langid = {english},
  keywords = {Cognitive neuroscience,Network models,notion},
  file = {/Users/nscherf/Zotero/storage/YFRT7VT7/Doerig et al. - 2023 - The neuroconnectionist research programme.pdf}
}

@inproceedings{dorrellActionableNeuralRepresentations2022,
  title = {Actionable {{Neural Representations}}: {{Grid Cells}} from {{Minimal Constraints}}},
  shorttitle = {Actionable {{Neural Representations}}},
  booktitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  author = {Dorrell, Will and Latham, Peter E. and Behrens, Timothy E. J. and Whittington, James C. R.},
  year = {2022},
  month = sep,
  urldate = {2024-02-01},
  abstract = {To afford flexible behaviour, the brain must build internal representations that mirror the structure of variables in the external world. For example, 2D space obeys rules: the same set of actions combine in the same way everywhere (step north, then south, and you won't have moved, wherever you start). We suggest the brain must represent this consistent meaning of actions across space, as it allows you to find new short-cuts and navigate in unfamiliar settings. We term this representation an `actionable representation'. We formulate actionable representations using group and representation theory, and show that, when combined with biological and functional constraints - non-negative firing, bounded neural activity, and precise coding - multiple modules of hexagonal grid cells are the optimal representation of 2D space. We support this claim with intuition, analytic justification, and simulations. Our analytic results normatively explain a set of surprising grid cell phenomena, and make testable predictions for future experiments. Lastly, we highlight the generality of our approach beyond just understanding 2D space. Our work characterises a new principle for understanding and designing flexible internal representations: they should be actionable, allowing animals and machines to predict the consequences of their actions, rather than just encode.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/GMPBJW92/Dorrell et al. - 2022 - Actionable Neural Representations Grid Cells from.pdf}
}

@inproceedings{duongRepresentationalDissimilarityMetric2022,
  title = {Representational {{Dissimilarity Metric Spaces}} for {{Stochastic Neural Networks}}},
  booktitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  author = {Duong, Lyndon and Zhou, Jingyang and Nassar, Josue and Berman, Jules and Olieslagers, Jeroen and Williams, Alex H.},
  year = {2022},
  month = sep,
  urldate = {2024-02-09},
  abstract = {Quantifying similarity between neural representations---e.g. hidden layer activation vectors---is a perennial problem in deep learning and neuroscience research. Existing methods compare deterministic responses (e.g. artificial networks that lack stochastic layers) or averaged responses (e.g., trial-averaged firing rates in biological data). However, these measures of \_deterministic\_ representational similarity ignore the scale and geometric structure of noise, both of which play important roles in neural computation. To rectify this, we generalize previously proposed shape metrics (Williams et al. 2021) to quantify differences in \_stochastic\_ representations. These new distances satisfy the triangle inequality, and thus can be used as a rigorous basis for many supervised and unsupervised analyses. Leveraging this novel framework, we find that the stochastic geometries of neurobiological representations of oriented visual gratings and naturalistic scenes respectively resemble untrained and trained deep network representations. Further, we are able to more accurately predict certain network attributes (e.g. training hyperparameters) from its position in stochastic (versus deterministic) shape space.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/SGH2BNC7/Duong et al. - 2022 - Representational Dissimilarity Metric Spaces for S.pdf}
}

@article{duttaMachineLearningPredicts2022,
  title = {Machine {{Learning Predicts Biogeochemistry}} from {{Microbial Community Structure}} in a {{Complex Model System}}},
  author = {Dutta, Avishek and Goldman, Thomas and Keating, Jeffrey and Burke, Ellen and Williamson, Nicole and Dirmeier, Reinhard and Bowman, Jeff S.},
  year = {2022},
  month = feb,
  journal = {Microbiology Spectrum},
  volume = {10},
  number = {1},
  pages = {e01909-21},
  publisher = {American Society for Microbiology},
  doi = {10.1128/spectrum.01909-21},
  urldate = {2023-11-02},
  abstract = {Microbial community structure is influenced by the environment and in turn exerts control on many environmental parameters. We applied this concept in a bioreactor study to test whether microbial community structure contains information sufficient to predict the concentration of H2S as the product of sulfate reduction. Microbial sulfate reduction is a major source of H2S in many industrial and environmental systems and is often influenced by the existing physicochemical conditions. Production of H2S in industrial systems leads to occupational hazards and adversely affects the quality of products. A long-term (148\,days) experiment was conducted in upflow bioreactors to mimic sulfidogenesis, followed by inhibition with nitrate salts and a resumption of H2S generation when inhibition was released. We determined microbial community structure in 731 samples across 20 bioreactors using 16S rRNA gene sequencing and applied a random forest algorithm to successfully predict different phases of sulfidogenesis and mitigation (accuracy\,=\,93.17\%) and sessile and effluent microbial communities (accuracy\,=\,100\%). Similarly derived regression models that also included cell abundances were able to predict H2S concentration with remarkably high fidelity (R2 {$>$} 0.82). Metabolic profiles based on microbial community structure were also found to be reliable predictors for H2S concentration (R2 = 0.78). These results suggest that microbial community structure contains information sufficient to predict sulfidogenesis in a closed system, with anticipated applications to microbially driven processes in open environments. IMPORTANCE Microbial communities control many biogeochemical processes. Many of these processes are impractical or expensive to measure directly. Because the taxonomic structure of the microbial community is indicative of its function, it encodes information that can be used to predict biogeochemistry. Here, we demonstrate how a machine learning technique can be used to predict sulfidogenesis, a key biogeochemical process in a model system. A distinction of this research was the ability to predict H2S production in a bioreactor from the effluent bacterial community structure without direct observations of the sessile community or other environmental conditions. This study establishes the ability to use machine learning approaches in predicting sulfide concentrations in a closed system, which can be further developed as a valuable tool for predicting biogeochemical processes in open environments. As machine learning algorithms continue to improve, we anticipate increased applications of microbial community structure to predict key environmental and industrial processes.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/7PS46EVS/Dutta et al. - 2022 - Machine Learning Predicts Biogeochemistry from Mic.pdf}
}

@misc{duttaRedesigningTransformerArchitecture2021,
  title = {Redesigning the {{Transformer Architecture}} with {{Insights}} from {{Multi-particle Dynamical Systems}}},
  author = {Dutta, Subhabrata and Gautam, Tanya and Chakrabarti, Soumen and Chakraborty, Tanmoy},
  year = {2021},
  month = oct,
  number = {arXiv:2109.15142},
  eprint = {2109.15142},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2109.15142},
  urldate = {2024-03-04},
  abstract = {The Transformer and its variants have been proven to be efficient sequence learners in many different domains. Despite their staggering success, a critical issue has been the enormous number of parameters that must be trained (ranging from \$10\^{}7\$ to \$10\^{}\{11\}\$) along with the quadratic complexity of dot-product attention. In this work, we investigate the problem of approximating the two central components of the Transformer -- multi-head self-attention and point-wise feed-forward transformation, with reduced parameter space and computational complexity. We build upon recent developments in analyzing deep neural networks as numerical solvers of ordinary differential equations. Taking advantage of an analogy between Transformer stages and the evolution of a dynamical system of multiple interacting particles, we formulate a temporal evolution scheme, TransEvolve, to bypass costly dot-product attention over multiple stacked layers. We perform exhaustive experiments with TransEvolve on well-known encoder-decoder as well as encoder-only tasks. We observe that the degree of approximation (or inversely, the degree of parameter reduction) has different effects on the performance, depending on the task. While in the encoder-decoder regime, TransEvolve delivers performances comparable to the original Transformer, in encoder-only tasks it consistently outperforms Transformer along with several subsequent variants.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/YDKAI3P9/Dutta et al. - 2021 - Redesigning the Transformer Architecture with Insi.pdf;/Users/nscherf/Zotero/storage/MDEDDV59/2109.html}
}

@inproceedings{eastwoodFrameworkQuantitativeEvaluation2018,
  title = {A {{Framework}} for the {{Quantitative Evaluation}} of {{Disentangled Representations}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Eastwood, Cian and Williams, Christopher K. I.},
  year = {2018},
  month = feb,
  urldate = {2024-02-08},
  abstract = {Recent AI research has emphasised the importance of learning disentangled representations of the explanatory factors behind data. Despite the growing interest in models which can learn such representations, visual inspection remains the standard evaluation metric. While various desiderata have been implied in recent definitions, it is currently unclear what exactly makes one disentangled representation better than another. In this work we propose a framework for the quantitative evaluation of disentangled representations when the ground-truth latent structure is available. Three criteria are explicitly defined and quantified to elucidate the quality of learnt representations and thus compare models on an equal basis. To illustrate the appropriateness of the framework, we employ it to compare quantitatively the representations learned by recent state-of-the-art models.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/GGKDHV7R/Eastwood and Williams - 2018 - A Framework for the Quantitative Evaluation of Dis.pdf}
}

@article{edelmanRepresentationRepresentationSimilarities1998,
  title = {Representation Is Representation of Similarities},
  author = {Edelman, S.},
  year = {1998},
  month = aug,
  journal = {The Behavioral and Brain Sciences},
  volume = {21},
  number = {4},
  pages = {449-467; discussion 467-498},
  issn = {0140-525X},
  doi = {10.1017/s0140525x98001253},
  abstract = {Advanced perceptual systems are faced with the problem of securing a principled (ideally, veridical) relationship between the world and its internal representation. I propose a unified approach to visual representation, addressing the need for superordinate and basic-level categorization and for the identification of specific instances of familiar categories. According to the proposed theory, a shape is represented internally by the responses of a small number of tuned modules, each broadly selective for some reference shape, whose similarity to the stimulus it measures. This amounts to embedding the stimulus in a low-dimensional proximal shape space spanned by the outputs of the active modules. This shape space supports representations of distal shape similarities that are veridical as Shepard's (1968) second-order isomorphisms (i.e., correspondence between distal and proximal similarities among shapes, rather than between distal shapes and their proximal representations). Representation in terms of similarities to reference shapes supports processing (e.g., discrimination) of shapes that are radically different from the reference ones, without the need for the computationally problematic decomposition into parts required by other theories. Furthermore, a general expression for similarity between two stimuli, based on comparisons to reference shapes, can be used to derive models of perceived similarity ranging from continuous, symmetric, and hierarchical ones, as in multidimensional scaling (Shepard 1980), to discrete and nonhierarchical ones, as in the general contrast models (Shepard \& Arabie 1979; Tversky 1977).},
  langid = {english},
  pmid = {10097019},
  keywords = {Cognition,Humans,Mental Processes,Models Psychological,notion,Visual Perception}
}

@article{fakharSystematicPerturbationArtificial2022,
  title = {Systematic Perturbation of an Artificial Neural Network: {{A}} Step towards Quantifying Causal Contributions in the Brain},
  shorttitle = {Systematic Perturbation of an Artificial Neural Network},
  author = {Fakhar, Kayson and Hilgetag, Claus C.},
  year = {2022},
  month = jun,
  journal = {PLOS Computational Biology},
  volume = {18},
  number = {6},
  pages = {e1010250},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1010250},
  urldate = {2024-01-25},
  abstract = {Lesion inference analysis is a fundamental approach for characterizing the causal contributions of neural elements to brain function. This approach has gained new prominence through the arrival of modern perturbation techniques with unprecedented levels of spatiotemporal precision. While inferences drawn from brain perturbations are conceptually powerful, they face methodological difficulties. Particularly, they are challenged to disentangle the true causal contributions of the involved elements, since often functions arise from coalitions of distributed, interacting elements, and localized perturbations have unknown global consequences. To elucidate these limitations, we systematically and exhaustively lesioned a small artificial neural network (ANN) playing a classic arcade game. We determined the functional contributions of all nodes and links, contrasting results from sequential single-element perturbations with simultaneous perturbations of multiple elements. We found that lesioning individual elements, one at a time, produced biased results. By contrast, multi-site lesion analysis captured crucial details that were missed by single-site lesions. We conclude that even small and seemingly simple ANNs show surprising complexity that needs to be addressed by multi-lesioning for a coherent causal characterization.},
  langid = {english},
  keywords = {Artificial neural networks,Behavior,Brain mapping,Chemical elements,Cognitive neuroscience,Neural networks,Neurons,notion,Permutation},
  file = {/Users/nscherf/Zotero/storage/LGEVWRJU/Fakhar and Hilgetag - 2022 - Systematic perturbation of an artificial neural ne.pdf}
}

@article{farrellNeuralBehaviouralState2024,
  title = {Neural and Behavioural State Switching during Hippocampal Dentate Spikes},
  author = {Farrell, Jordan S. and Hwaun, Ernie and Dudok, Barna and Soltesz, Ivan},
  year = {2024},
  month = mar,
  journal = {Nature},
  pages = {1--6},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-024-07192-8},
  urldate = {2024-03-14},
  abstract = {Distinct brain and behavioural states are associated with organized neural population dynamics that are thought to serve specific cognitive functions1--3. Memory replay events, for example, occur during synchronous population events called sharp-wave ripples in the hippocampus while mice are in an `offline' behavioural state, enabling cognitive mechanisms such as memory consolidation and planning4--11. But how does the brain re-engage with the external world during this behavioural state and permit access to current sensory information or promote new memory formation? Here we found that the hippocampal dentate spike, an understudied population event that frequently occurs between sharp-wave ripples12, may underlie such a mechanism. We show that dentate spikes are associated with distinctly elevated brain-wide firing rates, primarily observed in higher order networks, and couple to brief periods of arousal. Hippocampal place coding during dentate spikes aligns to the mouse's current spatial location, unlike the memory replay accompanying sharp-wave ripples. Furthermore, inhibiting neural activity during dentate spikes disrupts associative memory formation. Thus, dentate spikes represent a distinct brain state and support memory during non-locomotor behaviour, extending the repertoire of cognitive processes beyond the classical offline functions.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,notion,Science},
  file = {/Users/nscherf/Zotero/storage/TTIK5YSN/Farrell et al. - 2024 - Neural and behavioural state switching during hipp.pdf}
}

@misc{faskowitzCommentaryPang20232023,
  title = {Commentary on {{Pang}} et al. (2023) {{Nature}}},
  author = {Faskowitz, Joshua and Moyer, Daniel and Handwerker, Daniel A. and {Gonzalez-Castillo}, Javier and Bandettini, Peter A. and Jbabdi, Saad and Betzel, Richard},
  year = {2023},
  month = jul,
  primaryclass = {Contradictory Results},
  pages = {2023.07.20.549785},
  publisher = {bioRxiv},
  doi = {10.1101/2023.07.20.549785},
  urldate = {2023-08-04},
  abstract = {Pang et al. (2023) present novel analyses demonstrating that brain dynamics can be understood as resulting from the excitation of geometric modes, derived from the shape of the brain. Notably, they demonstrate that linear combinations of geometric modes can reconstruct patterns of fMRI data more accurately, and with fewer dimensions, than comparable connectivity-derived modes. Equipped with these results, and underpinned by neural field theory, the authors contend that the geometry of the cortical surface provides a more parsimonious explanation of brain activity than structural brain connectivity. This claim runs counter to prevailing theories of information flow in the brain, which emphasize the role of long-distance axonal projections and fasciculated white matter in relaying signals between cortical regions (Honey et al. 2009; Deco et al. 2011; Seguin et al., 2023). While we acknowledge that cortical geometry plays an important role in shaping human brain function, we feel that the presented work falls short of establishing that the brain's geometry is ``a more fundamental constraint on dynamics than complex interregional connectivity'' (Pang et al. 2023). Here, we provide 1) a brief critique of the paper's framing and 2) evidence showing that their methodology lacks specificity to the brain's orientation and shape. Ultimately, we recognize that the geometric mode approach is a powerful representational framework for brain dynamics analysis, but we also believe that there are key caveats to consider alongside the claims made in the manuscript.},
  archiveprefix = {bioRxiv},
  chapter = {Contradictory Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/MFYENP9Y/Faskowitz et al. - 2023 - Commentary on Pang et al. (2023) Nature.pdf}
}

@article{feinbergNextgenerationMRIScanner2023,
  title = {Next-Generation {{MRI}} Scanner Designed for Ultra-High-Resolution Human Brain Imaging at 7 {{Tesla}}},
  author = {Feinberg, David A. and Beckett, Alexander J. S. and Vu, An T. and Stockmann, Jason and Huber, Laurentius and Ma, Samantha and Ahn, Sinyeob and Setsompop, Kawin and Cao, Xiaozhi and Park, Suhyung and Liu, Chunlei and Wald, Lawrence L. and Polimeni, Jonathan R. and Mareyam, Azma and Gruber, Bernhard and Stirnberg, R{\"u}diger and Liao, Congyu and Yacoub, Essa and Davids, Mathias and Bell, Paul and Rummert, Elmar and Koehler, Michael and Potthast, Andreas and {Gonzalez-Insua}, Ignacio and Stocker, Stefan and Gunamony, Shajan and Dietz, Peter},
  year = {2023},
  month = dec,
  journal = {Nature Methods},
  volume = {20},
  number = {12},
  pages = {2048--2057},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-023-02068-7},
  urldate = {2023-12-22},
  abstract = {To increase granularity in human neuroimaging science, we designed and built a next-generation 7\,Tesla magnetic resonance imaging scanner to reach ultra-high resolution by implementing several advances in hardware. To improve spatial encoding and increase the image signal-to-noise ratio, we developed a head-only asymmetric gradient coil (200\,mT\,m-1, 900\,T\,m-1s-1) with an additional third layer of windings. We integrated a 128-channel receiver system with 64- and 96-channel receiver coil arrays to boost signal in the cerebral cortex while reducing g-factor noise to enable higher accelerations. A 16-channel transmit system reduced power deposition and improved image uniformity. The scanner routinely performs functional imaging studies at 0.35--0.45\,mm isotropic spatial resolution to reveal cortical layer functional activity, achieves high angular resolution in diffusion imaging and reduces acquisition time for both functional and structural imaging.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Functional magnetic resonance imaging,Magnetic resonance imaging,Neuroscience,notion},
  file = {/Users/nscherf/Zotero/storage/M6FLG7AB/Feinberg et al. - 2023 - Next-generation MRI scanner designed for ultra-hig.pdf}
}

@article{floryanDatadrivenDiscoveryIntrinsic2022,
  title = {Data-Driven Discovery of Intrinsic Dynamics},
  author = {Floryan, Daniel and Graham, Michael D.},
  year = {2022},
  month = dec,
  journal = {Nature Machine Intelligence},
  volume = {4},
  number = {12},
  pages = {1113--1120},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-022-00575-4},
  urldate = {2023-08-30},
  abstract = {Dynamical models underpin our ability to understand and predict the behaviour of natural systems. Whether dynamical models are developed from first-principles derivations or from observational data, they are predicated on our choice of state variables. The choice of state variables is driven by convenience and intuition, and, in data-driven cases, the observed variables are often chosen to be the state variables. The dimensionality of these variables (and consequently the dynamical models) can be arbitrarily large, obscuring the underlying behaviour of the system. In truth these variables are often highly redundant and the system is driven by a much smaller set of latent intrinsic variables. In this study we combine the mathematical theory of manifolds with the representational capacity of neural networks to develop a method that learns a system's intrinsic state variables directly from time-series data, as well as predictive models for their dynamics. What distinguishes our method is its ability to reduce data to the intrinsic dimensionality of the nonlinear manifold they live on. This ability is enabled by the concepts of charts and atlases from the theory of manifolds, whereby a manifold is represented by a collection of patches that are sewn together---a necessary representation to attain intrinsic dimensionality. We demonstrate this approach on several high-dimensional systems with low-dimensional behaviour. The resulting framework provides the ability to develop dynamical models of the lowest possible dimension, capturing the essence of a system.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Computational science,notion,Scientific data},
  file = {/Users/nscherf/Zotero/storage/4FS7SJEP/Floryan and Graham - 2022 - Data-driven discovery of intrinsic dynamics.pdf}
}

@inproceedings{frenchSemisupervisedSemanticSegmentation2019,
  title = {Semi-Supervised Semantic Segmentation Needs Strong, High-Dimensional Perturbations},
  booktitle = {British {{Machine Vision Conference}}},
  author = {French, Geoff and Aila, Timo and Laine, Samuli and Mackiewicz, Michal and Finlayson, Graham},
  year = {2019},
  month = sep,
  urldate = {2024-01-15},
  abstract = {Consistency regularization describes a class of approaches that have yielded ground breaking results in semi-supervised classification problems. Prior work has established the cluster assumption{\textbackslash},---{\textbackslash},under which the data distribution consists of uniform class clusters of samples separated by low density regions{\textbackslash},---{\textbackslash},as key to its success. We analyze the problem of semantic segmentation and find that the data distribution does not exhibit low density regions separating classes and offer this as an explanation for why semi-supervised segmentation is a challenging problem. We then identify the conditions that allow consistency regularization to work even without such low-density regions. This allows us to generalize the recently proposed CutMix augmentation technique to a powerful masked variant, CowMix, leading to a successful application of consistency regularization in the semi-supervised semantic segmentation setting and reaching state-of-the-art results in several standard datasets.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/KQM7YLMV/French et al. - 2019 - Semi-supervised semantic segmentation needs strong.pdf}
}

@article{gayosoDeepGenerativeModeling2024,
  title = {Deep Generative Modeling of Transcriptional Dynamics for {{RNA}} Velocity Analysis in Single Cells},
  author = {Gayoso, Adam and Weiler, Philipp and Lotfollahi, Mohammad and Klein, Dominik and Hong, Justin and Streets, Aaron and Theis, Fabian J. and Yosef, Nir},
  year = {2024},
  month = jan,
  journal = {Nature Methods},
  volume = {21},
  number = {1},
  pages = {50--59},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-023-01994-w},
  urldate = {2024-02-01},
  abstract = {RNA velocity has been rapidly adopted to guide interpretation of transcriptional dynamics in snapshot single-cell data; however, current approaches for estimating RNA velocity lack effective strategies for quantifying uncertainty and determining the overall applicability to the system of interest. Here, we present veloVI (velocity variational inference), a deep generative modeling framework for estimating RNA velocity. veloVI learns a gene-specific dynamical model of RNA metabolism and provides a transcriptome-wide quantification of velocity uncertainty. We show that veloVI compares favorably to previous approaches with respect to goodness of fit, consistency across transcriptionally similar cells and stability across preprocessing pipelines for quantifying RNA abundance. Further, we demonstrate that veloVI's posterior velocity uncertainty can be used to assess whether velocity analysis is appropriate for a given dataset. Finally, we highlight veloVI as a flexible framework for modeling transcriptional dynamics by adapting the underlying dynamical model to use time-dependent transcription rates.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Computational models,Machine learning,notion,Software,Transcriptomics},
  file = {/Users/nscherf/Zotero/storage/58S7VRLQ/Gayoso et al. - 2024 - Deep generative modeling of transcriptional dynami.pdf}
}

@misc{gazivRobustifiedANNsReveal2023,
  title = {Robustified {{ANNs Reveal Wormholes Between Human Category Percepts}}},
  author = {Gaziv, Guy and Lee, Michael J. and DiCarlo, James J.},
  year = {2023},
  month = oct,
  number = {arXiv:2308.06887},
  eprint = {2308.06887},
  primaryclass = {cs, q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.06887},
  urldate = {2024-02-02},
  abstract = {The visual object category reports of artificial neural networks (ANNs) are notoriously sensitive to tiny, adversarial image perturbations. Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations -- and locally stable in general -- this argues that ANNs are incomplete scientific models of human visual perception. Consistent with this, we show that when small-norm image perturbations are generated by standard ANN models, human object category percepts are indeed highly stable. However, in this very same "human-presumed-stable" regime, we find that robustified ANNs reliably discover low-norm image perturbations that strongly disrupt human percepts. These previously undetectable human perceptual disruptions are massive in amplitude, approaching the same level of sensitivity seen in robustified ANNs. Further, we show that robustified ANNs support precise perceptual state interventions: they guide the construction of low-norm image perturbations that strongly alter human category percepts toward specific prescribed percepts. These observations suggest that for arbitrary starting points in image space, there exists a set of nearby "wormholes", each leading the subject from their current category perceptual state into a semantically very different state. Moreover, contemporary ANN models of biological visual processing are now accurate enough to consistently guide us to those portals.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,notion,Quantitative Biology - Neurons and Cognition},
  file = {/Users/nscherf/Zotero/storage/W25ZYYG9/Gaziv et al. - 2023 - Robustified ANNs Reveal Wormholes Between Human Ca.pdf;/Users/nscherf/Zotero/storage/4AI4W4B4/2308.html}
}

@article{genevaTransformersModelingPhysical2022,
  title = {Transformers for Modeling Physical Systems},
  author = {Geneva, Nicholas and Zabaras, Nicholas},
  year = {2022},
  month = feb,
  journal = {Neural Networks},
  volume = {146},
  pages = {272--289},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2021.11.022},
  urldate = {2023-11-28},
  abstract = {Transformers are widely used in natural language processing due to their ability to model longer-term dependencies in text. Although these models achieve state-of-the-art performance for many language related tasks, their applicability outside of the natural language processing field has been minimal. In this work, we propose the use of transformer models for the prediction of dynamical systems representative of physical phenomena. The use of Koopman based embeddings provides a unique and powerful method for projecting any dynamical system into a vector representation which can then be predicted by a transformer. The proposed model is able to accurately predict various dynamical systems and outperform classical methods that are commonly used in the scientific machine learning literature.11Code available at: https://github.com/zabaras/transformer-physx.},
  keywords = {Deep learning,Koopman,notion,Physics,Self-attention,Surrogate modeling,Transformers},
  file = {/Users/nscherf/Zotero/storage/8P6AL5BT/Geneva and Zabaras - 2022 - Transformers for modeling physical systems.pdf;/Users/nscherf/Zotero/storage/YFR9RXUY/S0893608021004500.html}
}

@incollection{ghojoghMultidimensionalScalingSammon2023,
  title = {Multidimensional {{Scaling}}, {{Sammon Mapping}}, and {{Isomap}}},
  booktitle = {Elements of {{Dimensionality Reduction}} and {{Manifold Learning}}},
  author = {Ghojogh, Benyamin and Crowley, Mark and Karray, Fakhri and Ghodsi, Ali},
  editor = {Ghojogh, Benyamin and Crowley, Mark and Karray, Fakhri and Ghodsi, Ali},
  year = {2023},
  pages = {185--205},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-10602-6_7},
  urldate = {2023-12-22},
  abstract = {Multidimensional Scaling (MDS) was first proposed in Torgerson and is one of the earliest proposed dimensionality reduction methods.},
  isbn = {978-3-031-10602-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/W7WRUIXK/Ghojogh et al. - 2023 - Multidimensional Scaling, Sammon Mapping, and Isom.pdf}
}

@misc{ghoshLearningActionableRepresentations2019,
  title = {Learning {{Actionable Representations}} with {{Goal-Conditioned Policies}}},
  author = {Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  year = {2019},
  month = jan,
  number = {arXiv:1811.07819},
  eprint = {1811.07819},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-02-01},
  abstract = {Representation learning is a central challenge across a range of machine learning areas. In reinforcement learning, effective and functional representations have the potential to tremendously accelerate learning progress and solve more challenging problems. Most prior work on representation learning has focused on generative approaches, learning representations that capture all underlying factors of variation in the observation space in a more disentangled or well-ordered manner. In this paper, we instead aim to learn functionally salient representations: representations that are not necessarily complete in terms of capturing all factors of variation in the observation space, but rather aim to capture those factors of variation that are important for decision making -- that are "actionable." These representations are aware of the dynamics of the environment, and capture only the elements of the observation that are necessary for decision making rather than all factors of variation, without explicit reconstruction of the observation. We show how these representations can be useful to improve exploration for sparse reward problems, to enable long horizon hierarchical reinforcement learning, and as a state representation for learning policies for downstream tasks. We evaluate our method on a number of simulated environments, and compare it to prior methods for representation learning, exploration, and hierarchical reinforcement learning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,notion,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/DM96VEJ9/Ghosh et al. - 2019 - Learning Actionable Representations with Goal-Cond.pdf;/Users/nscherf/Zotero/storage/295GLAN9/1811.html}
}

@misc{gilpinDeepReconstructionStrange2020,
  title = {Deep Reconstruction of Strange Attractors from Time Series},
  author = {Gilpin, William},
  year = {2020},
  month = oct,
  number = {arXiv:2002.05909},
  eprint = {2002.05909},
  primaryclass = {nlin, physics:physics, q-bio, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2002.05909},
  urldate = {2024-01-26},
  abstract = {Experimental measurements of physical systems often have a limited number of independent channels, causing essential dynamical variables to remain unobserved. However, many popular methods for unsupervised inference of latent dynamics from experimental data implicitly assume that the measurements have higher intrinsic dimensionality than the underlying system---making coordinate identification a dimensionality reduction problem. Here, we study the opposite limit, in which hidden governing coordinates must be inferred from only a low-dimensional time series of measurements. Inspired by classical analysis techniques for partial observations of chaotic attractors, we introduce a general embedding technique for univariate and multivariate time series, consisting of an autoencoder trained with a novel latent-space loss function. We show that our technique reconstructs the strange attractors of synthetic and real-world systems better than existing techniques, and that it creates consistent, predictive representations of even stochastic systems. We conclude by using our technique to discover dynamical attractors in diverse systems such as patient electrocardiograms, household electricity usage, neural spiking, and eruptions of the Old Faithful geyser---demonstrating diverse applications of our technique for exploratory data analysis.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Nonlinear Sciences - Chaotic Dynamics,notion,Physics - Data Analysis Statistics and Probability,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/LVNHN8Y2/Gilpin - 2020 - Deep reconstruction of strange attractors from tim.pdf;/Users/nscherf/Zotero/storage/WXR83IBZ/2002.html}
}

@misc{gosztolaiInterpretableStatisticalRepresentations2023,
  title = {Interpretable Statistical Representations of Neural Population Dynamics and Geometry},
  author = {Gosztolai, Adam and Peach, Robert L. and Arnaudon, Alexis and Barahona, Mauricio and Vandergheynst, Pierre},
  year = {2023},
  month = may,
  number = {arXiv:2304.03376},
  eprint = {2304.03376},
  primaryclass = {cs, math, q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.03376},
  urldate = {2023-10-13},
  abstract = {The dynamics of neuron populations during diverse tasks often evolve on low-dimensional manifolds. However, it remains challenging to discern the contributions of geometry and dynamics for encoding relevant behavioural variables. Here, we introduce an unsupervised geometric deep learning framework for representing non-linear dynamical systems based on statistical distributions of local phase portrait features. Our method provides robust geometry-aware or geometry-agnostic representations for the unbiased comparison of dynamics based on measured trajectories. We demonstrate that our statistical representation can generalise across neural network instances to discriminate computational mechanisms, obtain interpretable embeddings of neural dynamics in a primate reaching task with geometric correspondence to hand kinematics, and develop a decoding algorithm with state-of-the-art accuracy. Our results highlight the importance of using the intrinsic manifold structure over temporal information to develop better decoding algorithms and assimilate data across experiments.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Dynamical Systems,notion,Quantitative Biology - Neurons and Cognition,Quantitative Biology - Quantitative Methods},
  file = {/Users/nscherf/Zotero/storage/LHXDW9FD/Gosztolai et al. - 2023 - Interpretable statistical representations of neura.pdf;/Users/nscherf/Zotero/storage/XYHBJWH2/2304.html}
}

@misc{gruverLargeLanguageModels2023,
  title = {Large {{Language Models Are Zero-Shot Time Series Forecasters}}},
  author = {Gruver, Nate and Finzi, Marc and Qiu, Shikai and Wilson, Andrew Gordon},
  year = {2023},
  month = oct,
  number = {arXiv:2310.07820},
  eprint = {2310.07820},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.07820},
  urldate = {2023-11-24},
  abstract = {By encoding time series as a string of numerical digits, we can frame time series forecasting as next-token prediction in text. Developing this approach, we find that large language models (LLMs) such as GPT-3 and LLaMA-2 can surprisingly zero-shot extrapolate time series at a level comparable to or exceeding the performance of purpose-built time series models trained on the downstream tasks. To facilitate this performance, we propose procedures for effectively tokenizing time series data and converting discrete distributions over tokens into highly flexible densities over continuous values. We argue the success of LLMs for time series stems from their ability to naturally represent multimodal distributions, in conjunction with biases for simplicity, and repetition, which align with the salient features in many time series, such as repeated seasonal trends. We also show how LLMs can naturally handle missing data without imputation through non-numerical text, accommodate textual side information, and answer questions to help explain predictions. While we find that increasing model size generally improves performance on time series, we show GPT-4 can perform worse than GPT-3 because of how it tokenizes numbers, and poor uncertainty calibration, which is likely the result of alignment interventions such as RLHF.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/CHXFEHAD/Gruver et al. - 2023 - Large Language Models Are Zero-Shot Time Series Fo.pdf}
}

@techreport{hanSystemIdentificationNeural2022,
  type = {Article},
  title = {System Identification of Neural Systems: {{If}} We Got It Right, Would We Know?},
  shorttitle = {System Identification of Neural Systems},
  author = {Han, Yena and Poggio, Tomaso and Cheung, Brian},
  year = {2022},
  month = jul,
  institution = {{Center for Brains, Minds and Machines (CBMM)}},
  urldate = {2024-02-08},
  abstract = {Various artificial neural networks developed by engineers have been evaluated as models of the brain, such as the ventral stream in the primate visual cortex. After being trained on large datasets, the network outputs are compared to recordings of biological neurons. Good performance in reproducing neural responses is taken as validation for the model. This system identification approach is different from the traditional ways to test theories and associated models in the natural sciences. Furthermore, it lacks a clear foundation in terms of theory and empirical validation. Here we begin characterizing some of these emerging approaches: what do they tell us? To address this question, we benchmark their ability to correctly identify a model by replacing the brain recordings with recordings from a known ground truth model. We evaluate commonly used identification techniques such as neural regression (linear regression on a population of model units) and centered kernel alignment (CKA). Even in the setting where the correct model is among the candidates, we find that the performance of these approaches at system identification is quite variable; it also depends significantly on factors independent of the ground truth architecture, such as scoring function and dataset.},
  langid = {english},
  keywords = {notion},
  annotation = {Accepted: 2022-07-05T20:07:24Z},
  file = {/Users/nscherf/Zotero/storage/MIFLNPP8/Han et al. - 2022 - System identification of neural systems If we got.pdf}
}

@article{hattoriMetareinforcementLearningOrbitofrontal2023,
  title = {Meta-Reinforcement Learning via Orbitofrontal Cortex},
  author = {Hattori, Ryoma and Hedrick, Nathan G. and Jain, Anant and Chen, Shuqi and You, Hanjia and Hattori, Mariko and Choi, Jun-Hyeok and Lim, Byung Kook and Yasuda, Ryohei and Komiyama, Takaki},
  year = {2023},
  month = nov,
  journal = {Nature Neuroscience},
  pages = {1--10},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-023-01485-3},
  urldate = {2023-11-24},
  abstract = {The meta-reinforcement learning (meta-RL) framework, which involves RL over multiple timescales, has been successful in training deep RL models that generalize to new environments. It has been hypothesized that the prefrontal cortex may mediate meta-RL in the brain, but the evidence is scarce. Here we show that the orbitofrontal cortex (OFC) mediates meta-RL. We trained mice and deep RL models on a probabilistic reversal learning task across sessions during which they improved their trial-by-trial RL policy through meta-learning. Ca2+/calmodulin-dependent protein kinase II-dependent synaptic plasticity in OFC was necessary for this meta-learning but not for the within-session trial-by-trial RL in experts. After meta-learning, OFC activity robustly encoded value signals, and OFC inactivation impaired the RL behaviors. Longitudinal tracking of OFC activity revealed that meta-learning gradually shapes population value coding to guide the ongoing behavioral policy. Our results indicate that two distinct RL algorithms with distinct neural mechanisms and timescales coexist in OFC to support adaptive decision-making.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Cortex,Neural circuits,notion,Reward},
  file = {/Users/nscherf/Zotero/storage/S7255HCK/Hattori et al. - 2023 - Meta-reinforcement learning via orbitofrontal cort.pdf}
}

@article{hirlingSegmentationMetricMisinterpretations2024,
  title = {Segmentation Metric Misinterpretations in Bioimage Analysis},
  author = {Hirling, Dominik and Tasnadi, Ervin and Caicedo, Juan and Caroprese, Maria V. and Sj{\"o}gren, Rickard and Aubreville, Marc and Koos, Krisztian and Horvath, Peter},
  year = {2024},
  month = feb,
  journal = {Nature Methods},
  volume = {21},
  number = {2},
  pages = {213--216},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-023-01942-8},
  urldate = {2024-02-26},
  abstract = {Quantitative evaluation of image segmentation algorithms is crucial in the field of bioimage analysis. The most common assessment scores, however, are often misinterpreted and multiple definitions coexist with the same name. Here we present the ambiguities of evaluation metrics for segmentation algorithms and show how these misinterpretations can alter leaderboards of influential competitions. We also propose guidelines for how the currently existing problems could be tackled.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Image processing,Machine learning,Microscopy,notion},
  file = {/Users/nscherf/Zotero/storage/L5E72D9A/Hirling et al. - 2024 - Segmentation metric misinterpretations in bioimage.pdf}
}

@inproceedings{horanWhenUnsupervisedDisentanglement2021,
  title = {When {{Is Unsupervised Disentanglement Possible}}?},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Horan, Daniella and Richardson, Eitan and Weiss, Yair},
  year = {2021},
  volume = {34},
  pages = {5150--5161},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-02-08},
  abstract = {A common assumption in many domains is that high dimensional data are a smooth nonlinear function of a small number of independent factors. When is it possible to recover the factors from unlabeled data? In the context of deep models this problem is called ``disentanglement'' and was recently shown to be impossible without additional strong assumptions [17, 19]. In this paper, we show that the assumption of local isometry together with non-Gaussianity of the factors, is sufficient to provably recover disentangled representations from data. We leverage recent advances in deep generative models to construct manifolds of highly realistic images for which the ground truth latent representation is known, and test whether modern and classical methods succeed in recovering the latent factors. For many different manifolds, we find that a spectral method that explicitly optimizes local isometry and non-Gaussianity consistently finds the correct latent factors, while baseline deep autoencoders do not. We propose how to encourage deep autoencoders to find encodings that satisfy local isometry and show that this helps them discover disentangled representations. Overall, our results suggest that in some realistic settings, unsupervised disentanglement is provably possible, without any domain-specific assumptions.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/6RH2XCWA/Horan et al. - 2021 - When Is Unsupervised Disentanglement Possible.pdf}
}

@misc{hsuCapturingImplicitHierarchical2021,
  title = {Capturing Implicit Hierarchical Structure in {{3D}} Biomedical Images with Self-Supervised Hyperbolic Representations},
  author = {Hsu, Joy and Gu, Jeffrey and Wu, Gong-Her and Chiu, Wah and Yeung, Serena},
  year = {2021},
  month = oct,
  number = {arXiv:2012.01644},
  eprint = {2012.01644},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-11-30},
  abstract = {We consider the task of representation learning for unsupervised segmentation of 3D voxel-grid biomedical images. We show that models that capture implicit hierarchical relationships between subvolumes are better suited for this task. To that end, we consider encoder-decoder architectures with a hyperbolic latent space, to explicitly capture hierarchical relationships present in subvolumes of the data. We propose utilizing a 3D hyperbolic variational autoencoder with a novel gyroplane convolutional layer to map from the embedding space back to 3D images. To capture these relationships, we introduce an essential self-supervised loss -- in addition to the standard VAE loss -- which infers approximate hierarchies and encourages implicitly related subvolumes to be mapped closer in the embedding space. We present experiments on both synthetic data and biomedical data to validate our hypothesis.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,I.4.10,notion},
  file = {/Users/nscherf/Zotero/storage/XY3WE42B/Hsu et al. - 2021 - Capturing implicit hierarchical structure in 3D bi.pdf;/Users/nscherf/Zotero/storage/RLR9DJTH/2012.html}
}

@misc{hubingerSleeperAgentsTraining2024,
  title = {Sleeper {{Agents}}: {{Training Deceptive LLMs}} That {{Persist Through Safety Training}}},
  shorttitle = {Sleeper {{Agents}}},
  author = {Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Tong, Meg and MacDiarmid, Monte and Lanham, Tamera and Ziegler, Daniel M. and Maxwell, Tim and Cheng, Newton and Jermyn, Adam and Askell, Amanda and Radhakrishnan, Ansh and Anil, Cem and Duvenaud, David and Ganguli, Deep and Barez, Fazl and Clark, Jack and Ndousse, Kamal and Sachan, Kshitij and Sellitto, Michael and Sharma, Mrinank and DasSarma, Nova and Grosse, Roger and Kravec, Shauna and Bai, Yuntao and Witten, Zachary and Favaro, Marina and Brauner, Jan and Karnofsky, Holden and Christiano, Paul and Bowman, Samuel R. and Graham, Logan and Kaplan, Jared and Mindermann, S{\"o}ren and Greenblatt, Ryan and Shlegeris, Buck and Schiefer, Nicholas and Perez, Ethan},
  year = {2024},
  month = jan,
  number = {arXiv:2401.05566},
  eprint = {2401.05566},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.05566},
  urldate = {2024-02-01},
  abstract = {Humans are capable of strategically deceptive behavior: behaving helpfully in most situations, but then behaving very differently in order to pursue alternative objectives when given the opportunity. If an AI system learned such a deceptive strategy, could we detect it and remove it using current state-of-the-art safety training techniques? To study this question, we construct proof-of-concept examples of deceptive behavior in large language models (LLMs). For example, we train models that write secure code when the prompt states that the year is 2023, but insert exploitable code when the stated year is 2024. We find that such backdoor behavior can be made persistent, so that it is not removed by standard safety training techniques, including supervised fine-tuning, reinforcement learning, and adversarial training (eliciting unsafe behavior and then training to remove it). The backdoor behavior is most persistent in the largest models and in models trained to produce chain-of-thought reasoning about deceiving the training process, with the persistence remaining even when the chain-of-thought is distilled away. Furthermore, rather than removing backdoors, we find that adversarial training can teach models to better recognize their backdoor triggers, effectively hiding the unsafe behavior. Our results suggest that, once a model exhibits deceptive behavior, standard techniques could fail to remove such deception and create a false impression of safety.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Software Engineering,notion},
  file = {/Users/nscherf/Zotero/storage/NNQUI6D5/Hubinger et al. - 2024 - Sleeper Agents Training Deceptive LLMs that Persi.pdf;/Users/nscherf/Zotero/storage/USLM7J98/2401.html}
}

@article{jackleTemporalMDSPlots2016,
  title = {Temporal {{MDS Plots}} for {{Analysis}} of {{Multivariate Data}}},
  author = {Jackle, Dominik and Fischer, Fabian and Schreck, Tobias and Keim, Daniel A.},
  year = {2016},
  month = jan,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {22},
  number = {1},
  pages = {141--150},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2015.2467553},
  urldate = {2023-12-08},
  abstract = {Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/BZ6S7BJA/Jackle et al. - 2016 - Temporal MDS Plots for Analysis of Multivariate Da.pdf}
}

@misc{jinTimeLLMTimeSeries2024,
  title = {Time-{{LLM}}: {{Time Series Forecasting}} by {{Reprogramming Large Language Models}}},
  shorttitle = {Time-{{LLM}}},
  author = {Jin, Ming and Wang, Shiyu and Ma, Lintao and Chu, Zhixuan and Zhang, James Y. and Shi, Xiaoming and Chen, Pin-Yu and Liang, Yuxuan and Li, Yuan-Fang and Pan, Shirui and Wen, Qingsong},
  year = {2024},
  month = jan,
  number = {arXiv:2310.01728},
  eprint = {2310.01728},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.01728},
  urldate = {2024-02-05},
  abstract = {Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process (NLP) and computer vision (CV), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in NLP and CV, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-LLM, a reprogramming framework to repurpose LLMs for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen LLM to align the two modalities. To augment the LLM's ability to reason with time series data, we propose Prompt-as-Prefix (PaP), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the LLM are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-LLM is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-LLM excels in both few-shot and zero-shot learning scenarios.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/F8UFZIYL/Jin et al. - 2024 - Time-LLM Time Series Forecasting by Reprogramming.pdf;/Users/nscherf/Zotero/storage/MSNKKAD3/2310.html}
}

@article{jonasCouldNeuroscientistUnderstand2017,
  ids = {jonasCouldNeuroscientistUnderstand2017a},
  title = {Could a {{Neuroscientist Understand}} a {{Microprocessor}}?},
  author = {Jonas, Eric and Kording, Konrad Paul},
  year = {2017},
  month = jan,
  journal = {PLOS Computational Biology},
  volume = {13},
  number = {1},
  pages = {e1005268},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005268},
  urldate = {2021-06-11},
  abstract = {There is a popular belief in neuroscience that we are primarily data limited, and that producing large, multimodal, and complex datasets will, with the help of advanced data analysis algorithms, lead to fundamental insights into the way the brain processes information. These datasets do not yet exist, and if they did we would have no way of evaluating whether or not the algorithmically-generated insights were sufficient or even correct. To address this, here we take a classical microprocessor as a model organism, and use our ability to perform arbitrary experiments on it to see if popular data analysis methods from neuroscience can elucidate the way it processes information. Microprocessors are among those artificial information processing systems that are both complex and that we understand at all levels, from the overall logical flow, via logical gates, to the dynamics of transistors. We show that the approaches reveal interesting structure in the data but do not meaningfully describe the hierarchy of information processing in the microprocessor. This suggests current analytic approaches in neuroscience may fall short of producing meaningful understanding of neural systems, regardless of the amount of data. Additionally, we argue for scientists using complex non-linear dynamical systems with known ground truth, such as the microprocessor as a validation platform for time-series and structure discovery methods.},
  langid = {english},
  keywords = {Behavior,Behavioral neuroscience,best-written-papers,Computational neuroscience,Connectomics,Microprocessors,Neuronal tuning,Neurons,Neuroscience,notion},
  file = {/Users/nscherf/Zotero/storage/V329GW3W/Jonas_Kording_2017_Could a Neuroscientist Understand a Microprocessor.pdf;/Users/nscherf/Zotero/storage/A7JKRV7R/article.html}
}

@article{juComprehensiveSurveyDeep2024,
  title = {A {{Comprehensive Survey}} on {{Deep Graph Representation Learning}}},
  author = {Ju, Wei and Fang, Zheng and Gu, Yiyang and Liu, Zequn and Long, Qingqing and Qiao, Ziyue and Qin, Yifang and Shen, Jianhao and Sun, Fang and Xiao, Zhiping and Yang, Junwei and Yuan, Jingyang and Zhao, Yusheng and Wang, Yifan and Luo, Xiao and Zhang, Ming},
  year = {2024},
  month = feb,
  journal = {Neural Networks},
  eprint = {2304.05055},
  primaryclass = {cs},
  pages = {106207},
  issn = {08936080},
  doi = {10.1016/j.neunet.2024.106207},
  urldate = {2024-03-04},
  abstract = {Graph representation learning aims to effectively encode high-dimensional sparse graph-structured data into low-dimensional dense vectors, which is a fundamental task that has been widely studied in a range of fields, including machine learning and data mining. Classic graph embedding methods follow the basic idea that the embedding vectors of interconnected nodes in the graph can still maintain a relatively close distance, thereby preserving the structural information between the nodes in the graph. However, this is sub-optimal due to: (i) traditional methods have limited model capacity which limits the learning performance; (ii) existing techniques typically rely on unsupervised learning strategies and fail to couple with the latest learning paradigms; (iii) representation learning and downstream tasks are dependent on each other which should be jointly enhanced. With the remarkable success of deep learning, deep graph representation learning has shown great potential and advantages over shallow (traditional) methods, there exist a large number of deep graph representation learning techniques have been proposed in the past decade, especially graph neural networks. In this survey, we conduct a comprehensive survey on current deep graph representation learning algorithms by proposing a new taxonomy of existing state-of-the-art literature. Specifically, we systematically summarize the essential components of graph representation learning and categorize existing approaches by the ways of graph neural network architectures and the most recent advanced learning paradigms. Moreover, this survey also provides the practical and promising applications of deep graph representation learning. Last but not least, we state new perspectives and suggest challenging directions which deserve further investigations in the future.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/E9W72ECU/Ju et al. - 2024 - A Comprehensive Survey on Deep Graph Representatio.pdf;/Users/nscherf/Zotero/storage/CZPGPKXV/2304.html}
}

@misc{katharopoulosTransformersAreRNNs2020,
  title = {Transformers Are {{RNNs}}: {{Fast Autoregressive Transformers}} with {{Linear Attention}}},
  shorttitle = {Transformers Are {{RNNs}}},
  author = {Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c c}ois},
  year = {2020},
  month = aug,
  number = {arXiv:2006.16236},
  eprint = {2006.16236},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2006.16236},
  urldate = {2024-01-30},
  abstract = {Transformers achieve remarkable performance in several tasks but due to their quadratic complexity, with respect to the input's length, they are prohibitively slow for very long sequences. To address this limitation, we express the self-attention as a linear dot-product of kernel feature maps and make use of the associativity property of matrix products to reduce the complexity from \${\textbackslash}mathcal\{O\}{\textbackslash}left(N\^{}2{\textbackslash}right)\$ to \${\textbackslash}mathcal\{O\}{\textbackslash}left(N{\textbackslash}right)\$, where \$N\$ is the sequence length. We show that this formulation permits an iterative implementation that dramatically accelerates autoregressive transformers and reveals their relationship to recurrent neural networks. Our linear transformers achieve similar performance to vanilla transformers and they are up to 4000x faster on autoregressive prediction of very long sequences.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/MBF7ZCKZ/Katharopoulos et al. - 2020 - Transformers are RNNs Fast Autoregressive Transfo.pdf;/Users/nscherf/Zotero/storage/8C3KGZML/2006.html}
}

@article{keinanCausalLocalizationNeural2004,
  title = {Causal Localization of Neural Function: The {{Shapley}} Value Method},
  shorttitle = {Causal Localization of Neural Function},
  author = {Keinan, Alon and Hilgetag, Claus C. and Meilijson, Isaac and Ruppin, Eytan},
  year = {2004},
  month = jun,
  journal = {Neurocomputing},
  series = {Computational {{Neuroscience}}: {{Trends}} in {{Research}} 2004},
  volume = {58--60},
  pages = {215--222},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2004.01.046},
  urldate = {2024-01-25},
  abstract = {Identifying the functional roles of elements of a neural network is one of the fundamental challenges in understanding neural information processing. Aiming at this goal, lesion studies have been used extensively in neuroscience. Most of these employ single lesions and hence, limited ability in revealing the significance of interacting elements. This paper presents the multi-perturbation Shapley value analysis (MSA), an axiomatic, scalable and rigorous method, addressing the challenge of determining the contributions of network elements from a data set of multi-lesions or other perturbations. The successful workings of the MSA are demonstrated on artificial and biological data. MSA is a novel method for causal function localization, with a wide range of potential applications for the analysis of reversible deactivation experiments and TMS-induced ``virtual lesions''.},
  keywords = {Contributions analysis,Interactions,Localization of function,Multi-lesions,Multi-perturbations,notion,Shapley value},
  file = {/Users/nscherf/Zotero/storage/QKXSLIG9/Keinan et al. - 2004 - Causal localization of neural function the Shaple.pdf;/Users/nscherf/Zotero/storage/9FJFGKS6/S0925231204000426.html}
}

@misc{kollingPointwiseRepresentationalSimilarity2023,
  title = {Pointwise {{Representational Similarity}}},
  author = {Kolling, Camila and Speicher, Till and Nanda, Vedant and Toneva, Mariya and Gummadi, Krishna P.},
  year = {2023},
  month = may,
  number = {arXiv:2305.19294},
  eprint = {2305.19294},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-11-10},
  abstract = {With the increasing reliance on deep neural networks, it is important to develop ways to better understand their learned representations. Representation similarity measures have emerged as a popular tool for examining learned representations However, existing measures only provide aggregate estimates of similarity at a global level, i.e. over a set of representations for N input examples. As such, these measures are not well-suited for investigating representations at a local level, i.e. representations of a single input example. Local similarity measures are needed, for instance, to understand which individual input representations are affected by training interventions to models (e.g. to be more fair and unbiased) or are at greater risk of being misclassified. In this work, we fill in this gap and propose Pointwise Normalized Kernel Alignment (PNKA), a measure that quantifies how similarly an individual input is represented in two representation spaces. Intuitively, PNKA compares the similarity of an input's neighborhoods across both spaces. Using our measure, we are able to analyze properties of learned representations at a finer granularity than what was previously possible. Concretely, we show how PNKA can be leveraged to develop a deeper understanding of (a) the input examples that are likely to be misclassified, (b) the concepts encoded by (individual) neurons in a layer, and (c) the effects of fairness interventions on learned representations.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/5X5V6YYR/Kolling et al. - 2023 - Pointwise Representational Similarity.pdf;/Users/nscherf/Zotero/storage/N5TPLA4D/2305.html}
}

@inproceedings{kornblithSimilarityNeuralNetwork2019,
  title = {Similarity of {{Neural Network Representations Revisited}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  year = {2019},
  month = may,
  pages = {3519--3529},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2021-07-28},
  abstract = {Recent work has sought to understand the behavior of neural networks by comparing representa- tions between layers and between different trained models. We examine methods for comparing neural network representations based on canonical correlation analysis (CCA). We show that CCA belongs to a family of statistics for measuring multivariate similarity, but that neither CCA nor any other statistic that is invariant to invertible linear transformation can measure meaningful similari- ties between representations of higher dimension than the number of data points. We introduce a similarity index that measures the relationship between representational similarity matrices and does not suffer from this limitation. This similarity index is equivalent to centered kernel align- ment (CKA) and is also closely connected to CCA. Unlike CCA, CKA can reliably identify correspondences between representations in networks trained from different initializations.},
  langid = {english},
  keywords = {ACONITE,BMBF,notion},
  file = {/Users/nscherf/Zotero/storage/UKXETR25/1905.00414.pdf}
}

@misc{kosinskiTheoryMindMight2023,
  title = {Theory of {{Mind Might Have Spontaneously Emerged}} in {{Large Language Models}}},
  author = {Kosinski, Michal},
  year = {2023},
  month = nov,
  number = {arXiv:2302.02083},
  eprint = {2302.02083},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.02083},
  urldate = {2024-02-09},
  abstract = {We explore the intriguing possibility that theory of mind (ToM), or the uniquely human ability to impute unobservable mental states to others, might have spontaneously emerged in large language models (LLMs). We designed 40 false-belief tasks, considered a gold standard in testing ToM in humans, and administered them to several LLMs. Each task included a false-belief scenario, three closely matched true-belief controls, and the reversed versions of all four. Smaller and older models solved no tasks; GPT-3-davinci-003 (from November 2022) and ChatGPT-3.5-turbo (from March 2023) solved 20\% of the tasks; ChatGPT-4 (from June 2023) solved 75\% of the tasks, matching the performance of six-year-old children observed in past studies. These findings suggest the intriguing possibility that ToM, previously considered exclusive to humans, may have spontaneously emerged as a byproduct of LLMs' improving language skills.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Human-Computer Interaction,notion},
  file = {/Users/nscherf/Zotero/storage/U3BVYMAF/Kosinski - 2023 - Theory of Mind Might Have Spontaneously Emerged in.pdf;/Users/nscherf/Zotero/storage/VVAQDXEY/2302.html}
}

@article{kriegeskorteInverseMDSInferring2012,
  title = {Inverse {{MDS}}: {{Inferring Dissimilarity Structure}} from {{Multiple Item Arrangements}}},
  shorttitle = {Inverse {{MDS}}},
  author = {Kriegeskorte, Nikolaus and Mur, Marieke},
  year = {2012},
  journal = {Frontiers in Psychology},
  volume = {3},
  issn = {1664-1078},
  urldate = {2023-12-08},
  abstract = {The pairwise dissimilarities of a set of items can be intuitively visualized by a 2D arrangement of the items, in which the distances reflect the dissimilarities. Such an arrangement can be obtained by multidimensional scaling (MDS). We propose a method for the inverse process: inferring the pairwise dissimilarities from multiple 2D arrangements of items. Perceptual dissimilarities are classically measured using pairwise dissimilarity judgments. However, alternative methods including free sorting and 2D arrangements have previously been proposed. The present proposal is novel (a) in that the dissimilarity matrix is estimated by ``inverse MDS'' based on multiple arrangements of item subsets, and (b) in that the subsets are designed by an adaptive algorithm that aims to provide optimal evidence for the dissimilarity estimates. The subject arranges the items (represented as icons on a computer screen) by means of mouse drag-and-drop operations. The multi-arrangement method can be construed as a generalization of simpler methods: It reduces to pairwise dissimilarity judgments if each arrangement contains only two items, and to free sorting if the items are categorically arranged into discrete piles. Multi-arrangement combines the advantages of these methods. It is efficient (because the subject communicates many dissimilarity judgments with each mouse drag), psychologically attractive (because dissimilarities are judged in context), and can characterize continuous high-dimensional dissimilarity structures. We present two procedures for estimating the dissimilarity matrix: a simple weighted-aligned-average of the partial dissimilarity matrices and a computationally intensive algorithm, which estimates the dissimilarity matrix by iteratively minimizing the error of MDS-predictions of the subject's arrangements. The Matlab code for interactive arrangement and dissimilarity estimation is available from the authors upon request.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/VCBUVNTS/Kriegeskorte and Mur - 2012 - Inverse MDS Inferring Dissimilarity Structure fro.pdf}
}

@article{kriegeskorteRepresentationalSimilarityAnalysis2008,
  title = {Representational Similarity Analysis - Connecting the Branches of Systems Neuroscience},
  author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
  year = {2008},
  journal = {Frontiers in Systems Neuroscience},
  volume = {2},
  pages = {4},
  issn = {1662-5137},
  doi = {10.3389/neuro.06.004.2008},
  urldate = {2021-08-24},
  abstract = {A fundamental challenge for systems neuroscience is to quantitatively relate its three major branches of research: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/UDIYI99S/Kriegeskorte et al. - 2008 - Representational similarity analysis - connecting .pdf}
}

@article{krioukovHyperbolicGeometryComplex2010,
  title = {Hyperbolic Geometry of Complex Networks},
  author = {Krioukov, Dmitri and Papadopoulos, Fragkiskos and Kitsak, Maksim and Vahdat, Amin and Bogu{\~n}{\'a}, Mari{\'a}n},
  year = {2010},
  month = sep,
  journal = {Physical Review E},
  volume = {82},
  number = {3},
  pages = {036106},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.82.036106},
  urldate = {2024-03-13},
  abstract = {We develop a geometric framework to study the structure and function of complex networks. We assume that hyperbolic geometry underlies these networks, and we show that with this assumption, heterogeneous degree distributions and strong clustering in complex networks emerge naturally as simple reflections of the negative curvature and metric property of the underlying hyperbolic geometry. Conversely, we show that if a network has some metric structure, and if the network degree distribution is heterogeneous, then the network has an effective hyperbolic geometry underneath. We then establish a mapping between our geometric framework and statistical mechanics of complex networks. This mapping interprets edges in a network as noninteracting fermions whose energies are hyperbolic distances between nodes, while the auxiliary fields coupled to edges are linear functions of these energies or distances. The geometric network ensemble subsumes the standard configuration model and classical random graphs as two limiting cases with degenerate geometric structures. Finally, we show that targeted transport processes without global topology knowledge, made possible by our geometric framework, are maximally efficient, according to all efficiency measures, in networks with strongest heterogeneity and clustering, and that this efficiency is remarkably robust with respect to even catastrophic disturbances and damages to the network structure.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/7DCFLEWA/Krioukov et al. - 2010 - Hyperbolic geometry of complex networks.pdf;/Users/nscherf/Zotero/storage/VJLNAYRF/PhysRevE.82.html}
}

@techreport{kubiliusCORnetModelingNeural2018,
  type = {Preprint},
  title = {{{CORnet}}: {{Modeling}} the {{Neural Mechanisms}} of {{Core Object Recognition}}},
  shorttitle = {{{CORnet}}},
  author = {Kubilius, Jonas and Schrimpf, Martin and Nayebi, Aran and Bear, Daniel and Yamins, Daniel L. K. and DiCarlo, James J.},
  year = {2018},
  month = sep,
  institution = {Neuroscience},
  doi = {10.1101/408385},
  urldate = {2022-04-11},
  abstract = {Abstract           Deep artificial neural networks with spatially repeated processing (a.k.a., deep convolutional ANNs) have been established as the best class of candidate models of visual processing in primate ventral visual processing stream. Over the past five years, these ANNs have evolved from a simple feedforward eight-layer architecture in AlexNet to extremely deep and branching NAS-Net architectures, demonstrating increasingly better object categorization performance and increasingly better explanatory power of both neural and behavioral responses. However, from the neuroscientist's point of view, the relationship between such very deep architectures and the ventral visual pathway is incomplete in at least two ways. On the one hand, current state-of-the-art ANNs appear to be too complex (e.g., now over 100 levels) compared with the relatively shallow cortical hierarchy (4-8 levels), which makes it difficult to map their elements to those in the ventral visual stream and to understand what they are doing. On the other hand, current state-of-the-art ANNs appear to be not complex enough in that they lack recurrent connections and the resulting neural response dynamics that are commonplace in the ventral visual stream. Here we describe our ongoing efforts to resolve both of these issues by developing a ``CORnet'' family of deep neural network architectures. Rather than just seeking high object recognition performance (as the state-of-the-art ANNs above), we instead try to reduce the model family to its most important elements and then gradually build new ANNs with recurrent and skip connections while monitoring both performance and the match between each new CORnet model and a large body of primate brain and behavioral data. We report here that our current best ANN model derived from this approach (CORnet-S) is among the top models on Brain-Score, a composite benchmark for comparing models to the brain, but is simpler than other deep ANNs in terms of the number of convolutions performed along the longest path of information processing in the model. All CORnet models are available at github.com/dicarlolab/CORnet, and we plan to up-date this manuscript and the available models in this family as they are produced.},
  langid = {english},
  keywords = {ACONITE,BMBF},
  file = {/Users/nscherf/Zotero/storage/3HXTB5H6/Kubilius et al. - 2018 - CORnet Modeling the Neural Mechanisms of Core Obj.pdf}
}

@misc{kuochProbingBiologicalArtificial2023,
  title = {Probing {{Biological}} and {{Artificial Neural Networks}} with {{Task-dependent Neural Manifolds}}},
  author = {Kuoch, Michael and Chou, Chi-Ning and Parthasarathy, Nikhil and Dapello, Joel and DiCarlo, James J. and Sompolinsky, Haim and Chung, SueYeon},
  year = {2023},
  month = dec,
  number = {arXiv:2312.14285},
  eprint = {2312.14285},
  primaryclass = {cs, q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.14285},
  urldate = {2024-01-29},
  abstract = {Recently, growth in our understanding of the computations performed in both biological and artificial neural networks has largely been driven by either low-level mechanistic studies or global normative approaches. However, concrete methodologies for bridging the gap between these levels of abstraction remain elusive. In this work, we investigate the internal mechanisms of neural networks through the lens of neural population geometry, aiming to provide understanding at an intermediate level of abstraction, as a way to bridge that gap. Utilizing manifold capacity theory (MCT) from statistical physics and manifold alignment analysis (MAA) from high-dimensional statistics, we probe the underlying organization of task-dependent manifolds in deep neural networks and macaque neural recordings. Specifically, we quantitatively characterize how different learning objectives lead to differences in the organizational strategies of these models and demonstrate how these geometric analyses are connected to the decodability of task-relevant information. These analyses present a strong direction for bridging mechanistic and normative theories in neural networks through neural population geometry, potentially opening up many future research avenues in both machine learning and neuroscience.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,notion,Quantitative Biology - Neurons and Cognition},
  file = {/Users/nscherf/Zotero/storage/LG7PECPJ/Kuoch et al. - 2023 - Probing Biological and Artificial Neural Networks .pdf;/Users/nscherf/Zotero/storage/Y9UAIW62/2312.html}
}

@article{lallyNeuralRepresentationsNaturalistic2023,
  title = {Neural Representations of Naturalistic Person Identities While Watching a Feature Film},
  author = {Lally, Clare and Lavan, Nadine and Garrido, Lucia and Tsantani, Maria and McGettigan, Carolyn},
  year = {2023},
  month = aug,
  journal = {Imaging Neuroscience},
  volume = {1},
  pages = {1--19},
  issn = {2837-6056},
  doi = {10.1162/imag_a_00009},
  urldate = {2023-11-23},
  abstract = {Recognising other people in naturalistic settings relies on differentiating between individuals (``telling apart''), as well as generalising across within-person variability (``telling together''; Burton, 2013; Lavan, Burston, \&amp; Garrido, 2019; Lavan, Burton, et al., 2019). However, previous neuroscientific investigations of face and voice recognition have tended to measure identity-related responses and representations using tightly controlled stimuli, thus under sampling the naturalistic variability encountered in everyday life. In this study, we tested whether cortical regions previously implicated in processing faces and voices represent identities during naturalistic and task-free stimulation. Representational similarity analyses were conducted on functional MRI datasets collected while human participants watched feature-length movies. Identity representations---defined as similar response patterns to variable instances of the same person (``telling together''), and dissimilar patterns in response to different people (``telling apart'')---were observed in established face and voice processing areas, across two independent participant groups viewing different sets of identities. We also explored contributions of face versus voice information to identity representations, finding more widespread preferential sensitivity to faces. We thus characterise how the brain represents identities in the real world, for the first-time accounting for both ``telling people together'' and ``telling people apart.'' Despite substantial differences to previous experimental research, our findings align with previous work, showing that similar brain areas are engaged in the representation of identities under experimental and naturalistic exposure.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/HPNQPS74/Lally et al. - 2023 - Neural representations of naturalistic person iden.pdf;/Users/nscherf/Zotero/storage/JX97Y8IM/Neural-representations-of-naturalistic-person.html}
}

@article{lamLearningSkillfulMediumrange2023,
  title = {Learning Skillful Medium-Range Global Weather Forecasting},
  author = {Lam, Remi and {Sanchez-Gonzalez}, Alvaro and Willson, Matthew and Wirnsberger, Peter and Fortunato, Meire and Alet, Ferran and Ravuri, Suman and Ewalds, Timo and {Eaton-Rosen}, Zach and Hu, Weihua and Merose, Alexander and Hoyer, Stephan and Holland, George and Vinyals, Oriol and Stott, Jacklynn and Pritzel, Alexander and Mohamed, Shakir and Battaglia, Peter},
  year = {2023},
  month = nov,
  journal = {Science},
  volume = {0},
  number = {0},
  pages = {eadi2336},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.adi2336},
  urldate = {2023-11-24},
  abstract = {Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy, but does not directly use historical weather data to improve the underlying model. Here, we introduce ``GraphCast,'' a machine learning-based method trained directly from reanalysis data. It predicts hundreds of weather variables, over 10 days at 0.25{$^\circ$} resolution globally, in under one minute. GraphCast significantly outperforms the most accurate operational deterministic systems on 90\% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclones tracking, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting, and helps realize the promise of machine learning for modeling complex dynamical systems.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/K9SJKYR5/Lam et al. - 2023 - Learning skillful medium-range global weather fore.pdf}
}

@inproceedings{laskinUnsupervisedReinforcementLearning2022,
  title = {Unsupervised {{Reinforcement Learning}} with {{Contrastive Intrinsic Control}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Laskin, Michael and Liu, Hao and Peng, Xue Bin and Yarats, Denis and Rajeswaran, Aravind and Abbeel, Pieter},
  year = {2022},
  month = may,
  urldate = {2023-11-11},
  abstract = {We introduce Contrastive Intrinsic Control (CIC), an unsupervised reinforcement learning (RL) algorithm that maximizes the mutual information between state-transitions and latent skill vectors. CIC utilizes contrastive learning between state-transitions and skills vectors to learn behaviour embeddings and maximizes the entropy of these embeddings as an intrinsic reward to encourage behavioural diversity. We evaluate our algorithm on the Unsupervised RL Benchmark (URLB) in the asymptotic state-based setting, which consists of a long reward-free pre-training phase followed by a short adaptation phase to downstream tasks with extrinsic rewards. We find that CIC improves over prior exploration algorithms in terms of adaptation efficiency to downstream tasks on state-based URLB.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/QGPFICNG/Laskin et al. - 2022 - Unsupervised Reinforcement Learning with Contrasti.pdf}
}

@article{lazebnikCanBiologistFix2002,
  title = {Can a Biologist Fix a Radio?--{{Or}}, What {{I}} Learned While Studying Apoptosis},
  shorttitle = {Can a Biologist Fix a Radio?},
  author = {Lazebnik, Yuri},
  year = {2002},
  month = sep,
  journal = {Cancer Cell},
  volume = {2},
  number = {3},
  pages = {179--182},
  issn = {1535-6108},
  doi = {10.1016/s1535-6108(02)00133-2},
  langid = {english},
  pmid = {12242150},
  keywords = {Apoptosis,best-written-papers,Biomedical Research,Interdisciplinary Communication,Models Biological,notion,Radio},
  file = {/Users/nscherf/Zotero/storage/WNDMRAAV/Lazebnik_2002_Can a biologist fix a radio.pdf}
}

@inproceedings{liJointGraphConvolution2022,
  title = {Joint {{Graph Convolution}} for~{{Analyzing Brain Structural}} and~{{Functional Connectome}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} -- {{MICCAI}} 2022},
  author = {Li, Yueting and Wei, Qingyue and Adeli, Ehsan and Pohl, Kilian M. and Zhao, Qingyu},
  editor = {Wang, Linwei and Dou, Qi and Fletcher, P. Thomas and Speidel, Stefanie and Li, Shuo},
  year = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {231--240},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-16431-6_22},
  abstract = {The white-matter (micro-)structural architecture of the brain promotes synchrony among neuronal populations, giving rise to richly patterned functional connections. A fundamental problem for systems neuroscience is determining the best way to relate structural and functional networks quantified by diffusion tensor imaging and resting-state functional MRI. As one of the state-of-the-art approaches for network analysis, graph convolutional networks (GCN) have been separately used to analyze functional and structural networks, but have not been applied to explore inter-network relationships. In this work, we propose to couple the two networks of an individual by adding inter-network edges between corresponding brain regions, so that the joint structure-function graph can be directly analyzed by a single GCN. The weights of inter-network edges are learnable, reflecting non-uniform structure-function coupling strength across the brain. We apply our Joint-GCN to predict age and sex of 662 participants from the public dataset of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) based on their functional and micro-structural white-matter networks. Our results support that the proposed Joint-GCN outperforms existing multi-modal graph learning approaches for analyzing structural and functional networks.},
  isbn = {978-3-031-16431-6},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/BTNQ6KL3/Li et al. - 2022 - Joint Graph Convolution forÂ Analyzing Brain Struct.pdf}
}

@article{linMultigroupAnalysisCompositions2024,
  title = {Multigroup Analysis of Compositions of Microbiomes with Covariate Adjustments and Repeated Measures},
  author = {Lin, Huang and Peddada, Shyamal Das},
  year = {2024},
  month = jan,
  journal = {Nature Methods},
  volume = {21},
  number = {1},
  pages = {83--91},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-023-02092-7},
  urldate = {2024-02-01},
  abstract = {Microbiome differential abundance analysis methods for two groups are well-established in the literature. However, many microbiome studies involve more than two groups, sometimes even ordered groups such as stages of a disease, and require different types of comparison. Standard pairwise comparisons are inefficient in terms of power and false discovery rates. In this Article, we propose a general framework, ANCOM-BC2, for performing a wide range of multigroup analyses with covariate adjustments and repeated measures. We illustrate our methodology through two real datasets. The first example explores the effects of aridity on the soil microbiome, and the second example investigates the effects of surgical interventions on the microbiome of patients with inflammatory bowel disease.},
  copyright = {2023 This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply},
  langid = {english},
  keywords = {Medical research,notion,Statistical methods},
  file = {/Users/nscherf/Zotero/storage/WMAEQKT4/Lin and Peddada - 2024 - Multigroup analysis of compositions of microbiomes.pdf}
}

@misc{linTopologyGeometryNeural2023,
  title = {The {{Topology}} and {{Geometry}} of {{Neural Representations}}},
  author = {Lin, Baihan and Kriegeskorte, Nikolaus},
  year = {2023},
  month = sep,
  number = {arXiv:2309.11028},
  eprint = {2309.11028},
  primaryclass = {cs, q-bio, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.11028},
  urldate = {2023-12-11},
  abstract = {A central question for neuroscience is how to characterize brain representations of perceptual and cognitive content. An ideal characterization should distinguish different functional regions with robustness to noise and idiosyncrasies of individual brains that do not correspond to computational differences. Previous studies have characterized brain representations by their representational geometry, which is defined by the representational dissimilarity matrix (RDM), a summary statistic that abstracts from the roles of individual neurons (or responses channels) and characterizes the discriminability of stimuli. Here we explore a further step of abstraction: from the geometry to the topology of brain representations. We propose topological representational similarity analysis (tRSA), an extension of representational similarity analysis (RSA) that uses a family of geo-topological summary statistics that generalizes the RDM to characterize the topology while de-emphasizing the geometry. We evaluate this new family of statistics in terms of the sensitivity and specificity for model selection using both simulations and functional MRI (fMRI) data. In the simulations, the ground truth is a data-generating layer representation in a neural network model and the models are the same and other layers in different model instances (trained from different random seeds). In fMRI, the ground truth is a visual area and the models are the same and other areas measured in different subjects. Results show that topology-sensitive characterizations of population codes are robust to noise and interindividual variability and maintain excellent sensitivity to the unique representational signatures of different neural network layers and brain regions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion,Quantitative Biology - Neurons and Cognition,Statistics - Methodology},
  file = {/Users/nscherf/Zotero/storage/SL5UNVSJ/Lin and Kriegeskorte - 2023 - The Topology and Geometry of Neural Representation.pdf;/Users/nscherf/Zotero/storage/WMS6QVK7/2309.html}
}

@misc{linVideoLLaVALearningUnited2023,
  title = {Video-{{LLaVA}}: {{Learning United Visual Representation}} by {{Alignment Before Projection}}},
  shorttitle = {Video-{{LLaVA}}},
  author = {Lin, Bin and Ye, Yang and Zhu, Bin and Cui, Jiaxi and Ning, Munan and Jin, Peng and Yuan, Li},
  year = {2023},
  month = nov,
  number = {arXiv:2311.10122},
  eprint = {2311.10122},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.10122},
  urldate = {2023-11-29},
  abstract = {The Large Vision-Language Model (LVLM) has enhanced the performance of various downstream tasks in visual-language understanding. Most existing approaches encode images and videos into separate feature spaces, which are then fed as inputs to large language models. However, due to the lack of unified tokenization for images and videos, namely misalignment before projection, it becomes challenging for a Large Language Model (LLM) to learn multi-modal interactions from several poor projection layers. In this work, we unify visual representation into the language feature space to advance the foundational LLM towards a unified LVLM. As a result, we establish a simple but robust LVLM baseline, Video-LLaVA, which learns from a mixed dataset of images and videos, mutually enhancing each other. Video-LLaVA achieves superior performances on a broad range of 9 image benchmarks across 5 image question-answering datasets and 4 image benchmark toolkits. Additionally, our Video-LLaVA also outperforms Video-ChatGPT by 5.8\%, 9.9\%, 18.6\%, and 10.1\% on MSRVTT, MSVD, TGIF, and ActivityNet, respectively. Notably, extensive experiments demonstrate that Video-LLaVA mutually benefits images and videos within a unified visual representation, outperforming models designed specifically for images or videos. We aim for this work to provide modest insights into the multi-modal inputs for the LLM.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,notion},
  file = {/Users/nscherf/Zotero/storage/KAWDHCLA/Lin et al. - 2023 - Video-LLaVA Learning United Visual Representation.pdf;/Users/nscherf/Zotero/storage/CVX35BIV/2311.html}
}

@article{liRealtimeDenoisingEnables2023,
  title = {Real-Time Denoising Enables High-Sensitivity Fluorescence Time-Lapse Imaging beyond the Shot-Noise Limit},
  author = {Li, Xinyang and Li, Yixin and Zhou, Yiliang and Wu, Jiamin and Zhao, Zhifeng and Fan, Jiaqi and Deng, Fei and Wu, Zhaofa and Xiao, Guihua and He, Jing and Zhang, Yuanlong and Zhang, Guoxun and Hu, Xiaowan and Chen, Xingye and Zhang, Yi and Qiao, Hui and Xie, Hao and Li, Yulong and Wang, Haoqian and Fang, Lu and Dai, Qionghai},
  year = {2023},
  month = feb,
  journal = {Nature Biotechnology},
  volume = {41},
  number = {2},
  pages = {282--292},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-022-01450-8},
  urldate = {2023-12-06},
  abstract = {A fundamental challenge in fluorescence microscopy is the photon shot noise arising from the inevitable stochasticity of photon detection. Noise increases measurement uncertainty and limits imaging resolution, speed and sensitivity. To achieve high-sensitivity fluorescence imaging beyond the shot-noise limit, we present DeepCAD-RT, a self-supervised deep learning method for real-time noise suppression. Based on our previous framework DeepCAD, we reduced the number of network parameters by 94\%, memory consumption by 27-fold and processing time by a factor of 20, allowing real-time processing on a two-photon microscope. A high imaging signal-to-noise ratio can be acquired with tenfold fewer photons than in standard imaging approaches. We demonstrate the utility of DeepCAD-RT in a series of photon-limited experiments, including in vivo calcium imaging of mice, zebrafish larva and fruit flies, recording of three-dimensional (3D) migration of neutrophils after acute brain injury and imaging of 3D dynamics of cortical ATP release. DeepCAD-RT will facilitate the morphological and functional interrogation of biological dynamics with a minimal photon budget.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Fluorescence imaging,Image processing,Microscopy,notion,Software},
  file = {/Users/nscherf/Zotero/storage/QPAWD4MJ/Li et al. - 2023 - Real-time denoising enables high-sensitivity fluor.pdf}
}

@article{liSpatialRedundancyTransformer2023,
  title = {Spatial Redundancy Transformer for Self-Supervised Fluorescence Image Denoising},
  author = {Li, Xinyang and Hu, Xiaowan and Chen, Xingye and Fan, Jiaqi and Zhao, Zhifeng and Wu, Jiamin and Wang, Haoqian and Dai, Qionghai},
  year = {2023},
  month = dec,
  journal = {Nature Computational Science},
  volume = {3},
  number = {12},
  pages = {1067--1080},
  publisher = {Nature Publishing Group},
  issn = {2662-8457},
  doi = {10.1038/s43588-023-00568-2},
  urldate = {2023-12-21},
  abstract = {Fluorescence imaging with high signal-to-noise ratios has become the foundation of accurate visualization and analysis of biological phenomena. However, the inevitable noise poses a formidable challenge to imaging sensitivity. Here we provide the spatial redundancy denoising transformer (SRDTrans) to remove noise from fluorescence images in a self-supervised manner. First, a sampling strategy based on spatial redundancy is proposed to extract adjacent orthogonal training pairs, which eliminates the dependence on high imaging speed. Second, we designed a lightweight spatiotemporal transformer architecture to capture long-range dependencies and high-resolution features at low computational cost. SRDTrans can restore high-frequency information without producing oversmoothed structures and distorted fluorescence traces. Finally, we demonstrate the state-of-the-art denoising performance of SRDTrans on single-molecule localization microscopy and two-photon volumetric calcium imaging. SRDTrans does not contain any assumptions about the imaging process and the sample, thus can be easily extended to various imaging modalities and biological applications.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Fluorescence imaging,Image processing,Microscopy,notion},
  file = {/Users/nscherf/Zotero/storage/5EVIN95F/Li et al. - 2023 - Spatial redundancy transformer for self-supervised.pdf}
}

@inproceedings{liuSeeingForestTree2022,
  title = {Seeing the Forest and the Tree: {{Building}} Representations of Both Individual and Collective Dynamics with Transformers},
  shorttitle = {Seeing the Forest and the Tree},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Liu, Ran and Azabou, Mehdi and Dabagia, Max and Xiao, Jingyun and Dyer, Eva L.},
  year = {2022},
  month = oct,
  urldate = {2022-12-13},
  abstract = {Complex time-varying systems are often studied by abstracting away from the dynamics of individual components to build a model of the population-level dynamics from the start. However, when building a population-level description, it can be easy to lose sight of each individual and how they contribute to the larger picture. In this paper, we present a novel transformer architecture for learning from time-varying data that builds descriptions of both the individual as well as the collective population dynamics. Rather than combining all of our data into our model at the onset, we develop a separable architecture that operates on individual time-series first before passing them forward; this induces a permutation-invariance property and can be used to transfer across systems of different size and order. After demonstrating that our model can be applied to successfully recover complex interactions and dynamics in many-body systems, we apply our approach to populations of neurons in the nervous system. On neural activity datasets, we show that our model not only yields robust decoding performance, but also provides impressive performance in transfer across recordings of different animals without any neuron-level correspondence. By enabling flexible pre-training that can be transferred to neural recordings of different size and order, our work provides a first step towards creating a foundation model for neural decoding.},
  langid = {english},
  keywords = {ACONITE,notion},
  file = {/Users/nscherf/Zotero/storage/CYAUTPEA/Liu et al_2022_Seeing the forest and the tree.pdf}
}

@inproceedings{locatelloChallengingCommonAssumptions2019,
  title = {Challenging {{Common Assumptions}} in the {{Unsupervised Learning}} of {{Disentangled Representations}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Locatello, Francesco and Bauer, Stefan and Lucic, Mario and Raetsch, Gunnar and Gelly, Sylvain and Sch{\"o}lkopf, Bernhard and Bachem, Olivier},
  year = {2019},
  month = may,
  pages = {4114--4124},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2024-02-08},
  abstract = {The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions. We first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than \$12000\$ models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/5RPYMKQG/Locatello et al. - 2019 - Challenging Common Assumptions in the Unsupervised.pdf}
}

@misc{luoDiffusionHyperfeaturesSearching2023,
  title = {Diffusion {{Hyperfeatures}}: {{Searching Through Time}} and {{Space}} for {{Semantic Correspondence}}},
  shorttitle = {Diffusion {{Hyperfeatures}}},
  author = {Luo, Grace and Dunlap, Lisa and Park, Dong Huk and Holynski, Aleksander and Darrell, Trevor},
  year = {2023},
  month = may,
  number = {arXiv:2305.14334},
  eprint = {2305.14334},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.14334},
  urldate = {2024-01-15},
  abstract = {Diffusion models have been shown to be capable of generating high-quality images, suggesting that they could contain meaningful internal representations. Unfortunately, the feature maps that encode a diffusion model's internal information are spread not only over layers of the network, but also over diffusion timesteps, making it challenging to extract useful descriptors. We propose Diffusion Hyperfeatures, a framework for consolidating multi-scale and multi-timestep feature maps into per-pixel feature descriptors that can be used for downstream tasks. These descriptors can be extracted for both synthetic and real images using the generation and inversion processes. We evaluate the utility of our Diffusion Hyperfeatures on the task of semantic keypoint correspondence: our method achieves superior performance on the SPair-71k real image benchmark. We also demonstrate that our method is flexible and transferable: our feature aggregation network trained on the inversion features of real image pairs can be used on the generation features of synthetic image pairs with unseen objects and compositions. Our code is available at {\textbackslash}url\{https://diffusion-hyperfeatures.github.io\}.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,notion},
  file = {/Users/nscherf/Zotero/storage/HYVRGX3R/Luo et al. - 2023 - Diffusion Hyperfeatures Searching Through Time an.pdf;/Users/nscherf/Zotero/storage/NES7QVDZ/2305.html}
}

@inproceedings{magaiDeepNeuralNetworks2023,
  title = {Deep {{Neural Networks Architectures}} from the {{Perspective}} of {{Manifold Learning}}},
  booktitle = {2023 {{IEEE}} 6th {{International Conference}} on {{Pattern Recognition}} and {{Artificial Intelligence}} ({{PRAI}})},
  author = {Magai, German},
  year = {2023},
  month = aug,
  pages = {1021--1031},
  doi = {10.1109/PRAI59366.2023.10331992},
  urldate = {2024-03-11},
  abstract = {Despite significant advances in the field of deep learning in applications to various areas, an explanation of the learning process of neural network models remains an important open question. The purpose of this paper is a comprehensive comparison and description of neural network architectures in terms of geometry and topology. We focus on the internal representation of neural networks and on the dynamics of changes in the topology and geometry of a data manifold on different layers. In this paper, we use the concepts of topological data analysis (TDA) and persistent homological fractal dimension. We present a wide range of experiments with various datasets and configurations of convolutional neural network (CNNs) architectures and transformers in CV and NLP tasks. Our work is a contribution to the development of the important field of explainable and interpretable AI within the framework of geometrical deep learning.},
  keywords = {Deep learning,Deep networks architectures,Geometry,manifold learning,Manifolds,Network topology,notion,Pattern recognition,performance evaluation,Representation learning,Topology,Transformers},
  file = {/Users/nscherf/Zotero/storage/Z6I6H78W/Magai - 2023 - Deep Neural Networks Architectures from the Perspe.pdf;/Users/nscherf/Zotero/storage/X9GZPPYX/10331992.html}
}

@misc{magaiTopologyGeometryData2022,
  title = {Topology and Geometry of Data Manifold in Deep Learning},
  author = {Magai, German and Ayzenberg, Anton},
  year = {2022},
  month = apr,
  number = {arXiv:2204.08624},
  eprint = {2204.08624},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2204.08624},
  urldate = {2024-02-28},
  abstract = {Despite significant advances in the field of deep learning in applications to various fields, explaining the inner processes of deep learning models remains an important and open question. The purpose of this article is to describe and substantiate the geometric and topological view of the learning process of neural networks. Our attention is focused on the internal representation of neural networks and on the dynamics of changes in the topology and geometry of the data manifold on different layers. We also propose a method for assessing the generalizing ability of neural networks based on topological descriptors. In this paper, we use the concepts of topological data analysis and intrinsic dimension, and we present a wide range of experiments on different datasets and different configurations of convolutional neural network architectures. In addition, we consider the issue of the geometry of adversarial attacks in the classification task and spoofing attacks on face recognition systems. Our work is a contribution to the development of an important area of explainable and interpretable AI through the example of computer vision.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Mathematics - Algebraic Topology,notion},
  file = {/Users/nscherf/Zotero/storage/W8LGKA9S/Magai and Ayzenberg - 2022 - Topology and geometry of data manifold in deep lea.pdf;/Users/nscherf/Zotero/storage/YE9HAK95/2204.html}
}

@article{maier-heinMetricsReloadedRecommendations2024,
  title = {Metrics Reloaded: Recommendations for Image Analysis Validation},
  shorttitle = {Metrics Reloaded},
  author = {{Maier-Hein}, Lena and Reinke, Annika and Godau, Patrick and Tizabi, Minu D. and Buettner, Florian and Christodoulou, Evangelia and Glocker, Ben and Isensee, Fabian and Kleesiek, Jens and Kozubek, Michal and Reyes, Mauricio and Riegler, Michael A. and Wiesenfarth, Manuel and Kavur, A. Emre and Sudre, Carole H. and Baumgartner, Michael and Eisenmann, Matthias and {Heckmann-N{\"o}tzel}, Doreen and R{\"a}dsch, Tim and Acion, Laura and Antonelli, Michela and Arbel, Tal and Bakas, Spyridon and Benis, Arriel and Blaschko, Matthew B. and Cardoso, M. Jorge and Cheplygina, Veronika and Cimini, Beth A. and Collins, Gary S. and Farahani, Keyvan and Ferrer, Luciana and Galdran, Adrian and {van Ginneken}, Bram and Haase, Robert and Hashimoto, Daniel A. and Hoffman, Michael M. and Huisman, Merel and Jannin, Pierre and Kahn, Charles E. and Kainmueller, Dagmar and Kainz, Bernhard and Karargyris, Alexandros and Karthikesalingam, Alan and Kofler, Florian and {Kopp-Schneider}, Annette and Kreshuk, Anna and Kurc, Tahsin and Landman, Bennett A. and Litjens, Geert and Madani, Amin and {Maier-Hein}, Klaus and Martel, Anne L. and Mattson, Peter and Meijering, Erik and Menze, Bjoern and Moons, Karel G. M. and M{\"u}ller, Henning and Nichyporuk, Brennan and Nickel, Felix and Petersen, Jens and Rajpoot, Nasir and Rieke, Nicola and {Saez-Rodriguez}, Julio and S{\'a}nchez, Clara I. and Shetty, Shravya and {van Smeden}, Maarten and Summers, Ronald M. and Taha, Abdel A. and Tiulpin, Aleksei and Tsaftaris, Sotirios A. and Van Calster, Ben and Varoquaux, Ga{\"e}l and J{\"a}ger, Paul F.},
  year = {2024},
  month = feb,
  journal = {Nature Methods},
  volume = {21},
  number = {2},
  pages = {195--212},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-023-02151-z},
  urldate = {2024-02-26},
  abstract = {Increasing evidence shows that flaws in machine learning (ML) algorithm validation are an underestimated global problem. In biomedical image analysis, chosen performance metrics often do not reflect the domain interest, and thus fail to adequately measure scientific progress and hinder translation of ML techniques into practice. To overcome this, we created Metrics Reloaded, a comprehensive framework guiding researchers in the problem-aware selection of metrics. Developed by a large international consortium in a multistage Delphi process, it is based on the novel concept of a problem fingerprint---a structured representation of the given problem that captures all aspects that are relevant for metric selection, from the domain interest to the properties of the target structure(s), dataset and algorithm output. On the basis of the problem fingerprint, users are guided through the process of choosing and applying appropriate validation metrics while being made aware of potential pitfalls. Metrics Reloaded targets image analysis problems that can be interpreted as classification tasks at image, object or pixel level, namely image-level classification, object detection, semantic segmentation and instance segmentation tasks. To improve the user experience, we implemented the framework in the Metrics Reloaded online tool. Following the convergence of ML methodology across application domains, Metrics Reloaded fosters the convergence of validation methodology. Its applicability is demonstrated for various biomedical use cases.},
  copyright = {2024 Springer Nature America, Inc.},
  langid = {english},
  keywords = {Education,Medical research,notion},
  file = {/Users/nscherf/Zotero/storage/CCSDQWSW/Maier-Hein et al. - 2024 - Metrics reloaded recommendations for image analys.pdf}
}

@misc{maSensoryPerceptualManifolds2023,
  title = {From {{Sensory}} to {{Perceptual Manifolds}}: {{The Twist}} of {{Neural Geometry}}},
  shorttitle = {From {{Sensory}} to {{Perceptual Manifolds}}},
  author = {Ma, Heng and Jiang, Longsheng and Liu, Tao and Liu, Jia},
  year = {2023},
  month = oct,
  primaryclass = {New Results},
  pages = {2023.10.02.559721},
  publisher = {bioRxiv},
  doi = {10.1101/2023.10.02.559721},
  urldate = {2024-01-19},
  abstract = {To humans, nearly everything is classifiable: whether as big or small, edible or poisonous, righteous or unjust. Similarly, classification is a central task in many machine learning applications, yet the problem of linear inseparability has long posed challenges for artificial neural networks since their inception. Here we asked how biological neural networks tackle this problem by investigating the geometric embedding of neural manifolds in macaques'V2 during orientation discrimination of motion-induced illusory contours. Specifically, we constructed a three-dimensional stimulus space that inherently made the orientation classification of these contours a linearly inseparable problem. As expected, we identified a sensory manifold, formed by the V2 neuron population, that faithfully corresponded to this stimulus space. Crucially, this sensory manifold underwent a series of twist operations, resulting in new axes orthogonal to the original ones. Within this expanded, high-dimensional perceptual manifold, the problem of linear inseparability became linearly separable. Computational models further revealed that the geometric twist operation was achieved by neurons exhibiting nonlinear mixed selectivity in networks with heterogeneous connectivity patterns. Taken together, our findings elucidate how perception arises from sensation through the lens of neural geometry, enriching our understanding of how cognitive functions derive from underlying anatomical structure.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/L2L5EIIP/Ma et al. - 2023 - From Sensory to Perceptual Manifolds The Twist of.pdf}
}

@article{maSpectralMethodAssessing2023,
  title = {A Spectral Method for Assessing and Combining Multiple Data Visualizations},
  author = {Ma, Rong and Sun, Eric D. and Zou, James},
  year = {2023},
  month = feb,
  journal = {Nature Communications},
  volume = {14},
  number = {1},
  pages = {780},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-36492-2},
  urldate = {2023-12-08},
  abstract = {Dimension reduction is an indispensable part of modern data science, and many algorithms have been developed. However, different algorithms have their own strengths and weaknesses, making it important to evaluate their relative performance, and to leverage and combine their individual strengths. This paper proposes a spectral method for assessing and combining multiple visualizations of a given dataset produced by diverse algorithms. The proposed method provides a quantitative measure -- the visualization eigenscore -- of the relative performance of the visualizations for preserving the structure around each data point. It also generates a consensus visualization, having improved quality over individual visualizations in capturing the underlying structure. Our approach is flexible and works as a wrapper around any visualizations. We analyze multiple real-world datasets to demonstrate the effectiveness of the method. We also provide theoretical justifications based on a general statistical framework, yielding several fundamental principles along with practical guidance.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Computer science,notion,Statistics},
  file = {/Users/nscherf/Zotero/storage/2JZL9ZLM/Ma et al. - 2023 - A spectral method for assessing and combining mult.pdf}
}

@article{mitchellHowWeKnow2023,
  title = {How Do We Know How Smart {{AI}} Systems Are?},
  author = {Mitchell, Melanie},
  year = {2023},
  month = jul,
  journal = {Science},
  volume = {381},
  number = {6654},
  pages = {adj5957},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.adj5957},
  urldate = {2023-08-08},
  keywords = {notion}
}

@article{mitchellTubULARTrackingToto2023,
  title = {{{TubULAR}}: Tracking in Toto Deformations of Dynamic Tissues via Constrained Maps},
  shorttitle = {{{TubULAR}}},
  author = {Mitchell, Noah P. and Cislo, Dillon J.},
  year = {2023},
  month = dec,
  journal = {Nature Methods},
  volume = {20},
  number = {12},
  pages = {1980--1988},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-023-02081-w},
  urldate = {2023-12-08},
  abstract = {A common motif in biology is the arrangement of cells into tubes, which further transform into complex shapes. Traditionally, analysis of dynamic tissues has relied on inspecting static snapshots, live imaging of cross-sections or tracking isolated cells in three dimensions. However, capturing the interplay between in-plane and out-of-plane behaviors requires following the full surface as it deforms and integrating cell-scale motions into collective, tissue-scale deformations. Here, we present an analysis framework that builds in toto maps of tissue deformations by following tissue parcels in a static material frame of reference. Our approach then relates in-plane and out-of-plane behaviors and decomposes complex deformation maps into elementary contributions. The tube-like surface Lagrangian analysis resource (TubULAR) provides an open-source implementation accessible either as a standalone toolkit or as an extension of the ImSAnE package used in the developmental biology community. We demonstrate our approach by analyzing shape change in the embryonic Drosophila midgut and beating zebrafish heart. The method naturally generalizes to in vitro and synthetic systems and provides ready access to the mechanical mechanisms relating genetic patterning to organ shape change.},
  copyright = {2023 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Computational biophysics,Image processing,Morphogenesis,notion,Organogenesis,Software},
  file = {/Users/nscherf/Zotero/storage/FEGSH45D/Mitchell and Cislo - 2023 - TubULAR tracking in toto deformations of dynamic .pdf}
}

@article{mooreOMENGFFNextgenerationFile2021,
  title = {{{OME-NGFF}}: A next-Generation File Format for Expanding Bioimaging Data-Access Strategies},
  shorttitle = {{{OME-NGFF}}},
  author = {Moore, Josh and Allan, Chris and Besson, S{\'e}bastien and Burel, Jean-Marie and Diel, Erin and Gault, David and Kozlowski, Kevin and Lindner, Dominik and Linkert, Melissa and Manz, Trevor and Moore, Will and Pape, Constantin and Tischer, Christian and Swedlow, Jason R.},
  year = {2021},
  month = dec,
  journal = {Nature Methods},
  volume = {18},
  number = {12},
  pages = {1496--1498},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-021-01326-w},
  urldate = {2023-11-29},
  abstract = {The rapid pace of innovation in biological imaging and the diversity of its applications have prevented the establishment of a community-agreed standardized data format. We propose that complementing established open formats such as OME-TIFF and HDF5 with a next-generation file format such as Zarr will satisfy the majority of use cases in bioimaging. Critically, a common metadata format used in all these vessels can deliver truly findable, accessible, interoperable and reusable bioimaging data.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Computational platforms and environments,Data publication and archiving,notion},
  file = {/Users/nscherf/Zotero/storage/AJESLI67/Moore et al. - 2021 - OME-NGFF a next-generation file format for expand.pdf}
}

@misc{morrisLevelsAGIOperationalizing2024,
  title = {Levels of {{AGI}}: {{Operationalizing Progress}} on the {{Path}} to {{AGI}}},
  shorttitle = {Levels of {{AGI}}},
  author = {Morris, Meredith Ringel and {Sohl-dickstein}, Jascha and Fiedel, Noah and Warkentin, Tris and Dafoe, Allan and Faust, Aleksandra and Farabet, Clement and Legg, Shane},
  year = {2024},
  month = jan,
  number = {arXiv:2311.02462},
  eprint = {2311.02462},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.02462},
  urldate = {2024-01-26},
  abstract = {We propose a framework for classifying the capabilities and behavior of Artificial General Intelligence (AGI) models and their precursors. This framework introduces levels of AGI performance, generality, and autonomy. It is our hope that this framework will be useful in an analogous way to the levels of autonomous driving, by providing a common language to compare models, assess risks, and measure progress along the path to AGI. To develop our framework, we analyze existing definitions of AGI, and distill six principles that a useful ontology for AGI should satisfy. These principles include focusing on capabilities rather than mechanisms; separately evaluating generality and performance; and defining stages along the path toward AGI, rather than focusing on the endpoint. With these principles in mind, we propose 'Levels of AGI' based on depth (performance) and breadth (generality) of capabilities, and reflect on how current systems fit into this ontology. We discuss the challenging requirements for future benchmarks that quantify the behavior and capabilities of AGI models against these levels. Finally, we discuss how these levels of AGI interact with deployment considerations such as autonomy and risk, and emphasize the importance of carefully selecting Human-AI Interaction paradigms for responsible and safe deployment of highly capable AI systems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,notion},
  file = {/Users/nscherf/Zotero/storage/25JKSNVT/Morris et al. - 2024 - Levels of AGI Operationalizing Progress on the Pa.pdf;/Users/nscherf/Zotero/storage/F7RZNDFV/2311.html}
}

@inproceedings{moschellaRelativeRepresentationsEnable2022,
  title = {Relative Representations Enable Zero-Shot Latent Space Communication},
  booktitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  author = {Moschella, Luca and Maiorca, Valentino and Fumero, Marco and Norelli, Antonio and Locatello, Francesco and Rodol{\`a}, Emanuele},
  year = {2022},
  month = sep,
  urldate = {2023-11-24},
  abstract = {Neural networks embed the geometric structure of a data manifold lying in a high-dimensional space into latent representations. Ideally, the distribution of the data points in the latent space should depend only on the task, the data, the loss, and other architecture-specific constraints. However, factors such as the random weights initialization, training hyperparameters, or other sources of randomness in the training phase may induce incoherent latent spaces that hinder any form of reuse. Nevertheless, we empirically observe that, under the same data and modeling choices, the angles between the encodings within distinct latent spaces do not change. In this work, we propose the latent similarity between each sample and a fixed set of anchors as an alternative data representation, demonstrating that it can enforce the desired invariances without any additional training. We show how neural architectures can leverage these relative representations to guarantee, in practice, invariance to latent isometries and rescalings, effectively enabling latent space communication: from zero-shot model stitching to latent space comparison between diverse settings. We extensively validate the generalization capability of our approach on different datasets, spanning various modalities (images, text, graphs), tasks (e.g., classification, reconstruction) and architectures (e.g., CNNs, GCNs, transformers).},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/72XFVIGH/Moschella et al. - 2022 - Relative representations enable zero-shot latent s.pdf}
}

@misc{muttenthalerVICEVariationalInterpretable2022,
  title = {{{VICE}}: {{Variational Interpretable Concept Embeddings}}},
  shorttitle = {{{VICE}}},
  author = {Muttenthaler, Lukas and Zheng, Charles Y. and McClure, Patrick and Vandermeulen, Robert A. and Hebart, Martin N. and Pereira, Francisco},
  year = {2022},
  month = oct,
  number = {arXiv:2205.00756},
  eprint = {2205.00756},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.00756},
  urldate = {2024-01-05},
  abstract = {A central goal in the cognitive sciences is the development of numerical models for mental representations of object concepts. This paper introduces Variational Interpretable Concept Embeddings (VICE), an approximate Bayesian method for embedding object concepts in a vector space using data collected from humans in a triplet odd-one-out task. VICE uses variational inference to obtain sparse, non-negative representations of object concepts with uncertainty estimates for the embedding values. These estimates are used to automatically select the dimensions that best explain the data. We derive a PAC learning bound for VICE that can be used to estimate generalization performance or determine a sufficient sample size for experimental design. VICE rivals or outperforms its predecessor, SPoSE, at predicting human behavior in the triplet odd-one-out task. Furthermore, VICE's object representations are more reproducible and consistent across random initializations, highlighting the unique advantage of using VICE for deriving interpretable embeddings from human behavior.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion,Statistics - Applications,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/2FCYKT6V/Muttenthaler et al. - 2022 - VICE Variational Interpretable Concept Embeddings.pdf;/Users/nscherf/Zotero/storage/FQSGN2VF/2205.html}
}

@article{nestorInteractionsCulturableBacteria2023,
  title = {Interactions between {{Culturable Bacteria Are Predicted}} by {{Individual Species}}' {{Growth}}},
  author = {Nestor, Einat and Toledano, Gal and Friedman, Jonathan},
  year = {2023},
  month = feb,
  journal = {mSystems},
  volume = {8},
  number = {2},
  pages = {e00836-22},
  publisher = {American Society for Microbiology},
  doi = {10.1128/msystems.00836-22},
  urldate = {2023-11-27},
  abstract = {Predicting interspecies interactions is a key challenge in microbial ecology given that interactions shape the composition and functioning of microbial communities. However, predicting microbial interactions is challenging because they can vary considerably depending on species' metabolic capabilities and environmental conditions. Here, we employ machine learning models to predict pairwise interactions between culturable bacteria based on their phylogeny, monoculture growth capabilities, and interactions with other species. We trained our models on one of the largest available pairwise interactions data set containing over 7,500 interactions between 20 species from two taxonomic groups that were cocultured in 40 different carbon environments. Our models accurately predicted both the sign (accuracy of 88\%) and the strength of effects (R2 of 0.87) species had on each other's growth. Encouragingly, predictions with comparable accuracy could be made even when not relying on information about interactions with other species, which are often hard to measure. However, species' monoculture growth was essential to the model, as predictions based solely on species' phylogeny and inferred metabolic capabilities were significantly less accurate. These results bring us one step closer to a predictive understanding of microbial communities, which is essential for engineering beneficial microbial consortia. IMPORTANCE In order to understand the function and structure of microbial communities, one must know all pairwise interactions that occur between the different species within the community, as these interactions shape the community's structure and functioning. However, measuring all pairwise interactions can be an extremely difficult task especially when dealing with big complex communities. Because of that, predicting interspecies interactions is a key challenge in microbial ecology. Here, we use machine learning models in order to accurately predict the type and strength of interactions. We trained our models on one of the largest available pairwise interactions data set, containing over 7,500 interactions between 20 different species that were cocultured in 40 different environments. Our results show that, in general, accurate predictions can be made, and that the ability of each species to grow on its own in the given environment contributes the most to predictions. Being able to predict microbial interactions would put us one step closer to predicting the functionality of microbial communities and to rationally microbiome engineering.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/MGPIZV9E/Nestor et al. - 2023 - Interactions between Culturable Bacteria Are Predi.pdf}
}

@article{nielsenElementaryIntroductionInformation2020,
  title = {An {{Elementary Introduction}} to {{Information Geometry}}},
  author = {Nielsen, Frank},
  year = {2020},
  month = oct,
  journal = {Entropy},
  volume = {22},
  number = {10},
  pages = {1100},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1099-4300},
  doi = {10.3390/e22101100},
  urldate = {2024-01-11},
  abstract = {In this survey, we describe the fundamental differential-geometric structures of information manifolds, state the fundamental theorem of information geometry, and illustrate some use cases of these information manifolds in information sciences. The exposition is self-contained by concisely introducing the necessary concepts of differential geometry. Proofs are omitted for brevity.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {-embeddings,affine connection,Bayesian hypothesis testing,conjugate connections,curvature and flatness,differential geometry,dual metric-compatible parallel transport,dually flat manifolds,exponential family,Fisher-Rao distance,gauge freedom,Hessian manifolds,information manifold,metric compatibility,metric tensor,mixed parameterization,mixture clustering,mixture family,notion,parameter divergence,separable divergence,statistical divergence,statistical invariance,statistical manifold},
  file = {/Users/nscherf/Zotero/storage/7WZGQE2B/Nielsen - 2020 - An Elementary Introduction to Information Geometry.pdf}
}

@misc{ostrowGeometryComparingTemporal2023,
  title = {Beyond {{Geometry}}: {{Comparing}} the {{Temporal Structure}} of {{Computation}} in {{Neural Circuits}} with {{Dynamical Similarity Analysis}}},
  shorttitle = {Beyond {{Geometry}}},
  author = {Ostrow, Mitchell and Eisen, Adam and Kozachkov, Leo and Fiete, Ila},
  year = {2023},
  month = aug,
  number = {arXiv:2306.10168},
  eprint = {2306.10168},
  primaryclass = {cs, q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.10168},
  urldate = {2023-09-08},
  abstract = {How can we tell whether two neural networks are utilizing the same internal processes for a particular computation? This question is pertinent for multiple subfields of both neuroscience and machine learning, including neuroAI, mechanistic interpretability, and brain-machine interfaces. Standard approaches for comparing neural networks focus on the spatial geometry of latent states. Yet in recurrent networks, computations are implemented at the level of neural dynamics, which do not have a simple one-to-one mapping with geometry. To bridge this gap, we introduce a novel similarity metric that compares two systems at the level of their dynamics. Our method incorporates two components: Using recent advances in data-driven dynamical systems theory, we learn a high-dimensional linear system that accurately captures core features of the original nonlinear dynamics. Next, we compare these linear approximations via a novel extension of Procrustes Analysis that accounts for how vector fields change under orthogonal transformation. Via four case studies, we demonstrate that our method effectively identifies and distinguishes dynamic structure in recurrent neural networks (RNNs), whereas geometric methods fall short. We additionally show that our method can distinguish learning rules in an unsupervised manner. Our method therefore opens the door to novel data-driven analyses of the temporal structure of neural computation, and to more rigorous testing of RNNs as models of the brain.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,notion,Quantitative Biology - Neurons and Cognition,Quantitative Biology - Quantitative Methods},
  file = {/Users/nscherf/Zotero/storage/7AYTKN6T/Ostrow et al. - 2023 - Beyond Geometry Comparing the Temporal Structure .pdf;/Users/nscherf/Zotero/storage/LP6DIZIW/2306.html}
}

@article{pangGeometricConstraintsHuman2023,
  title = {Geometric Constraints on Human Brain Function},
  author = {Pang, James C. and Aquino, Kevin M. and Oldehinkel, Marianne and Robinson, Peter A. and Fulcher, Ben D. and Breakspear, Michael and Fornito, Alex},
  year = {2023},
  month = jun,
  journal = {Nature},
  volume = {618},
  number = {7965},
  pages = {566--574},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06098-1},
  urldate = {2023-06-15},
  abstract = {The anatomy of the brain necessarily~constrains its function, but precisely how remains unclear. The classical and dominant paradigm in neuroscience is that neuronal dynamics are driven by interactions between discrete, functionally specialized cell populations connected by a complex array of axonal fibres1--3. However, predictions from neural field theory, an established mathematical framework for modelling large-scale brain activity4--6, suggest that the geometry of the brain may represent a more fundamental constraint on dynamics than complex interregional connectivity7,8. Here, we confirm these theoretical predictions by analysing human magnetic resonance imaging data acquired under spontaneous and diverse task-evoked conditions. Specifically, we show that cortical and subcortical activity can be parsimoniously understood as resulting from excitations of fundamental, resonant modes of the brain's geometry (that is, its shape) rather than from modes of complex interregional connectivity, as classically assumed. We then use these geometric modes to show that task-evoked activations across over 10,000 brain maps are not confined to focal areas, as widely believed, but instead excite brain-wide modes with wavelengths spanning over 60\,mm. Finally, we confirm predictions that the close link between geometry and function is explained by a dominant role for wave-like activity, showing that wave dynamics can reproduce numerous canonical spatiotemporal properties of spontaneous and evoked recordings. Our findings challenge prevailing views and identify a previously underappreciated role of geometry in shaping function, as predicted by a unifying and physically principled model of brain-wide dynamics.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Cognitive neuroscience,Computational neuroscience,notion},
  file = {/Users/nscherf/Zotero/storage/Y6VEKL5R/Pang et al. - 2023 - Geometric constraints on human brain function.pdf}
}

@misc{pangReplyCommentaryPang2023,
  title = {Reply to: {{Commentary}} on {{Pang}} et al. (2023) {{Nature}}},
  shorttitle = {Reply To},
  author = {Pang, James C. and Aquino, Kevin M. and Oldehinkel, Marianne and Robinson, Peter A. and Fulcher, Ben D. and Breakspear, Michael and Fornito, Alex},
  year = {2023},
  month = oct,
  primaryclass = {Contradictory Results},
  pages = {2023.10.06.560797},
  publisher = {bioRxiv},
  doi = {10.1101/2023.10.06.560797},
  urldate = {2023-10-17},
  abstract = {In Pang et al. (2023)1, we identified a close link between the geometry and function of the human brain by showing that: (1) eigenmodes derived from cortical geometry parsimoniously reconstruct activity patterns recorded with functional magnetic resonance imaging (fMRI); (2) task-evoked cortical activity results from excitations of brain-wide modes with long wavelengths; (3) wave dynamics, constrained by geometry and distance-dependent connectivity, can account for diverse aspects of spontaneous and evoked brain activity; and (4) geometry and function are strongly coupled in the subcortex. Faskowitz et al. (2023)2 raise concerns about the framing of our paper and the specificity of the eigenmode reconstructions in result (1). Here, we address these concerns and show how specificity is established by using appropriate benchmarks.},
  archiveprefix = {bioRxiv},
  chapter = {Contradictory Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/C3MB2DVQ/Pang et al. - 2023 - Reply to Commentary on Pang et al. (2023) Nature.pdf}
}

@misc{papamarkouPositionPaperChallenges2024,
  title = {Position {{Paper}}: {{Challenges}} and {{Opportunities}} in {{Topological Deep Learning}}},
  shorttitle = {Position {{Paper}}},
  author = {Papamarkou, Theodore and Birdal, Tolga and Bronstein, Michael and Carlsson, Gunnar and Curry, Justin and Gao, Yue and Hajij, Mustafa and Kwitt, Roland and Li{\`o}, Pietro and Di Lorenzo, Paolo and Maroulas, Vasileios and Miolane, Nina and Nasrin, Farzana and Ramamurthy, Karthikeyan Natesan and Rieck, Bastian and Scardapane, Simone and Schaub, Michael T. and Veli{\v c}kovi{\'c}, Petar and Wang, Bei and Wang, Yusu and Wei, Guo-Wei and Zamzmi, Ghada},
  year = {2024},
  month = feb,
  number = {arXiv:2402.08871},
  eprint = {2402.08871},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.08871},
  urldate = {2024-03-14},
  abstract = {Topological deep learning (TDL) is a rapidly evolving field that uses topological features to understand and design deep learning models. This paper posits that TDL may complement graph representation learning and geometric deep learning by incorporating topological concepts, and can thus provide a natural choice for various machine learning settings. To this end, this paper discusses open problems in TDL, ranging from practical benefits to theoretical foundations. For each problem, it outlines potential solutions and future research opportunities. At the same time, this paper serves as an invitation to the scientific community to actively participate in TDL research to unlock the potential of this emerging field.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/CASDWKSS/Papamarkou et al. - 2024 - Position Paper Challenges and Opportunities in To.pdf;/Users/nscherf/Zotero/storage/NK5SMUM3/2402.html}
}

@article{parisotSpectralGraphConvolutions2017,
  title = {Spectral {{Graph Convolutions}} for {{Population-based Disease Prediction}}},
  author = {Parisot, Sarah and Ktena, Sofia Ira and Ferrante, Enzo and Lee, Matthew and Moreno, Ricardo Guerrerro and Glocker, Ben and Rueckert, Daniel},
  year = {2017},
  month = jun,
  journal = {arXiv:1703.03020 [cs, stat]},
  eprint = {1703.03020},
  primaryclass = {cs, stat},
  urldate = {2022-03-10},
  abstract = {Exploiting the wealth of imaging and non-imaging information for disease prediction tasks requires models capable of representing, at the same time, individual features as well as data associations between subjects from potentially large populations. Graphs provide a natural framework for such tasks, yet previous graph-based approaches focus on pairwise similarities without modelling the subjects' individual characteristics and features. On the other hand, relying solely on subject-specific imaging feature vectors fails to model the interaction and similarity between subjects, which can reduce performance. In this paper, we introduce the novel concept of Graph Convolutional Networks (GCN) for brain analysis in populations, combining imaging and non-imaging data. We represent populations as a sparse graph where its vertices are associated with image-based feature vectors and the edges encode phenotypic information. This structure was used to train a GCN model on partially labelled graphs, aiming to infer the classes of unlabelled nodes from the node features and pairwise associations between subjects. We demonstrate the potential of the method on the challenging ADNI and ABIDE databases, as a proof of concept of the benefit from integrating contextual information in classification tasks. This has a clear impact on the quality of the predictions, leading to 69.5\% accuracy for ABIDE (outperforming the current state of the art of 66.8\%) and 77\% for ADNI for prediction of MCI conversion, significantly outperforming standard linear classifiers where only individual features are considered.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,notion,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/D85LGRSA/Parisot et al_2017_Spectral Graph Convolutions for Population-based Disease Prediction.pdf;/Users/nscherf/Zotero/storage/QNZHHZAV/1703.html}
}

@article{parkAutomatedNeuronTracking2024a,
  title = {Automated Neuron Tracking inside Moving and Deforming {{C}}. Elegans Using Deep Learning and Targeted Augmentation},
  author = {Park, Core Francisco and {Barzegar-Keshteli}, Mahsa and Korchagina, Kseniia and Delrocq, Ariane and Susoy, Vladislav and Jones, Corinne L. and Samuel, Aravinthan D. T. and Rahi, Sahand Jamal},
  year = {2024},
  month = jan,
  journal = {Nature Methods},
  volume = {21},
  number = {1},
  pages = {142--149},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-023-02096-3},
  urldate = {2024-02-01},
  abstract = {Reading out neuronal activity from three-dimensional (3D) functional imaging requires segmenting and tracking individual neurons. This is challenging in behaving animals if the brain moves and deforms. The traditional approach is to train a convolutional neural network with ground-truth (GT) annotations of images representing different brain postures. For 3D images, this is very labor intensive. We introduce `targeted augmentation', a method to automatically synthesize artificial annotations from a few manual annotations. Our method (`Targettrack') learns the internal deformations of the brain to synthesize annotations for new postures by deforming GT annotations. This reduces the need for manual annotation and proofreading. A graphical user interface allows the application of the method end-to-end. We demonstrate Targettrack on recordings where neurons are labeled as key points or 3D volumes. Analyzing freely moving animals exposed to odor pulses, we uncover rich patterns in interneuron dynamics, including switching neuronal entrainment on and off.},
  copyright = {2023 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Cellular neuroscience,Computational neuroscience,Fluorescence imaging,Image processing,notion},
  file = {/Users/nscherf/Zotero/storage/8W3FKDIF/Park et al. - 2024 - Automated neuron tracking inside moving and deform.pdf}
}

@misc{parkesUsingNetworkControl2023,
  title = {Using Network Control Theory to Study the Dynamics of the Structural Connectome},
  author = {Parkes, Linden and Kim, Jason Z. and Stiso, Jennifer and Brynildsen, Julia K. and Cieslak, Matthew and Covitz, Sydney and Gur, Raquel E. and Gur, Ruben C. and Pasqualetti, Fabio and Shinohara, Russell T. and Zhou, Dale and Satterthwaite, Theodore D. and Bassett, Dani S.},
  year = {2023},
  month = aug,
  primaryclass = {Confirmatory Results},
  pages = {2023.08.23.554519},
  publisher = {bioRxiv},
  doi = {10.1101/2023.08.23.554519},
  urldate = {2023-10-16},
  abstract = {Network control theory (NCT) is a simple and powerful tool for studying how network topology informs and constrains dynamics. Compared to other structure-function coupling approaches, the strength of NCT lies in its capacity to predict the patterns of external control signals that may alter dynamics in a desired way. We have extensively developed and validated the application of NCT to the human structural connectome. Through these efforts, we have studied (i) how different aspects of connectome topology affect neural dynamics, (ii) whether NCT outputs cohere with empirical data on brain function and stimulation, and (iii) how NCT outputs vary across development and correlate with behavior and mental health symptoms. In this protocol, we introduce a framework for applying NCT to structural connectomes following two main pathways. Our primary pathway focuses on computing the control energy associated with transitioning between specific neural activity states. Our second pathway focuses on computing average controllability, which indexes nodes' general capacity to control dynamics. We also provide recommendations for comparing NCT outputs against null network models. Finally, we support this protocol with a Python-based software package called network control theory for python (nctpy).},
  archiveprefix = {bioRxiv},
  chapter = {Confirmatory Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/RRL9UW8R/Parkes et al. - 2023 - Using network control theory to study the dynamics.pdf}
}

@article{parkPapersPatentsAre2023,
  title = {Papers and Patents Are Becoming Less Disruptive over Time},
  author = {Park, Michael and Leahey, Erin and Funk, Russell J.},
  year = {2023},
  month = jan,
  journal = {Nature},
  volume = {613},
  number = {7942},
  pages = {138--144},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-022-05543-x},
  urldate = {2024-01-02},
  abstract = {Theories of scientific and technological change view discovery and invention as endogenous processes1,2, wherein previous accumulated knowledge enables future progress by allowing researchers to, in Newton's words, `stand on the shoulders of giants'3--7. Recent decades have witnessed exponential growth in the volume of new scientific and technological knowledge, thereby creating conditions that should be ripe for major advances8,9. Yet contrary to this view, studies suggest that progress is slowing in several major fields10,11. Here, we analyse these claims at scale across six decades, using data on 45\,million papers and 3.9\,million patents from six large-scale datasets, together with a new quantitative metric---the CD index12---that characterizes how papers and patents change networks of citations in science and technology. We find that papers and patents are increasingly less likely to break with the past in ways that push science and technology in new directions. This pattern holds universally across fields and is robust across multiple different citation- and text-based metrics1,13--17. Subsequently, we link this decline in disruptiveness to a narrowing in the use of previous knowledge, allowing us to reconcile the patterns we observe with the `shoulders of giants' view. We find that the observed declines are unlikely to be driven by changes in the quality of published science, citation practices or field-specific factors. Overall, our results suggest that slowing rates of disruption may reflect a fundamental shift in the nature of science and technology.},
  copyright = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Economics,notion,Scientific community,Sociology,Technology},
  file = {/Users/nscherf/Zotero/storage/7RH3ISA7/Park et al. - 2023 - Papers and patents are becoming less disruptive ov.pdf}
}

@inproceedings{pinayaFastUnsupervisedBrain2022,
  title = {Fast {{Unsupervised Brain Anomaly Detection}} and~{{Segmentation}} with~{{Diffusion Models}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} -- {{MICCAI}} 2022},
  author = {Pinaya, Walter H. L. and Graham, Mark S. and Gray, Robert and {da Costa}, Pedro F. and Tudosiu, Petru-Daniel and Wright, Paul and Mah, Yee H. and MacKinnon, Andrew D. and Teo, James T. and Jager, Rolf and Werring, David and Rees, Geraint and Nachev, Parashkev and Ourselin, Sebastien and Cardoso, M. Jorge},
  editor = {Wang, Linwei and Dou, Qi and Fletcher, P. Thomas and Speidel, Stefanie and Li, Shuo},
  year = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {705--714},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-16452-1_67},
  abstract = {Deep generative models have emerged as promising tools for detecting arbitrary anomalies in data, dispensing with the necessity for manual labelling. Recently, autoregressive transformers have achieved state-of-the-art performance for anomaly detection in medical imaging. Nonetheless, these models still have some intrinsic weaknesses, such as requiring images to be modelled as 1D sequences, the accumulation of errors during the sampling process, and the significant inference times associated with transformers. Denoising diffusion probabilistic models are a class of non-autoregressive generative models recently shown to produce excellent samples in computer vision (surpassing Generative Adversarial Networks), and to achieve log-likelihoods that are competitive with transformers while having relatively fast inference times. Diffusion models can be applied to the latent representations learnt by autoencoders, making them easily scalable and great candidates for application to high dimensional data, such as medical images. Here, we propose a method based on diffusion models to detect and segment anomalies in brain imaging. By training the models on healthy data and then exploring its diffusion and reverse steps across its Markov chain, we can identify anomalous areas in the latent space and hence identify anomalies in the pixel space. Our diffusion models achieve competitive performance compared with autoregressive approaches across a series of experiments with 2D CT and MRI data involving synthetic and real pathological lesions with much reduced inference times, making their usage clinically viable.},
  isbn = {978-3-031-16452-1},
  langid = {english},
  keywords = {Denoising diffusion probabilistic models,Lesion segmentation,Neuroimaging,notion,Out-of-distribution detection,Unsupervised anomaly detection},
  file = {/Users/nscherf/Zotero/storage/XYEEH2NK/Pinaya et al. - 2022 - Fast Unsupervised Brain Anomaly Detection andÂ Segm.pdf}
}

@misc{pioroMoEMambaEfficientSelective2024,
  title = {{{MoE-Mamba}}: {{Efficient Selective State Space Models}} with {{Mixture}} of {{Experts}}},
  shorttitle = {{{MoE-Mamba}}},
  author = {Pi{\'o}ro, Maciej and Ciebiera, Kamil and Kr{\'o}l, Krystian and Ludziejewski, Jan and Jaszczur, Sebastian},
  year = {2024},
  month = jan,
  number = {arXiv:2401.04081},
  eprint = {2401.04081},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.04081},
  urldate = {2024-01-18},
  abstract = {State Space Models (SSMs) have become serious contenders in the field of sequential modeling, challenging the dominance of Transformers. At the same time, Mixture of Experts (MoE) has significantly improved Transformer-based LLMs, including recent state-of-the-art open-source models. We propose that to unlock the potential of SSMs for scaling, they should be combined with MoE. We showcase this on Mamba, a recent SSM-based model that achieves remarkable, Transformer-like performance. Our model, MoE-Mamba, outperforms both Mamba and Transformer-MoE. In particular, MoE-Mamba reaches the same performance as Mamba in 2.2x less training steps while preserving the inference performance gains of Mamba against the Transformer.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/UT9FC5BU/PiÃ³ro et al. - 2024 - MoE-Mamba Efficient Selective State Space Models .pdf;/Users/nscherf/Zotero/storage/SY46DG2F/2401.html}
}

@article{purvineExperimentalObservationsTopology2023,
  title = {Experimental {{Observations}} of the {{Topology}} of {{Convolutional Neural Network Activations}}},
  author = {Purvine, Emilie and Brown, Davis and Jefferson, Brett and Joslyn, Cliff and Praggastis, Brenda and Rathore, Archit and Shapiro, Madelyn and Wang, Bei and Zhou, Youjia},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {8},
  pages = {9470--9479},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v37i8.26134},
  urldate = {2023-12-06},
  abstract = {Topological data analysis (TDA) is a branch of computational mathematics, bridging algebraic topology and data science, that provides compact, noise-robust representations of complex structures. Deep neural networks (DNNs) learn millions of parameters associated with a series of transformations defined by the model architecture, resulting in highdimensional, difficult-to-interpret internal representations of input data. As DNNs become more ubiquitous across multiple sectors of our society, there is increasing recognition that mathematical methods are needed to aid analysts, researchers, and practitioners in understanding and interpreting how these models' internal representations relate to the final classification. In this paper, we apply cutting edge techniques from TDA with the goal of gaining insight into the interpretability of convolutional neural networks used for image classification. We use two common TDA approaches to explore several methods for modeling hidden-layer activations as high-dimensional point clouds, and provide experimental evidence that these point clouds capture valuable structural information about the model's process. First, we demonstrate that a distance metric based on persistent homology can be used to quantify meaningful differences between layers, and we discuss these distances in the broader context of existing representational similarity metrics for neural network interpretability. Second, we show that a mapper graph can provide semantic insight into how these models organize hierarchical class knowledge at each layer. These observations demonstrate that TDA is a useful tool to help deep learning practitioners unlock the hidden structures of their models.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/Q7BBAEK5/Purvine et al. - 2023 - Experimental Observations of the Topology of Convo.pdf}
}

@misc{ragiArtificialIntelligencedrivenImage2021,
  title = {Artificial {{Intelligence-driven Image Analysis}} of {{Bacterial Cells}} and {{Biofilms}}},
  author = {Ragi, Shankarachary and Rahman, Md Hafizur and Duckworth, Jamison and Jawaharraj, Kalimuthu and Chundi, Parvathi and Gadhamshetty, Venkataramana},
  year = {2021},
  month = dec,
  number = {arXiv:2112.01577},
  eprint = {2112.01577},
  primaryclass = {q-bio},
  publisher = {arXiv},
  urldate = {2023-11-24},
  abstract = {The current study explores an artificial intelligence framework for measuring the structural features from microscopy images of the bacterial biofilms. Desulfovibrio alaskensis G20 (DA-G20) grown on mild steel surfaces is used as a model for sulfate reducing bacteria that are implicated in microbiologically influenced corrosion problems. Our goal is to automate the process of extracting the geometrical properties of the DA-G20 cells from the scanning electron microscopy (SEM) images, which is otherwise a laborious and costly process. These geometric properties are a biofilm phenotype that allow us to understand how the biofilm structurally adapts to the surface properties of the underlying metals, which can lead to better corrosion prevention solutions. We adapt two deep learning models: (a) a deep convolutional neural network (DCNN) model to achieve semantic segmentation of the cells, (d) a mask region-convolutional neural network (Mask R-CNN) model to achieve instance segmentation of the cells. These models are then integrated with moment invariants approach to measure the geometric characteristics of the segmented cells. Our numerical studies confirm that the Mask-RCNN and DCNN methods are 227x and 70x faster respectively, compared to the traditional method of manual identification and measurement of the cell geometric properties by the domain experts.},
  archiveprefix = {arxiv},
  keywords = {notion,Quantitative Biology - Quantitative Methods},
  file = {/Users/nscherf/Zotero/storage/SDX843N5/Ragi et al. - 2021 - Artificial Intelligence-driven Image Analysis of B.pdf;/Users/nscherf/Zotero/storage/5B7TMD2C/2112.html}
}

@article{randiNeuralSignalPropagation2023,
  title = {Neural Signal Propagation Atlas of {{Caenorhabditis}} Elegans},
  author = {Randi, Francesco and Sharma, Anuj K. and Dvali, Sophie and Leifer, Andrew M.},
  year = {2023},
  month = nov,
  journal = {Nature},
  volume = {623},
  number = {7986},
  pages = {406--414},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06683-4},
  urldate = {2023-11-24},
  abstract = {Establishing how neural function emerges from network properties is a fundamental problem in neuroscience1. Here, to better understand the relationship between the structure and the function of a nervous system, we systematically measure signal propagation in 23,433 pairs of neurons across the head of the nematode Caenorhabditis elegans by direct optogenetic activation and simultaneous whole-brain calcium imaging. We measure the sign (excitatory or inhibitory), strength, temporal properties and causal direction of signal propagation between these neurons to create a functional atlas. We find that signal propagation differs from model predictions that are based on anatomy. Using mutants, we show that extrasynaptic signalling not visible from anatomy contributes to this difference. We identify many instances of dense-core-vesicle-dependent signalling,~including on timescales of less than a~second, that evoke acute calcium transients---often where no direct wired connection exists but where relevant neuropeptides and receptors are expressed. We propose that, in such cases, extrasynaptically released neuropeptides serve a similar function to that of classical neurotransmitters. Finally, our measured signal propagation atlas better predicts the neural dynamics of spontaneous activity than do models based on anatomy. We conclude that both synaptic and extrasynaptic signalling drive neural dynamics on short timescales, and that measurements of evoked signal propagation are crucial for interpreting neural function.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Biological physics,Biophysical models,Fluorescence imaging,Neural circuits,notion,Optogenetics},
  file = {/Users/nscherf/Zotero/storage/RS2LT28V/Randi et al. - 2023 - Neural signal propagation atlas of Caenorhabditis .pdf}
}

@article{rathoreTopoBERTExploringTopology2023,
  title = {{{TopoBERT}}: {{Exploring}} the Topology of Fine-Tuned Word Representations},
  shorttitle = {{{TopoBERT}}},
  author = {Rathore, Archit and Zhou, Yichu and Srikumar, Vivek and Wang, Bei},
  year = {2023},
  month = may,
  journal = {Information Visualization},
  pages = {14738716231168671},
  publisher = {SAGE Publications},
  issn = {1473-8716},
  doi = {10.1177/14738716231168671},
  urldate = {2023-05-15},
  abstract = {Transformer-based language models such as BERT and its variants have found widespread use in natural language processing (NLP). A common way of using these models is to fine-tune them to improve their performance on a specific task. However, it is currently unclear how the fine-tuning process affects the underlying structure of the word embeddings from these models. We present TopoBERT, a visual analytics system for interactively exploring the fine-tuning process of various transformer-based models -- across multiple fine-tuning batch updates, subsequent layers of the model, and different NLP tasks -- from a topological perspective. The system uses the mapper algorithm from topological data analysis (TDA) to generate a graph that approximates the shape of a model's embedding space for an input dataset. TopoBERT enables its users (e.g. experts in NLP and linguistics) to (1) interactively explore the fine-tuning process across different model-task pairs, (2) visualize the shape of embedding spaces at multiple scales and layers, and (3) connect linguistic and contextual information about the input dataset with the topology of the embedding space. Using TopoBERT, we provide various use cases to exemplify its applications in exploring fine-tuned word embeddings. We further demonstrate the utility of TopoBERT, which enables users to generate insights about the fine-tuning process and provides support for empirical validation of these insights.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/UJUYS27D/Rathore et al. - 2023 - TopoBERT Exploring the topology of fine-tuned wor.pdf}
}

@article{reinkeUnderstandingMetricrelatedPitfalls2024,
  title = {Understanding Metric-Related Pitfalls in Image Analysis Validation},
  author = {Reinke, Annika and Tizabi, Minu D. and Baumgartner, Michael and Eisenmann, Matthias and {Heckmann-N{\"o}tzel}, Doreen and Kavur, A. Emre and R{\"a}dsch, Tim and Sudre, Carole H. and Acion, Laura and Antonelli, Michela and Arbel, Tal and Bakas, Spyridon and Benis, Arriel and Buettner, Florian and Cardoso, M. Jorge and Cheplygina, Veronika and Chen, Jianxu and Christodoulou, Evangelia and Cimini, Beth A. and Farahani, Keyvan and Ferrer, Luciana and Galdran, Adrian and {van Ginneken}, Bram and Glocker, Ben and Godau, Patrick and Hashimoto, Daniel A. and Hoffman, Michael M. and Huisman, Merel and Isensee, Fabian and Jannin, Pierre and Kahn, Charles E. and Kainmueller, Dagmar and Kainz, Bernhard and Karargyris, Alexandros and Kleesiek, Jens and Kofler, Florian and Kooi, Thijs and {Kopp-Schneider}, Annette and Kozubek, Michal and Kreshuk, Anna and Kurc, Tahsin and Landman, Bennett A. and Litjens, Geert and Madani, Amin and {Maier-Hein}, Klaus and Martel, Anne L. and Meijering, Erik and Menze, Bjoern and Moons, Karel G. M. and M{\"u}ller, Henning and Nichyporuk, Brennan and Nickel, Felix and Petersen, Jens and Rafelski, Susanne M. and Rajpoot, Nasir and Reyes, Mauricio and Riegler, Michael A. and Rieke, Nicola and {Saez-Rodriguez}, Julio and S{\'a}nchez, Clara I. and Shetty, Shravya and Summers, Ronald M. and Taha, Abdel A. and Tiulpin, Aleksei and Tsaftaris, Sotirios A. and Van Calster, Ben and Varoquaux, Ga{\"e}l and Yaniv, Ziv R. and J{\"a}ger, Paul F. and {Maier-Hein}, Lena},
  year = {2024},
  month = feb,
  journal = {Nature Methods},
  volume = {21},
  number = {2},
  pages = {182--194},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-023-02150-0},
  urldate = {2024-02-26},
  abstract = {Validation metrics are key for tracking scientific progress and bridging the current chasm between artificial intelligence research and its translation into practice. However, increasing evidence shows that, particularly in image analysis, metrics are often chosen inadequately. Although taking into account the individual strengths, weaknesses and limitations of validation metrics is a critical prerequisite to making educated choices, the relevant knowledge is currently scattered and poorly accessible to individual researchers. Based on a multistage Delphi process conducted by a multidisciplinary expert consortium as well as extensive community feedback, the present work provides a reliable and comprehensive common point of access to information on pitfalls related to validation metrics in image analysis. Although focused on biomedical image analysis, the addressed pitfalls generalize across application domains and are categorized according to a newly created, domain-agnostic taxonomy. The work serves to enhance global comprehension of a key topic in image analysis validation.},
  copyright = {2024 Springer Nature America, Inc.},
  langid = {english},
  keywords = {Cancer,Education,Medical research,notion},
  file = {/Users/nscherf/Zotero/storage/VUVV4MWZ/Reinke et al. - 2024 - Understanding metric-related pitfalls in image ana.pdf}
}

@article{rohrerThinkingClearlyCorrelations2018,
  title = {Thinking {{Clearly About Correlations}} and {{Causation}}: {{Graphical Causal Models}} for {{Observational Data}}},
  shorttitle = {Thinking {{Clearly About Correlations}} and {{Causation}}},
  author = {Rohrer, Julia M.},
  year = {2018},
  month = mar,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {1},
  pages = {27--42},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245917745629},
  urldate = {2024-03-11},
  abstract = {Correlation does not imply causation; but often, observational data are the only option, even though the research question at hand involves causality. This article discusses causal inference based on observational data, introducing readers to graphical causal models that can provide a powerful tool for thinking more clearly about the interrelations between variables. Topics covered include the rationale behind the statistical control of third variables, common procedures for statistical control, and what can go wrong during their implementation. Certain types of third variables---colliders and mediators---should not be controlled for because that can actually move the estimate of an association away from the value of the causal effect of interest. More subtle variations of such harmful control include using unrepresentative samples, which can undermine the validity of causal conclusions, and statistically controlling for mediators. Drawing valid causal inferences on the basis of observational data is not a mechanistic procedure but rather always depends on assumptions that require domain knowledge and that can be more or less plausible. However, this caveat holds not only for research based on observational data, but for all empirical research endeavors.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/45DFFZ3J/Rohrer - 2018 - Thinking Clearly About Correlations and Causation.pdf}
}

@article{romera-paredesMathematicalDiscoveriesProgram2024,
  title = {Mathematical Discoveries from Program Search with Large Language Models},
  author = {{Romera-Paredes}, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and Balog, Matej and Kumar, M. Pawan and Dupont, Emilien and Ruiz, Francisco J. R. and Ellenberg, Jordan S. and Wang, Pengming and Fawzi, Omar and Kohli, Pushmeet and Fawzi, Alhussein},
  year = {2024},
  month = jan,
  journal = {Nature},
  volume = {625},
  number = {7995},
  pages = {468--475},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06924-6},
  urldate = {2024-03-03},
  abstract = {Large language models (LLMs) have demonstrated tremendous capabilities in solving complex tasks, from quantitative reasoning to understanding natural language. However, LLMs sometimes suffer from confabulations (or hallucinations), which can result in them making plausible but incorrect statements1,2. This hinders the use of current large models in scientific discovery. Here we introduce FunSearch (short for searching in the function space), an evolutionary procedure based on pairing a pretrained LLM with a systematic evaluator. We demonstrate the effectiveness of this approach to surpass the best-known results in important problems, pushing the boundary of existing LLM-based approaches3. Applying FunSearch to a central problem in extremal combinatorics---the cap set problem---we discover new constructions of large cap sets going beyond the best-known ones, both in finite dimensional and asymptotic cases. This shows that it is possible to make discoveries for established open problems using LLMs. We showcase the generality of FunSearch by applying it to an algorithmic problem, online bin packing, finding new heuristics that improve on widely used baselines. In contrast to most computer search approaches, FunSearch searches for programs that describe how to solve a problem, rather than what the solution is. Beyond being an effective and scalable strategy, discovered programs tend to be more interpretable than raw solutions, enabling feedback loops between domain experts and FunSearch, and the deployment of such programs in real-world applications.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Computer science,notion,Pure mathematics},
  file = {/Users/nscherf/Zotero/storage/VRHC8HY8/Romera-Paredes et al. - 2024 - Mathematical discoveries from program search with .pdf}
}

@article{sarkarShadowsDonLie,
  title = {Shadows {{Don}}'t {{Lie}} and {{Lines Can}}'t {{Bend}}!},
  author = {Sarkar, Ayush and Mai, Hanlin and Mahapatra, Amitabh and Lazebnik, Svetlana and Forsyth, D A and Bhattad, Anand},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/5HAHVS2S/Sarkar et al. - Shadows Donâ€™t Lie and Lines Canâ€™t Bend!.pdf}
}

@article{saxeIfDeepLearning2021,
  title = {If Deep Learning Is the Answer, What Is the Question?},
  author = {Saxe, Andrew and Nelli, Stephanie and Summerfield, Christopher},
  year = {2021},
  month = jan,
  journal = {Nature Reviews Neuroscience},
  volume = {22},
  number = {1},
  pages = {55--67},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-00395-8},
  urldate = {2021-10-14},
  abstract = {Neuroscience research is undergoing a minor revolution. Recent advances in machine learning and artificial intelligence research have opened up new ways of thinking about neural computation. Many researchers are excited by the possibility that deep neural networks may offer theories of perception, cognition and action for biological brains. This approach has the potential to radically reshape our approach to understanding neural systems, because the computations performed by deep networks are learned from experience, and not endowed by the researcher. If so, how can neuroscientists use deep networks to model and understand biological brains? What is the outlook for neuroscientists who seek to characterize computations or neural codes, or who wish to understand perception, attention, memory and executive functions? In this Perspective, our goal is to offer a road map for systems neuroscience research in the age of deep learning. We discuss the conceptual and methodological challenges of comparing behaviour, learning dynamics and neural representations in artificial and biological systems, and we highlight new research questions that have emerged for neuroscience as a direct consequence of recent advances in machine learning.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  keywords = {_tablet,neural geometry,notion},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Learning algorithms;Network models Subject\_term\_id: learning-algorithms;network-models},
  file = {/Users/nscherf/Zotero/storage/XPW7INVA/Saxe et al. - 2021 - If deep learning is the answer, what is the questi.pdf;/Users/nscherf/Zotero/storage/8Z4S97TN/s41583-020-00395-8.html}
}

@article{schomersNeurocomputationalConsequencesEvolutionary2017,
  title = {Neurocomputational {{Consequences}} of {{Evolutionary Connectivity Changes}} in {{Perisylvian Language Cortex}}},
  author = {Schomers, Malte R. and Garagnani, Max and Pulverm{\"u}ller, Friedemann},
  year = {2017},
  month = mar,
  journal = {Journal of Neuroscience},
  volume = {37},
  number = {11},
  pages = {3045--3055},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2693-16.2017},
  urldate = {2023-11-24},
  abstract = {The human brain sets itself apart from that of its primate relatives by specific neuroanatomical features, especially the strong linkage of left perisylvian language areas (frontal and temporal cortex) by way of the arcuate fasciculus (AF). AF connectivity has been shown to correlate with verbal working memory---a specifically human trait providing the foundation for language abilities---but a mechanistic explanation of any related causal link between anatomical structure and cognitive function is still missing. Here, we provide a possible explanation and link, by using neurocomputational simulations in neuroanatomically structured models of the perisylvian language cortex. We compare networks mimicking key features of cortical connectivity in monkeys and humans, specifically the presence of relatively stronger higher-order ``jumping links'' between nonadjacent perisylvian cortical areas in the latter, and demonstrate that the emergence of working memory for syllables and word forms is a functional consequence of this structural evolutionary change. We also show that a mere increase of learning time is not sufficient, but that this specific structural feature, which entails higher connectivity degree of relevant areas and shorter sensorimotor path length, is crucial. These results offer a better understanding of specifically human anatomical features underlying the language faculty and their evolutionary selection advantage. SIGNIFICANCE STATEMENT Why do humans have superior language abilities compared to primates? Recently, a uniquely human neuroanatomical feature has been demonstrated in the strength of the arcuate fasciculus (AF), a fiber pathway interlinking the left-hemispheric language areas. Although AF anatomy has been related to linguistic skills, an explanation of how this fiber bundle may support language abilities is still missing. We use neuroanatomically structured computational models to investigate the consequences of evolutionary changes in language area connectivity and demonstrate that the human-specific higher connectivity degree and comparatively shorter sensorimotor path length implicated by the AF entail emergence of verbal working memory, a prerequisite for language learning. These results offer a better understanding of specifically human anatomical features for language and their evolutionary selection advantage.},
  chapter = {Research Articles},
  copyright = {Copyright {\copyright} 2017 Schomers et al.. This is an open-access article distributed under the terms of the Creative Commons Attribution License Creative Commons Attribution 4.0 International, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
  langid = {english},
  pmid = {28193685},
  keywords = {action-perception cycle,arcuate fasciculus,cortical connectivity,neurocomputational modeling,notion,perisylvian cortex,verbal working memory},
  file = {/Users/nscherf/Zotero/storage/6CWQ7A3K/Schomers et al. - 2017 - Neurocomputational Consequences of Evolutionary Co.pdf}
}

@misc{schonsheckSemiSupervisedManifoldLearning2022,
  title = {Semi-{{Supervised Manifold Learning}} with {{Complexity Decoupled Chart Autoencoders}}},
  author = {Schonsheck, Stefan C. and Mahan, Scott and Klock, Timo and Cloninger, Alexander and Lai, Rongjie},
  year = {2022},
  month = aug,
  number = {arXiv:2208.10570},
  eprint = {2208.10570},
  primaryclass = {cs, math},
  publisher = {arXiv},
  urldate = {2023-09-11},
  abstract = {Autoencoding is a popular method in representation learning. Conventional autoencoders employ symmetric encoding-decoding procedures and a simple Euclidean latent space to detect hidden low-dimensional structures in an unsupervised way. This work introduces a chart autoencoder with an asymmetric encoding-decoding process that can incorporate additional semi-supervised information such as class labels. Besides enhancing the capability for handling data with complicated topological and geometric structures, these models can successfully differentiate nearby but disjoint manifolds and intersecting manifolds with only a small amount of supervision. Moreover, this model only requires a low complexity encoder, such as local linear projection. We discuss the theoretical approximation power of such networks that essentially depends on the intrinsic dimension of the data manifold and not the dimension of the observations. Our numerical experiments on synthetic and real-world data verify that the proposed model can effectively manage data with multi-class nearby but disjoint manifolds of different classes, overlapping manifolds, and manifolds with non-trivial topology.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,notion},
  file = {/Users/nscherf/Zotero/storage/YM58FPKC/Schonsheck et al. - 2022 - Semi-Supervised Manifold Learning with Complexity .pdf;/Users/nscherf/Zotero/storage/MEF2WX7W/2208.html}
}

@misc{schrimpfBrainScoreWhichArtificial2018,
  title = {Brain-{{Score}}: {{Which Artificial Neural Network}} for {{Object Recognition}} Is Most {{Brain-Like}}?},
  shorttitle = {Brain-{{Score}}},
  author = {Schrimpf, Martin and Kubilius, Jonas and Hong, Ha and Majaj, Najib J. and Rajalingham, Rishi and Issa, Elias B. and Kar, Kohitij and Bashivan, Pouya and {Prescott-Roy}, Jonathan and Schmidt, Kailyn and Yamins, Daniel L. K. and DiCarlo, James J.},
  year = {2018},
  month = sep,
  primaryclass = {New Results},
  pages = {407007},
  publisher = {bioRxiv},
  doi = {10.1101/407007},
  urldate = {2024-02-08},
  abstract = {The internal representations of early deep artificial neural networks (ANNs) were found to be remarkably similar to the internal neural representations measured experimentally in the primate brain. Here we ask, as deep ANNs have continued to evolve, are they becoming more or less brain-like? ANNs that are most functionally similar to the brain will contain mechanisms that are most like those used by the brain. We therefore developed Brain-Score -- a composite of multiple neural and behavioral benchmarks that score any ANN on how similar it is to the brain's mechanisms for core object recognition -- and we deployed it to evaluate a wide range of state-of-the-art deep ANNs. Using this scoring system, we here report that: (1) DenseNet-169, CORnet-S and ResNet-101 are the most brain-like ANNs. There remains considerable variability in neural and behavioral responses that is not predicted by any ANN, suggesting that no ANN model has yet captured all the relevant mechanisms. (3) Extending prior work, we found that gains in ANN ImageNet performance led to gains on Brain-Score. However, correlation weakened at {$\geq$} 70\% top-1 ImageNet performance, suggesting that additional guidance from neuroscience is needed to make further advances in capturing brain mechanisms. (4) We uncovered smaller (i.e. less complex) ANNs that are more brain-like than many of the best-performing ImageNet models, which suggests the opportunity to simplify ANNs to better understand the ventral stream. The scoring system used here is far from complete. However, we propose that evaluating and tracking model-benchmark correspondences through a Brain-Score that is regularly updated with new brain data is an exciting opportunity: experimental benchmarks can be used to guide machine network evolution, and machine networks are mechanistic hypotheses of the brain's network and thus drive next experiments. To facilitate both of these, we release Brain-Score.org: a platform that hosts the neural and behavioral benchmarks, where ANNs for visual processing can be submitted to receive a Brain-Score and their rank relative to other models, and where new experimental data can be naturally incorporated.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/M2H5YHVN/Schrimpf et al. - 2018 - Brain-Score Which Artificial Neural Network for O.pdf}
}

@article{schurrDynamicComputationalPhenotyping2024,
  title = {Dynamic Computational Phenotyping of Human Cognition},
  author = {Schurr, Roey and Reznik, Daniel and Hillman, Hanna and Bhui, Rahul and Gershman, Samuel J.},
  year = {2024},
  month = feb,
  journal = {Nature Human Behaviour},
  pages = {1--15},
  publisher = {Nature Publishing Group},
  issn = {2397-3374},
  doi = {10.1038/s41562-024-01814-x},
  urldate = {2024-02-21},
  abstract = {Computational phenotyping has emerged as a powerful tool for characterizing individual variability across a variety of cognitive domains. An individual's computational phenotype is defined as a set of mechanistically interpretable parameters obtained from fitting computational models to behavioural data. However, the interpretation of these parameters hinges critically on their psychometric properties, which are rarely studied. To identify the sources governing the temporal variability of the computational phenotype, we carried out a 12-week longitudinal study using a battery of seven tasks that measure aspects of human learning, memory, perception and decision making. To examine the influence of state effects, each week, participants provided reports tracking their mood, habits and daily activities. We developed a dynamic computational phenotyping framework, which allowed us to tease apart the time-varying effects of practice and internal states such as affective valence and arousal. Our results show that many phenotype dimensions covary with practice and affective factors, indicating that what appears to be unreliability may reflect previously unmeasured structure. These results support a fundamentally dynamic understanding of cognitive variability within an individual.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Cognitive neuroscience,Human behaviour,notion},
  file = {/Users/nscherf/Zotero/storage/N39FS9YQ/Schurr et al. - 2024 - Dynamic computational phenotyping of human cogniti.pdf}
}

@article{sharpeeArgumentHyperbolicGeometry2019,
  title = {An Argument for Hyperbolic Geometry in Neural Circuits},
  author = {Sharpee, Tatyana O},
  year = {2019},
  month = oct,
  journal = {Current Opinion in Neurobiology},
  series = {Computational {{Neuroscience}}},
  volume = {58},
  pages = {101--104},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2019.07.008},
  urldate = {2024-01-22},
  abstract = {This review connects several lines of research to argue that hyperbolic geometry should be broadly applicable to neural circuits as well as other biological circuits. The reason for this is that networks that conform to hyperbolic geometry are maximally responsive to external and internal perturbations. These networks also allow for efficient communication under conditions where nodes are added or removed. We will argue that one of the signatures of hyperbolic geometry is the celebrated Zipf's law (also sometimes known as the Pareto distribution) that states that the probability to observe a given pattern is inversely related to its rank. Zipf's law is observed in a variety of biological systems --- from protein sequences, neural networks to economics. These observations provide further evidence for the ubiquity of networks with an underlying hyperbolic metric structure. Recent studies in neuroscience specifically point to the relevance of a three-dimensional hyperbolic space for neural signaling. The three-dimensional hyperbolic space may confer additional robustness compared to other dimensions. We illustrate how the use of hyperbolic coordinates revealed a novel topographic organization within the olfactory system. The use of such coordinates may facilitate representation of relevant signals elsewhere in the brain.},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/LDLC3FBA/Sharpee - 2019 - An argument for hyperbolic geometry in neural circ.pdf;/Users/nscherf/Zotero/storage/MGSBYSNP/S0959438818302411.html}
}

@misc{sosanyaDissipativeHamiltonianNeural2022,
  title = {Dissipative {{Hamiltonian Neural Networks}}: {{Learning Dissipative}} and {{Conservative Dynamics Separately}}},
  shorttitle = {Dissipative {{Hamiltonian Neural Networks}}},
  author = {Sosanya, Andrew and Greydanus, Sam},
  year = {2022},
  month = jan,
  number = {arXiv:2201.10085},
  eprint = {2201.10085},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-10-18},
  abstract = {Understanding natural symmetries is key to making sense of our complex and ever-changing world. Recent work has shown that neural networks can learn such symmetries directly from data using Hamiltonian Neural Networks (HNNs). But HNNs struggle when trained on datasets where energy is not conserved. In this paper, we ask whether it is possible to identify and decompose conservative and dissipative dynamics simultaneously. We propose Dissipative Hamiltonian Neural Networks (D-HNNs), which parameterize both a Hamiltonian and a Rayleigh dissipation function. Taken together, they represent an implicit Helmholtz decomposition which can separate dissipative effects such as friction from symmetries such as conservation of energy. We train our model to decompose a damped mass-spring system into its friction and inertial terms and then show that this decomposition can be used to predict dynamics for unseen friction coefficients. Then we apply our model to real world data including a large, noisy ocean current dataset where decomposing the velocity field yields useful scientific insights.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,notion},
  file = {/Users/nscherf/Zotero/storage/MXVK8B69/Sosanya and Greydanus - 2022 - Dissipative Hamiltonian Neural Networks Learning .pdf;/Users/nscherf/Zotero/storage/8X5G9VAD/2201.html}
}

@inproceedings{stolt-ansoNISFNeuralImplicit2023,
  title = {{{NISF}}: {{Neural Implicit Segmentation Functions}}},
  shorttitle = {{{NISF}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} -- {{MICCAI}} 2023},
  author = {{Stolt-Ans{\'o}}, Nil and McGinnis, Julian and Pan, Jiazhen and Hammernik, Kerstin and Rueckert, Daniel},
  editor = {Greenspan, Hayit and Madabhushi, Anant and Mousavi, Parvin and Salcudean, Septimiu and Duncan, James and {Syeda-Mahmood}, Tanveer and Taylor, Russell},
  year = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {734--744},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-43901-8_70},
  abstract = {Segmentation of anatomical shapes from medical images has taken an important role in the automation of clinical measurements. While typical deep-learning segmentation approaches are performed on discrete voxels, the underlying objects being analysed exist in a real-valued continuous space. Approaches that rely on convolutional neural networks (CNNs) are limited to grid-like inputs and not easily applicable to sparse or partial measurements. We propose a novel family of image segmentation models that tackle many of CNNs' shortcomings: Neural Implicit Segmentation Functions (NISF). Our framework takes inspiration from the field of neural implicit functions where a network learns a mapping from a real-valued coordinate-space to a shape representation. NISFs have the ability to segment anatomical shapes in high-dimensional continuous spaces. Training is not limited to voxelized grids, and covers applications with sparse and partial data. Interpolation between observations is learnt naturally in the training procedure and requires no post-processing. Furthermore, NISFs allow the leveraging of learnt shape priors to make predictions for regions outside of the original image plane. We go on to show the framework achieves dice scores of \$\$0.87 {\textbackslash}pm 0.045\$\$on a (3D+t) short-axis cardiac segmentation task using the UK Biobank dataset. We also provide a qualitative analysis on our frameworks ability to perform segmentation and image interpolation on unseen regions of an image volume at arbitrary resolutions.},
  isbn = {978-3-031-43901-8},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/FIFMBGSN/Stolt-AnsÃ³ et al. - 2023 - NISF Neural Implicit Segmentation Functions.pdf}
}

@article{straubGradientsMammalianCerebellar2020,
  title = {Gradients in the Mammalian Cerebellar Cortex Enable {{Fourier-like}} Transformation and Improve Storing Capacity},
  author = {Straub, Isabelle and Witter, Laurens and Eshra, Abdelmoneim and Hoidis, Miriam and Byczkowicz, Niklas and Maas, Sebastian and Delvendahl, Igor and Dorgans, Kevin and Savier, Elise and Bechmann, Ingo and Krueger, Martin and Isope, Philippe and Hallermann, Stefan},
  editor = {Nelson, Sacha B and {Shinn-Cunningham}, Barbara G and Nelson, Sacha B},
  year = {2020},
  month = feb,
  journal = {eLife},
  volume = {9},
  pages = {e51771},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.51771},
  urldate = {2024-02-02},
  abstract = {Cerebellar granule cells (GCs) make up the majority of all neurons in the vertebrate brain, but heterogeneities among GCs and potential functional consequences are poorly understood. Here, we identified unexpected gradients in the biophysical properties of GCs in mice. GCs closer to the white matter (inner-zone GCs) had higher firing thresholds and could sustain firing with larger current inputs than GCs closer to the Purkinje cell layer (outer-zone GCs). Dynamic Clamp experiments showed that inner- and outer-zone GCs preferentially respond to high- and low-frequency mossy fiber inputs, respectively, enabling dispersion of the mossy fiber input into its frequency components as performed by a Fourier transformation. Furthermore, inner-zone GCs have faster axonal conduction velocity and elicit faster synaptic potentials in Purkinje cells. Neuronal network modeling revealed that these gradients improve spike-timing precision of Purkinje cells and decrease the number of GCs required to learn spike-sequences. Thus, our study uncovers biophysical gradients in the cerebellar cortex enabling a Fourier-like transformation of mossy fiber inputs.},
  keywords = {cerebellum,electrophysiology,granule cell,mossy fiber,notion},
  file = {/Users/nscherf/Zotero/storage/6NK9GGXX/Straub et al. - 2020 - Gradients in the mammalian cerebellar cortex enabl.pdf}
}

@book{strogatzNonlinearDynamicsChaos2014,
  title = {Nonlinear {{Dynamics}} and {{Chaos}}: {{With Applications}} to {{Physics}}, {{Biology}}, {{Chemistry}}, and {{Engineering}}, {{Second Edition}}},
  shorttitle = {Nonlinear {{Dynamics}} and {{Chaos}}},
  author = {Strogatz, Steven},
  year = {2014},
  month = jul,
  edition = {2},
  publisher = {CRC Press},
  urldate = {2024-01-16},
  abstract = {This textbook is aimed at newcomers to nonlinear dynamics and chaos, especially students taking a first course in the subject. The presentation stresses analytical methods, concrete examples, and geometric intuition. The theory is developed systematically, starting with first-order differential equations and their bifurcations, followed by phase plane analysis, limit cycles and their bifurcations, and culminating with the Lorenz equations, chaos, iterated maps, period doubling, renormalization,},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/PN2USBFD/9780813349107.html}
}

@misc{sucholutskyGettingAlignedRepresentational2023,
  title = {Getting Aligned on Representational Alignment},
  author = {Sucholutsky, Ilia and Muttenthaler, Lukas and Weller, Adrian and Peng, Andi and Bobu, Andreea and Kim, Been and Love, Bradley C. and Grant, Erin and Groen, Iris and Achterberg, Jascha and Tenenbaum, Joshua B. and Collins, Katherine M. and Hermann, Katherine L. and Oktar, Kerem and Greff, Klaus and Hebart, Martin N. and Jacoby, Nori and Zhang, Qiuyi and Marjieh, Raja and Geirhos, Robert and Chen, Sherol and Kornblith, Simon and Rane, Sunayana and Konkle, Talia and O'Connell, Thomas P. and Unterthiner, Thomas and Lampinen, Andrew K. and M{\"u}ller, Klaus-Robert and Toneva, Mariya and Griffiths, Thomas L.},
  year = {2023},
  month = nov,
  number = {arXiv:2310.13018},
  eprint = {2310.13018},
  primaryclass = {cs, q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.13018},
  urldate = {2023-11-08},
  abstract = {Biological and artificial information processing systems form representations that they can use to categorize, reason, plan, navigate, and make decisions. How can we measure the extent to which the representations formed by these diverse systems agree? Do similarities in representations then translate into similar behavior? How can a system's representations be modified to better match those of another system? These questions pertaining to the study of representational alignment are at the heart of some of the most active research areas in cognitive science, neuroscience, and machine learning. For example, cognitive scientists measure the representational alignment of multiple individuals to identify shared cognitive priors, neuroscientists align fMRI responses from multiple individuals into a shared representational space for group-level analyses, and ML researchers distill knowledge from teacher models into student models by increasing their alignment. Unfortunately, there is limited knowledge transfer between research communities interested in representational alignment, so progress in one field often ends up being rediscovered independently in another. Thus, greater cross-field communication would be advantageous. To improve communication between these fields, we propose a unifying framework that can serve as a common language between researchers studying representational alignment. We survey the literature from all three fields and demonstrate how prior work fits into this framework. Finally, we lay out open problems in representational alignment where progress can benefit all three of these fields. We hope that our work can catalyze cross-disciplinary collaboration and accelerate progress for all communities studying and developing information processing systems. We note that this is a working paper and encourage readers to reach out with their suggestions for future revisions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,notion,Quantitative Biology - Neurons and Cognition},
  file = {/Users/nscherf/Zotero/storage/ZTXTKMUX/Sucholutsky et al. - 2023 - Getting aligned on representational alignment.pdf;/Users/nscherf/Zotero/storage/5JU8DR3I/2310.html}
}

@article{thompsonMachineLearningPredict2019,
  title = {Machine Learning to Predict Microbial Community Functions: {{An}} Analysis of Dissolved Organic Carbon from Litter Decomposition},
  shorttitle = {Machine Learning to Predict Microbial Community Functions},
  author = {Thompson, Jaron and Johansen, Renee and Dunbar, John and Munsky, Brian},
  year = {2019},
  month = jul,
  journal = {PLOS ONE},
  volume = {14},
  number = {7},
  pages = {e0215502},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0215502},
  urldate = {2023-10-27},
  abstract = {Microbial communities are ubiquitous and often influence macroscopic properties of the ecosystems they inhabit. However, deciphering the functional relationship between specific microbes and ecosystem properties is an ongoing challenge owing to the complexity of the communities. This challenge can be addressed, in part, by integrating the advances in DNA sequencing technology with computational approaches like machine learning. Although machine learning techniques have been applied to microbiome data, use of these techniques remains rare, and user-friendly platforms to implement such techniques are not widely available. We developed a tool that implements neural network and random forest models to perform regression and feature selection tasks on microbiome data. In this study, we applied the tool to analyze soil microbiome (16S rRNA gene profiles) and dissolved organic carbon (DOC) data from a 44-day plant litter decomposition experiment. The microbiome data includes 1709 total bacterial operational taxonomic units (OTU) from 300+ microcosms. Regression analysis of predicted and actual DOC for a held-out test set of 51 samples yield Pearson's correlation coefficients of.636 and.676 for neural network and random forest approaches, respectively. Important taxa identified by the machine learning techniques are compared to results from a standard tool (indicator species analysis) widely used by microbial ecologists. Of 1709 bacterial taxa, indicator species analysis identified 285 taxa as significant determinants of DOC concentration. Of the top 285 ranked features determined by machine learning methods, a subset of 86 taxa are common to all feature selection techniques. Using this subset of features, prediction results for random permutations of the data set are at least equally accurate compared to predictions determined using the entire feature set. Our results suggest that integration of multiple methods can aid identification of a robust subset of taxa within complex communities that may drive specific functional outcomes of interest.},
  langid = {english},
  keywords = {Decision trees,Feedforward neural networks,Machine learning,Machine learning algorithms,Microbial ecology,Microbiome,Monte Carlo method,Neural networks,notion},
  file = {/Users/nscherf/Zotero/storage/VYA8KBT9/Thompson et al. - 2019 - Machine learning to predict microbial community fu.pdf}
}

@article{tuckuteManyNotAll2023,
  title = {Many but Not All Deep Neural Network Audio Models Capture Brain Responses and Exhibit Correspondence between Model Stages and Brain Regions},
  author = {Tuckute, Greta and Feather, Jenelle and Boebinger, Dana and McDermott, Josh H.},
  year = {2023},
  month = dec,
  journal = {PLOS Biology},
  volume = {21},
  number = {12},
  pages = {e3002366},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3002366},
  urldate = {2023-12-21},
  abstract = {Models that predict brain responses to stimuli provide one measure of understanding of a sensory system and have many potential applications in science and engineering. Deep artificial neural networks have emerged as the leading such predictive models of the visual system but are less explored in audition. Prior work provided examples of audio-trained neural networks that produced good predictions of auditory cortical fMRI responses and exhibited correspondence between model stages and brain regions, but left it unclear whether these results generalize to other neural network models and, thus, how to further improve models in this domain. We evaluated model-brain correspondence for publicly available audio neural network models along with in-house models trained on 4 different tasks. Most tested models outpredicted standard spectromporal filter-bank models of auditory cortex and exhibited systematic model-brain correspondence: Middle stages best predicted primary auditory cortex, while deep stages best predicted non-primary cortex. However, some state-of-the-art models produced substantially worse brain predictions. Models trained to recognize speech in background noise produced better brain predictions than models trained to recognize speech in quiet, potentially because hearing in noise imposes constraints on biological auditory representations. The training task influenced the prediction quality for specific cortical tuning properties, with best overall predictions resulting from models trained on multiple tasks. The results generally support the promise of deep neural networks as models of audition, though they also indicate that current models do not explain auditory cortical responses in their entirety.},
  langid = {english},
  keywords = {Audio equipment,Auditory cortex,Bioacoustics,Functional magnetic resonance imaging,Neural networks,notion,Speech,Speech signal processing,Word recognition},
  file = {/Users/nscherf/Zotero/storage/QYV9FVAY/Tuckute et al. - 2023 - Many but not all deep neural network audio models .pdf}
}

@misc{vafaiiHierarchicalVAEsProvide2023,
  title = {Hierarchical {{VAEs}} Provide a Normative Account of Motion Processing in the Primate Brain},
  author = {Vafaii, Hadi and Yates, Jacob L. and Butts, Daniel A.},
  year = {2023},
  month = nov,
  primaryclass = {New Results},
  pages = {2023.09.27.559646},
  publisher = {bioRxiv},
  doi = {10.1101/2023.09.27.559646},
  urldate = {2023-11-23},
  abstract = {The relationship between perception and inference, as postulated by Helmholtz in the 19th century, is paralleled in modern machine learning by generative models like Variational Autoencoders (VAEs) and their hierarchical variants. Here, we evaluate the role of hierarchical inference and its alignment with brain function in the domain of motion perception. We first introduce a novel synthetic data framework, Retinal Optic Flow Learning (ROFL), which enables control over motion statistics and their causes. We then present a new hierarchical VAE and test it against alternative models on two downstream tasks: (i) predicting ground truth causes of retinal optic flow (e.g., self-motion); and (ii) predicting the responses of neurons in the motion processing pathway of primates. We manipulate the model architectures (hierarchical versus non-hierarchical), loss functions, and the causal structure of the motion stimuli. We find that hierarchical latent structure in the model leads to several improvements. First, it improves the linear decodability of ground truth factors and does so in a sparse and disentangled manner. Second, our hierarchical VAE outperforms previous state-of-the-art models in predicting neuronal responses and exhibits sparse latent-to-neuron relationships. These results depend on the causal structure of the world, indicating that alignment between brains and artificial neural networks depends not only on architecture but also on matching ecologically relevant stimulus statistics. Taken together, our results suggest that hierarchical Bayesian inference underlines the brain's understanding of the world, and hierarchical VAEs can effectively model this understanding.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/JW97NAIA/Vafaii et al. - 2023 - Hierarchical VAEs provide a normative account of m.pdf}
}

@misc{valerianiGeometryHiddenRepresentations2023,
  title = {The Geometry of Hidden Representations of Large Transformer Models},
  author = {Valeriani, Lucrezia and Doimo, Diego and Cuturello, Francesca and Laio, Alessandro and Ansuini, Alessio and Cazzaniga, Alberto},
  year = {2023},
  month = oct,
  number = {arXiv:2302.00294},
  eprint = {2302.00294},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.00294},
  urldate = {2024-03-04},
  abstract = {Large transformers are powerful architectures used for self-supervised data analysis across various data types, including protein sequences, images, and text. In these models, the semantic structure of the dataset emerges from a sequence of transformations between one representation and the next. We characterize the geometric and statistical properties of these representations and how they change as we move through the layers. By analyzing the intrinsic dimension (ID) and neighbor composition, we find that the representations evolve similarly in transformers trained on protein language tasks and image reconstruction tasks. In the first layers, the data manifold expands, becoming high-dimensional, and then contracts significantly in the intermediate layers. In the last part of the model, the ID remains approximately constant or forms a second shallow peak. We show that the semantic information of the dataset is better expressed at the end of the first peak, and this phenomenon can be observed across many models trained on diverse datasets. Based on our findings, we point out an explicit strategy to identify, without supervision, the layers that maximize semantic content: representations at intermediate layers corresponding to a relative minimum of the ID profile are more suitable for downstream learning tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,notion,Statistics - Machine Learning},
  file = {/Users/nscherf/Zotero/storage/JYTD3HVE/Valeriani et al. - 2023 - The geometry of hidden representations of large tr.pdf;/Users/nscherf/Zotero/storage/WJLZ4P86/2302.html}
}

@article{vlontzosEstimatingCategoricalCounterfactuals2023,
  title = {Estimating Categorical Counterfactuals via Deep Twin Networks},
  author = {Vlontzos, Athanasios and Kainz, Bernhard and {Gilligan-Lee}, Ciar{\'a}n M.},
  year = {2023},
  month = feb,
  journal = {Nature Machine Intelligence},
  volume = {5},
  number = {2},
  pages = {159--168},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-023-00611-x},
  urldate = {2024-02-29},
  abstract = {Counterfactual inference is a powerful tool, capable of solving challenging problems in high-profile sectors. To perform counterfactual inference, we require knowledge of the underlying causal mechanisms. However, causal mechanisms cannot be uniquely determined from observations and interventions alone. This raises the question of how to choose the causal mechanisms so that the resulting counterfactual inference is trustworthy in a given domain. This question has been addressed in causal models with binary variables, but for the case of categorical variables, it remains unanswered. We address this challenge by introducing for causal models with categorical variables the notion of counterfactual ordering, a principle positing desirable properties that causal mechanisms should possess and prove that it is equivalent to specific functional constraints on the causal mechanisms. To learn causal mechanisms satisfying these constraints, and perform counterfactual inference with them, we introduce deep twin networks. These are deep neural networks that, when trained, are capable of twin network counterfactual inference---an alternative to the abduction--action--prediction method. We empirically test our approach on diverse real-world and semisynthetic data from medicine, epidemiology and finance, reporting accurate estimation of counterfactual probabilities while demonstrating the issues that arise with counterfactual reasoning when counterfactual ordering is not enforced},
  copyright = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Computer science,Experimental models of disease,notion,Technology},
  file = {/Users/nscherf/Zotero/storage/33LQ78ZG/Vlontzos et al. - 2023 - Estimating categorical counterfactuals via deep tw.pdf}
}

@inproceedings{whittingtonDisentanglementBiologicalConstraints2022,
  title = {Disentanglement with {{Biological Constraints}}: {{A Theory}} of {{Functional Cell Types}}},
  shorttitle = {Disentanglement with {{Biological Constraints}}},
  booktitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  author = {Whittington, James C. R. and Dorrell, Will and Ganguli, Surya and Behrens, Timothy},
  year = {2022},
  month = sep,
  urldate = {2024-02-01},
  abstract = {Neurons in the brain are often finely tuned for specific task variables. Moreover, such disentangled representations are highly sought after in machine learning. Here we mathematically prove that simple biological constraints on neurons, namely nonnegativity and energy efficiency in both activity and weights, promote such sought after disentangled representations by enforcing neurons to become selective for single factors of task variation. We demonstrate these constraints lead to disentanglement in a variety of tasks and architectures, including variational autoencoders. We also use this theory to explain why the brain partitions its cells into distinct cell types such as grid and object-vector cells, and also explain when the brain instead entangles representations in response to entangled task factors. Overall, this work provides a mathematical understanding of why single neurons in the brain often represent single human-interpretable factors, and steps towards an understanding task structure shapes the structure of brain representation.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/643CDPMJ/Whittington et al. - 2022 - Disentanglement with Biological Constraints A The.pdf}
}

@inproceedings{wyattAnoDDPMAnomalyDetection2022,
  title = {{{AnoDDPM}}: {{Anomaly Detection}} with {{Denoising Diffusion Probabilistic Models}} Using {{Simplex Noise}}},
  shorttitle = {{{AnoDDPM}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  author = {Wyatt, Julian and Leach, Adam and Schmon, Sebastian M. and Willcocks, Chris G.},
  year = {2022},
  month = jun,
  pages = {649--655},
  publisher = {IEEE},
  address = {New Orleans, LA, USA},
  doi = {10.1109/CVPRW56347.2022.00080},
  urldate = {2024-01-15},
  abstract = {Generative models have been shown to provide a powerful mechanism for anomaly detection by learning to model healthy or normal reference data which can subsequently be used as a baseline for scoring anomalies. In this work we consider denoising diffusion probabilistic models (DDPMs) for unsupervised anomaly detection. DDPMs have superior mode coverage over generative adversarial networks (GANs) and higher sample quality than variational autoencoders (VAEs). However, this comes at the expense of poor scalability and increased sampling times due to the long Markov chain sequences required. We observe that within reconstruction-based anomaly detection a full-length Markov chain diffusion is not required. This leads us to develop a novel partial diffusion anomaly detection strategy that scales to high-resolution imagery, named AnoDDPM. A secondary problem is that Gaussian diffusion fails to capture larger anomalies; therefore we develop a multi-scale simplex noise diffusion process that gives control over the target anomaly size. AnoDDPM with simplex noise is shown to significantly outperform both f-AnoGAN and Gaussian diffusion for the tumorous dataset of 22 T1weighted MRI scans (CCBS Edinburgh) qualitatively and quantitatively (improvement of +25.5\% S{\o}rensen--Dice coefficient, +17.6\% IoU and +7.4\% AUC).},
  isbn = {978-1-66548-739-9},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/KQSIIDWV/Wyatt et al. - 2022 - AnoDDPM Anomaly Detection with Denoising Diffusio.pdf}
}

@article{yamakawaAttentionalReinforcementLearning2020,
  title = {Attentional {{Reinforcement Learning}} in the {{Brain}}},
  author = {Yamakawa, Hiroshi},
  year = {2020},
  month = mar,
  journal = {New Generation Computing},
  volume = {38},
  number = {1},
  pages = {49--64},
  issn = {1882-7055},
  doi = {10.1007/s00354-019-00081-z},
  urldate = {2023-11-24},
  abstract = {Recently, attention mechanisms have significantly boosted the performance of natural language processing using deep learning. An attention mechanism can select the information to be used, such as by conducting a dictionary lookup; this information is then used, for example, to select the next utterance word in a sentence. In neuroscience, the basis of the function of sequentially selecting words is considered to be the cortico-basal ganglia-thalamocortical loop. Here, we first show that the attention mechanism used in deep learning corresponds to the mechanism in which the cerebral basal ganglia suppress thalamic relay cells in the brain. Next, we demonstrate that, in neuroscience, the output of the basal ganglia is associated with the action output in the actor of reinforcement learning. Based on these, we show that the aforementioned loop can be generalized as reinforcement learning that controls the transmission of the prediction signal so as to maximize the prediction reward. We call this attentional reinforcement learning (ARL). In ARL, the actor selects the information transmission route according to the attention, and the prediction signal changes according to the context detected by the information source of the route. Hence, ARL enables flexible action selection that depends on the situation, unlike traditional reinforcement learning, wherein the actor must directly select an action.},
  langid = {english},
  keywords = {Actor-critic model,Basal ganglia,Brain-inspired refactoring,Deep learning,Natural language processing,notion,Predictive coding,Self-attention,Situatedness,Thalamocortical loop},
  file = {/Users/nscherf/Zotero/storage/TXBPYQTZ/Yamakawa - 2020 - Attentional Reinforcement Learning in the Brain.pdf}
}

@article{yanaiItTakesTwo2024,
  title = {It Takes Two to Think},
  author = {Yanai, Itai and Lercher, Martin J.},
  year = {2024},
  month = jan,
  journal = {Nature Biotechnology},
  volume = {42},
  number = {1},
  pages = {18--19},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/s41587-023-02074-2},
  urldate = {2024-02-01},
  copyright = {2024 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Education,Lab life,notion},
  file = {/Users/nscherf/Zotero/storage/SNN2P6EP/Yanai and Lercher - 2024 - It takes two to think.pdf}
}

@misc{yerxaLearningEfficientCoding2023,
  title = {Learning {{Efficient Coding}} of {{Natural Images}} with {{Maximum Manifold Capacity Representations}}},
  author = {Yerxa, Thomas and Kuang, Yilun and Simoncelli, Eero and Chung, SueYeon},
  year = {2023},
  month = dec,
  number = {arXiv:2303.03307},
  eprint = {2303.03307},
  primaryclass = {cs, q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.03307},
  urldate = {2024-02-08},
  abstract = {The efficient coding hypothesis proposes that the response properties of sensory systems are adapted to the statistics of their inputs such that they capture maximal information about the environment, subject to biological constraints. While elegant, information theoretic properties are notoriously difficult to measure in practical settings or to employ as objective functions in optimization. This difficulty has necessitated that computational models designed to test the hypothesis employ several different information metrics ranging from approximations and lower bounds to proxy measures like reconstruction error. Recent theoretical advances have characterized a novel and ecologically relevant efficiency metric, the manifold capacity, which is the number of object categories that may be represented in a linearly separable fashion. However, calculating manifold capacity is a computationally intensive iterative procedure that until now has precluded its use as an objective. Here we outline the simplifying assumptions that allow manifold capacity to be optimized directly, yielding Maximum Manifold Capacity Representations (MMCR). The resulting method is closely related to and inspired by advances in the field of self supervised learning (SSL), and we demonstrate that MMCRs are competitive with state of the art results on standard SSL benchmarks. Empirical analyses reveal differences between MMCRs and representations learned by other SSL frameworks, and suggest a mechanism by which manifold compression gives rise to class separability. Finally we evaluate a set of SSL methods on a suite of neural predictivity benchmarks, and find MMCRs are higly competitive as models of the ventral stream.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,notion,Quantitative Biology - Neurons and Cognition},
  file = {/Users/nscherf/Zotero/storage/AQ9TRED7/Yerxa et al. - 2023 - Learning Efficient Coding of Natural Images with M.pdf;/Users/nscherf/Zotero/storage/LS2XCF7Q/2303.html}
}

@article{yongBayesianAutoencodersUncertainty2022,
  title = {Bayesian Autoencoders with Uncertainty Quantification: {{Towards}} Trustworthy Anomaly Detection},
  shorttitle = {Bayesian Autoencoders with Uncertainty Quantification},
  author = {Yong, Bang Xiang and Brintrup, Alexandra},
  year = {2022},
  month = dec,
  journal = {Expert Systems with Applications},
  volume = {209},
  pages = {118196},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2022.118196},
  urldate = {2024-03-14},
  abstract = {Despite numerous studies of deep autoencoders (AEs) for unsupervised anomaly detection, AEs still lack a way to express uncertainty in their predictions, crucial for ensuring safe and trustworthy machine learning systems in high-stake applications. Therefore, in this work, the formulation of Bayesian autoencoders (BAEs) is adopted to quantify the total anomaly uncertainty, comprising epistemic and aleatoric uncertainties. To evaluate the quality of uncertainty, we consider the task of classifying anomalies with the additional option of rejecting predictions of high uncertainty. In addition, we use the accuracy-rejection curve and propose the weighted average accuracy as a performance metric. Our experiments demonstrate the effectiveness of the BAE and total anomaly uncertainty on a set of benchmark datasets and two real datasets for manufacturing: one for condition monitoring, the other for quality inspection.},
  keywords = {Anomaly detection,Bayesian autoencoders,notion,Trustworthy machine learning,Uncertainty},
  file = {/Users/nscherf/Zotero/storage/6HATRLB6/Yong and Brintrup - 2022 - Bayesian autoencoders with uncertainty quantificat.pdf;/Users/nscherf/Zotero/storage/XNA3KFFZ/S0957417422013562.html}
}

@misc{yuCurvaturebasedComparisonTwo2018,
  title = {Curvature-Based {{Comparison}} of {{Two Neural Networks}}},
  author = {Yu, Tao and Long, Huan and Hopcroft, John E.},
  year = {2018},
  month = jan,
  number = {arXiv:1801.06801},
  eprint = {1801.06801},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1801.06801},
  urldate = {2024-03-14},
  abstract = {In this paper we show the similarities and differences of two deep neural networks by comparing the manifolds composed of activation vectors in each fully connected layer of them. The main contribution of this paper includes 1) a new data generating algorithm which is crucial for determining the dimension of manifolds; 2) a systematic strategy to compare manifolds. Especially, we take Riemann curvature and sectional curvature as part of criterion, which can reflect the intrinsic geometric properties of manifolds. Some interesting results and phenomenon are given, which help in specifying the similarities and differences between the features extracted by two networks and demystifying the intrinsic mechanism of deep neural networks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/J5YPL5RH/Yu et al. - 2018 - Curvature-based Comparison of Two Neural Networks.pdf;/Users/nscherf/Zotero/storage/98Y29BLA/1801.html}
}

@misc{zhang3DShape2VecSet3DShape2023,
  title = {{{3DShape2VecSet}}: {{A 3D Shape Representation}} for {{Neural Fields}} and {{Generative Diffusion Models}}},
  shorttitle = {{{3DShape2VecSet}}},
  author = {Zhang, Biao and Tang, Jiapeng and Niessner, Matthias and Wonka, Peter},
  year = {2023},
  month = may,
  number = {arXiv:2301.11445},
  eprint = {2301.11445},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-11-24},
  abstract = {We introduce 3DShape2VecSet, a novel shape representation for neural fields designed for generative diffusion models. Our shape representation can encode 3D shapes given as surface models or point clouds, and represents them as neural fields. The concept of neural fields has previously been combined with a global latent vector, a regular grid of latent vectors, or an irregular grid of latent vectors. Our new representation encodes neural fields on top of a set of vectors. We draw from multiple concepts, such as the radial basis function representation and the cross attention and self-attention function, to design a learnable representation that is especially suitable for processing with transformers. Our results show improved performance in 3D shape encoding and 3D shape generative modeling tasks. We demonstrate a wide variety of generative applications: unconditioned generation, category-conditioned generation, text-conditioned generation, point-cloud completion, and image-conditioned generation.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,notion},
  file = {/Users/nscherf/Zotero/storage/3JXK5LV8/Zhang et al. - 2023 - 3DShape2VecSet A 3D Shape Representation for Neur.pdf;/Users/nscherf/Zotero/storage/MIJ9QRLJ/2301.html}
}

@article{zhangEmergingDrugInteraction2023,
  title = {Emerging Drug Interaction Prediction Enabled by a Flow-Based Graph Neural Network with Biomedical Network},
  author = {Zhang, Yongqi and Yao, Quanming and Yue, Ling and Wu, Xian and Zhang, Ziheng and Lin, Zhenxi and Zheng, Yefeng},
  year = {2023},
  month = dec,
  journal = {Nature Computational Science},
  volume = {3},
  number = {12},
  pages = {1023--1033},
  publisher = {Nature Publishing Group},
  issn = {2662-8457},
  doi = {10.1038/s43588-023-00558-4},
  urldate = {2023-12-21},
  abstract = {Drug--drug interactions (DDIs) for emerging drugs offer possibilities for treating and alleviating diseases, and accurately predicting these with computational methods can improve patient care and contribute to efficient drug development. However, many existing computational methods require large amounts of known DDI information, which is scarce for emerging drugs. Here we propose EmerGNN, a graph neural network that can effectively predict interactions for emerging drugs by leveraging the rich information in biomedical networks. EmerGNN learns pairwise representations of drugs by extracting the paths between drug pairs, propagating information from one drug to the other, and incorporating the relevant biomedical concepts on the paths. The edges of the biomedical network are weighted to indicate the relevance for the target DDI prediction. Overall, EmerGNN has higher accuracy than existing approaches in predicting interactions for emerging drugs and can identify the most relevant information on the biomedical network.},
  copyright = {2023 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Drug development,Drug discovery,notion},
  file = {/Users/nscherf/Zotero/storage/PWWG23S8/Zhang et al. - 2023 - Emerging drug interaction prediction enabled by a .pdf}
}

@article{zhangHippocampalSpatialRepresentations2023,
  title = {Hippocampal Spatial Representations Exhibit a Hyperbolic Geometry That Expands with Experience},
  author = {Zhang, Huanqiu and Rich, P. Dylan and Lee, Albert K. and Sharpee, Tatyana O.},
  year = {2023},
  month = jan,
  journal = {Nature Neuroscience},
  volume = {26},
  number = {1},
  pages = {131--139},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-022-01212-4},
  urldate = {2024-01-23},
  abstract = {Daily experience suggests that we perceive distances near us linearly. However, the actual geometry of spatial representation in the brain is unknown. Here we report that neurons in the CA1 region of rat hippocampus that mediate spatial perception represent space according to a non-linear hyperbolic geometry. This geometry uses an exponential scale and yields greater positional information than a linear scale. We found that the size of the representation matches the optimal predictions for the number of CA1 neurons. The representations also dynamically expanded proportional to the logarithm of time that the animal spent exploring the environment, in correspondence with the maximal mutual information that can be received. The dynamic changes tracked even small variations due to changes in the running speed of the animal. These results demonstrate how neural circuits achieve efficient representations using dynamic hyperbolic geometry.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Learning and memory,Neural encoding,notion},
  file = {/Users/nscherf/Zotero/storage/5K4RAQ9U/Zhang et al. - 2023 - Hippocampal spatial representations exhibit a hype.pdf}
}

@article{zhangMappingNonlinearBrain2023,
  title = {Mapping Nonlinear Brain Dynamics by Phase Space Embedding with {{fMRI}} Data},
  author = {Zhang, Zhenhai and Li, Kaiming and Hu, Xiaoping},
  year = {2023},
  month = apr,
  journal = {Biomedical Signal Processing and Control},
  volume = {82},
  pages = {104521},
  issn = {1746-8094},
  doi = {10.1016/j.bspc.2022.104521},
  urldate = {2024-02-01},
  abstract = {The human brain is a complex neurobiological system exhibiting complex nonlinear spatiotemporal dynamics. While functional magnetic resonance imaging (fMRI) has been widely used to study brain activity, whole-brain nonlinear dynamics in fMRI data have not been extensively examined. The present study applied phase space embedding on resting-state fMRI data and characterized their phase space dynamics with the sum of lengths of portrait edges (SE) in the reconstructed phase portrait. The effects of repetition time (TR), bandpass filtering and the added noise power of BOLD signals on the optimal embedding parameters (embedding time delay {$\tau$} and embedding dimension m) were examined with experimental or simulated fMRI data. Our results show that {$\tau$} and m vary with the three acquisition parameters. The present method was applied to the autism spectrum disorder dataset from Autism Imaging Data Exchange I to demonstrate its capability in the characterization of abnormal brain dynamics. The resultant SE maps were statistically compared between patients and controls, and the significant differences in SE were fed into a support vector machine (SVM) for classification. A significant increase in SE in the default mode network (DMN) and salience network (SN), as well as the visual network, was found in autistic patients. With the SE features of these regions, our SVM classifier achieved superior accuracy (74.55\% with 10-folds cross validation) compared with prior studies, indicating that phase space embedding and SE mapping are promising in characterizing the nonlinear dynamics of the BOLD signal and might be useful for brain biomarker discovery in clinical psychiatry.},
  keywords = {fMRI,Nonlinear dynamics,notion,Phase space embedding,Sum of lengths of portrait edges},
  file = {/Users/nscherf/Zotero/storage/QUNGZL63/S1746809422009752.html}
}

@article{zhouComparingMapperGraphs,
  title = {Comparing {{Mapper Graphs}} of {{Artificial Neuron Activations}}},
  author = {Zhou, Youjia and Jenne, Helen and Brown, Davis and Shapiro, Madelyn and Jefferson, Brett and Joslyn, Cliff and {Henselman-Petrusek}, Gregory and Praggastis, Brenda and Purvine, Emilie and Wang, Bei},
  abstract = {The mapper graph is a popular tool from topological data analysis that provides a graphical summary of point cloud data. It has been used to study data from cancer research, sports analytics, neurosciences, and machine learning. In particular, mapper graphs have been used recently to visualize the topology of high-dimensional artificial neural activations from convolutional neural networks and large language models. However, a key question that arises from using mapper graphs across applications is how to compare mapper graphs to study their structural differences. In this paper, we introduce a distance between mapper graphs using tools from optimal transport. We demonstrate the utility of such a distance by studying the topological changes of neural activations across convolutional layers in deep learning, as well as by capturing the loss of structural information for a multiscale mapper.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nscherf/Zotero/storage/VXBHX7YK/Zhou et al. - Comparing Mapper Graphs of Artiï¬cial Neuron Activa.pdf}
}

@misc{zouRepresentationEngineeringTopDown2023,
  title = {Representation {{Engineering}}: {{A Top-Down Approach}} to {{AI Transparency}}},
  shorttitle = {Representation {{Engineering}}},
  author = {Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and Goel, Shashwat and Li, Nathaniel and Byun, Michael J. and Wang, Zifan and Mallen, Alex and Basart, Steven and Koyejo, Sanmi and Song, Dawn and Fredrikson, Matt and Kolter, J. Zico and Hendrycks, Dan},
  year = {2023},
  month = oct,
  number = {arXiv:2310.01405},
  eprint = {2310.01405},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.01405},
  urldate = {2023-10-11},
  abstract = {In this paper, we identify and characterize the emerging area of representation engineering (RepE), an approach to enhancing the transparency of AI systems that draws on insights from cognitive neuroscience. RepE places population-level representations, rather than neurons or circuits, at the center of analysis, equipping us with novel methods for monitoring and manipulating high-level cognitive phenomena in deep neural networks (DNNs). We provide baselines and an initial analysis of RepE techniques, showing that they offer simple yet effective solutions for improving our understanding and control of large language models. We showcase how these methods can provide traction on a wide range of safety-relevant problems, including honesty, harmlessness, power-seeking, and more, demonstrating the promise of top-down transparency research. We hope that this work catalyzes further exploration of RepE and fosters advancements in the transparency and safety of AI systems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computers and Society,Computer Science - Machine Learning,notion},
  file = {/Users/nscherf/Zotero/storage/JHTSPJ7J/Zou et al. - 2023 - Representation Engineering A Top-Down Approach to.pdf;/Users/nscherf/Zotero/storage/2UL4N2AP/2310.html}
}
